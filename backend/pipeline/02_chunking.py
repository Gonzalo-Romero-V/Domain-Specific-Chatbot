def chunk_by_paragraphs(text):
    """
    Divide el texto en chunks usando los saltos de l√≠nea dobles como separadores de p√°rrafos.
    Limpia espacios extra y omite p√°rrafos vac√≠os o muy cortos.
    """
    # Dividimos por saltos de l√≠nea dobles (\n\n), que generalmente separan p√°rrafos
    raw_paragraphs = text.split('\n\n')
    
    chunks = []
    for para in raw_paragraphs:
        # Limpiamos espacios extra al inicio y final
        cleaned_para = para.strip()
        
        # Omitimos p√°rrafos vac√≠os o demasiado cortos (menos de 10 palabras)
        if len(cleaned_para) > 0 and len(cleaned_para.split()) >= 10:
            chunks.append(cleaned_para)
    
    return chunks

import os
from pathlib import Path

# --- Configuraci√≥n de rutas ---
# Script en: backend/pipeline/02_chunking.py
# parents[0] = pipeline, parents[1] = backend, parents[2] = root
BASE_DIR = Path(__file__).resolve().parents[2]
DATA_DIR = BASE_DIR / "data"
INPUT_FILE = DATA_DIR / "extraction_output.txt"
OUTPUT_FILE = DATA_DIR / "chunking_output.json"

# --- Cargar el texto extra√≠do ---
try:
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        full_text = f.read()
    print(f"‚úÖ Texto cargado desde '{INPUT_FILE}'")
    print(f"Total de caracteres: {len(full_text)}")
    print(f"Total de palabras: {len(full_text.split())}")
    
except FileNotFoundError:
    print(f"‚ùå No se encontr√≥ el archivo '{INPUT_FILE}'.")
    print("Aseg√∫rate de haber ejecutado primero '01_extraction.py'.")
    exit()


# --- Fragmentar por p√°rrafos ---
print("\nDividiendo el texto por p√°rrafos...")
chunks = chunk_by_paragraphs(full_text)
print(f"‚úÖ Se crearon {len(chunks)} chunks (p√°rrafos v√°lidos).")


# --- Mostrar ejemplo de los primeros 3 p√°rrafos ---
print("\n--- Ejemplo de los primeros 3 p√°rrafos extra√≠dos ---")
for i in range(min(3, len(chunks))):
    word_count = len(chunks[i].split())
    print(f"\nüîπ P√°rrafo {i+1} ({word_count} palabras):\n\"{chunks[i][:400]}...\"")


# --- Guardar los chunks en formato JSON ---
import json

with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    json.dump(chunks, f, ensure_ascii=False, indent=2)

print(f"\n‚úÖ Chunks guardados en '{OUTPUT_FILE}'")