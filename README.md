# ğŸ§  Domain-Specific Chatbot

**Asistente acadÃ©mico inteligente basado exclusivamente en el libro â€œFundamentos de la Inteligencia Artificial: Una visiÃ³n introductoria â€” Volumen Iâ€.**

Este proyecto implementa un sistema **RAG (Retrieval-Augmented Generation)** para responder preguntas basÃ¡ndose Ãºnicamente en una fuente de conocimiento especÃ­fica, evitando alucinaciones y garantizando la fidelidad de la informaciÃ³n.

---

## ğŸ¯ Objetivo del Proyecto

Desarrollar un chatbot conversacional capaz de:

1.  **Entender preguntas en lenguaje natural.**
2.  **Buscar y recuperar** los fragmentos mÃ¡s relevantes del libro en formato PDF.
3.  **Generar respuestas** basadas Ãºnicamente en el contenido recuperado.
4.  **Informar** cuando no existe contenido relevante en la base de conocimiento.

## ğŸ“š Fuente de Conocimiento

El sistema utiliza como Ãºnica fuente de verdad:

*   **TÃ­tulo:** "Fundamentos de la Inteligencia Artificial: Una visiÃ³n introductoria â€” Volumen I"
*   **Editorial:** Puerto Madero
*   **Enlace:** [Puerto Madero Editorial](https://puertomaderoeditorial.com.ar/index.php/pmea/catalog/book/77)
*   **DOI:** [10.55204/pmea.77](https://doi.org/10.55204/pmea.77)

---

## ğŸ—ï¸ Arquitectura del Sistema

El proyecto se divide en dos componentes principales: un **Backend** robusto que maneja la lÃ³gica de RAG y la API, y un **Frontend** moderno para la interacciÃ³n con el usuario.

> **Nota:** Para visualizar los diagramas Mermaid en VS Code es necesario instalar
> la extensiÃ³n *Markdown Preview Mermaid Support*:
> https://marketplace.visualstudio.com/items?itemName=bierner.markdown-mermaid


```mermaid
graph TD
    User[Usuario] -->|HTTP/REST| FE[Frontend Next.js]
    FE -->|Requests| API[Backend API FastAPI]
    
    subgraph Backend
		API -->|Consultas| RAG[RAG Service]
		API -->|Historial| DB[(MongoDB)]
        
        
        
        subgraph Pipeline_de_Datos
            PDF[Documento PDF] --> Extract[ExtracciÃ³n]
            Extract --> Chunk[Chunking]
            Chunk --> Embed[Embedding]
            Embed --> VectorDB[(ChromaDB)]
        end
        
        RAG -->|BÃºsqueda SemÃ¡ntica| VectorDB
        RAG -->|GeneraciÃ³n| LLM[OpenAI API]
    end

```

### ğŸ”§ Estructura del Backend

El backend estÃ¡ organizado en dos mÃ³dulos clave:

1.  **Pipeline de Procesamiento (`backend/pipeline/`)**:
    *   Encargado de la ingesta y preparaciÃ³n de datos.
    *   **01_extraction.py**: Extrae texto del PDF.
    *   **02_chunking.py**: Divide el texto en fragmentos manejables.
    *   **03_embedding.py**: Genera vectores semÃ¡nticos.
    *   **04_store_chroma.py**: Almacena los vectores en ChromaDB.
    *   **05_query_core.py** & **06_rag_response.py**: MÃ³dulos nÃºcleo para la lÃ³gica de recuperaciÃ³n y respuesta.

2.  **API REST (`backend/api/`)**:
    *   Construida con **FastAPI**.
    *   Expone endpoints para el chat, historial y gestiÃ³n de usuarios.
    *   Integra los servicios de base de datos y el servicio RAG.

### ğŸ’» Frontend

*   Desarrollado con **Next.js**.
*   Interfaz de chat interactiva.
*   VisualizaciÃ³n del documento fuente.
*   GestiÃ³n de autenticaciÃ³n y sesiones.

---

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### Prerrequisitos
*   Python 3.10+
*   Node.js 18+
*   MongoDB (corriendo localmente en puerto 27017)

### 1. ConfiguraciÃ³n del Backend

```powershell
# Navegar a la carpeta raÃ­z
cd Domain-Specific-Chatbot

# Crear entorno virtual
python -m venv venv

# Activar entorno virtual (Windows)
venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
# (AsegÃºrate de tener tu .env con OPENAI_API_KEY y otras configuraciones necesarias)
```

**Ejecutar el Pipeline (Solo si es la primera vez o cambian los datos):**
Ejecuta los scripts en orden dentro de `backend/pipeline/` para procesar el PDF y poblar la base de datos vectorial.

**Iniciar el Servidor API:**

```powershell
# OpciÃ³n 1: Script de inicio
python backend/start_api.py

# OpciÃ³n 2: Uvicorn directo
uvicorn backend.api.main:app --reload --host 0.0.0.0 --port 8000
```
La documentaciÃ³n de la API estarÃ¡ disponible en: http://localhost:8000/docs

### 2. ConfiguraciÃ³n del Frontend

```powershell
# Navegar a la carpeta frontend
cd frontend

# Instalar dependencias
npm install

# Iniciar servidor de desarrollo
npm run dev
```
La aplicaciÃ³n estarÃ¡ disponible en: http://localhost:3000

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

*   **Lenguajes:** Python, TypeScript
*   **Frameworks:** FastAPI, Next.js
*   **IA / ML:** OpenAI API, LangChain (conceptos), PyMuPDF
*   **Bases de Datos:** ChromaDB (Vectorial), MongoDB (NoSQL)
*   **Herramientas:** Git, VS Code

---

## ğŸ“‚ Estructura del Repositorio

```
Domain-Specific-Chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/            # Servidor FastAPI (Rutas, Modelos, Servicios)
â”‚   â”œâ”€â”€ pipeline/       # Scripts ETL y RAG Core
â”‚   â””â”€â”€ start_api.py    # Entry point
â”œâ”€â”€ frontend/           # AplicaciÃ³n Next.js
â”œâ”€â”€ data/               # Almacenamiento de datos procesados y ChromaDB
â”œâ”€â”€ docs/               # DocumentaciÃ³n adicional
â””â”€â”€ requirements.txt    # Dependencias de Python
```



- **Enlace:** https://github.com/Gonzalo-Romero-V/Domain-Specific-Chatbot.git


