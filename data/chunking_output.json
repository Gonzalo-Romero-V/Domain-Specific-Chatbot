[
  "FUNDAMENTOS DE LA \nINTELIGENCIA ARTIFICIAL: \nUNA VISION \nINTRODUCTORIA \nVolumen I",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nII",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nIII \n \n \n \n \n \nFUNDAMENTOS DE LA \nINTELIGENCIA ARTIFICIAL: \nUNA VISION \nINTRODUCTORIA \nVolumen I \n \n \nAUTORES: \nPATRICIO XAVIER MORENO VALLEJO \nGISEL KATERINE BASTIDAS GUACHO  \nPATRICIO RENE MORENO COSTALES",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nIV",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nV \nISBN General \nMoreno Vallejo, Patricio Xavier \n   Fundamentos de la inteligencia artificial : una visión introductoria / Patricio Xavier \nMoreno Vallejo ; Gisel Katerine Bastidas Guacho ; Patricio Rene Moreno Costales ; \nEditado por Juan Carlos Santillán Lima ;  Daniela Margoth Caichug Rivera. - 1a ed \nrevisada. - La Plata : Puerto Madero Editorial Académica, 2024. \n   Libro digital, PDF \n \n   Archivo Digital: descarga y online \n   ISBN 978-631-6557-23-0 \n \n   1. Ingeniería Informática. 2. Inteligencia Artificial. I. Bastidas Guacho, Gisel Katerine. \nII. Moreno Costales, Patricio Rene. III. Santillán Lima, Juan Carlos, ed. IV. Caichug \nRivera, Daniela Margoth, ed. V. Título. \n   CDD 006.301 \n  \nISBN Tomo 1 \nMoreno Vallejo, Patricio Xavier \n   Fundamentos de la inteligencia artificial : una visión introductoria / Patricio Xavier \nMoreno Vallejo ; Gisel Katerine Bastidas Guacho ; Patricio Rene Moreno Costales ; \nEditado por Juan Carlos Santillán Lima ;  Daniela Margoth Caichug Rivera. - 1a ed - La \nPlata : Puerto Madero Editorial Académica, 2024. \n   Libro digital, PDF \n \n   Archivo Digital: descarga y online \n   ISBN 978-631-6557-25-4 \n \n   1. Aplicaciones Informáticas. 2. Inteligencia Artificial. I. Bastidas Guacho, Gisel \nKaterine. II. Moreno Costales, Patricio Rene. III. Santillán Lima, Juan Carlos, ed. IV. \nCaichug Rivera, Daniela Margoth, ed. V. Título. \n   CDD 006.301 \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \nLicencia Creative Commons:  \nAtribución-NoComercial-SinDerivar 4.0 Internacional (CC BY-NC-SA 4.0)",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nVI",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nVII \nDEDICATORIA \n \n \nA los niñ@s: Leonel Robayo Moreno, Victoria Robayo Moreno y Benjamín Moreno \nBastidas. \nA quienes inspiraron esta obra: Peter Norving, Stuart Russell, Brian Yu y Hugo Banda.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nVIII",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nIX \n \n \n \n \n \nPrimera Edición, Julio 2024 \n \nFUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION \nINTRODUCTORIA \nISBN General: 978-631-6557-23-0 \nISBN Tomo 1: 978-631-6557-25-4 \nISBN Tomo 2: 978-631-6557-26-1 \n \nEditado por:  \nSello editorial: \n©Puerto Madero Editorial Académica \nNº de Alta:  \n \n933832 \n \nEditorial:  \n© Puerto Madero Editorial Académica \n \nCUIL: 20630333971 \n \nCalle 45 N491 entre 4 y 5 \n \nDirección de Publicaciones Científicas Puerto Madero Editorial \nAcadémica \n \nLa Plata, Buenos Aires, Argentina  \n \nTeléfono:  \n+54 9 221 314 5902 \n \n \n+54 9 221 531 5142 \n \nCódigo Postal: AR1900 \n \nEste libro se sometió a arbitraje bajo el sistema de doble ciego (peer review)  \n \nCorrección y diseño: \nPuerto Madero Editorial Académica  \nDiseñador Gráfico: José Luis Santillán Lima  \n \nDiseño, Montaje y Producción Editorial: \nPuerto Madero Editorial Académica  \nDiseñador Gráfico: Santillán Lima, José Luis  \n \n \nDirector del equipo editorial:  \nSantillán Lima, Juan Carlos  \n \nEditor: \nSantillán Lima, Juan Carlos \n \nCaichug Rivera, Daniela Margoth \n \nHecho en Argentina \nMade in Argentina",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nX",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXI \nAUTORES: \n \nPatricio Xavier Moreno Vallejo \nEscuela Superior Politécnica de Chimborazo, Facultad de Administración de \nEmpresas, Carrera de Gestión del Transporte, Panamericana Sur Km 1 1/2, \nEC060155, Riobamba, Chimborazo, Ecuador \npxmoreno@espoch.edu.ec \nhttps://orcid.org/0000-0002-9317-9884  \n \nGisel Katerine Bastidas Guacho \nEscuela Superior Politécnica de Chimborazo, Facultad de Informática y Electrónica, \nCarrera de Software, Panamericana Sur Km 1 1/2, EC060155, Riobamba, \nChimborazo, Ecuador \ngis.bastidas@espoch.edu.ec \nhttps://orcid.org/0000-0002-6070-7193  \n \nPatricio René Moreno Costales \nEscuela Superior Politécnica de Chimborazo, Facultad de Informática y Electrónica, \nCarrera de Software, Panamericana Sur Km 1 1/2, EC060155, Riobamba, \nChimborazo, Ecuador \npmoreno@espoch.edu.ec \nhttps://orcid.org/0000-0001-8255-8953",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXII",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXIII \nCONTENIDO \nCONTENIDO.............................................................................................................. XIII \nÍNDICE DE FIGURAS ............................................................................................. XVI \nÍNDICE DE TABLAS ............................................................................................. XVIII \nRESUMEN ................................................................................................................. XIX \nINTRODUCCIÓN ....................................................................................................... XX \nCAPITULO 1 .................................................................................................................. 1 \n1 \nEXPLORANDO LA INTELIGENCIA ARTIFICIAL .................................. 1 \n1.1 \nBreve historia cronológica de la inteligencia artificial ........................... 3 \n1.2 \nContribuciones de las ciencias a la inteligencia artificial ..................... 10 \n1.3 \nAreas de investigación de la inteligencia artificial ............................... 14 \n1.4 \nInfluencia significativa de la inteligencia artificial ............................... 19 \n1.5 \nTuring y la Evaluación de la Inteligencia de las Máquinas .................. 21 \n1.6 \nAgentes inteligentes .............................................................................. 23 \n1.7 \nDiseño del agente .................................................................................. 25 \n1.7.1 \nPropiedades del entorno de trabajo .................................................. 31 \n1.7.2 \nClases de agentes ............................................................................. 42 \n1.7.3 \nArquitecturas de programas para agentes ........................................ 50 \n1.8 \nEl conocimiento .................................................................................... 59 \n1.9 \nRepresentación del conocimiento ......................................................... 64 \n1.9.1 \nMétodos de representación del conocimiento .................................. 65 \n1.10 \nAgente basado en conocimiento ........................................................ 76 \nCAPITULO 2 ................................................................................................................ 79 \n2 \nFUNDAMENTOS DE LÓGICA Y REGLAS DE PRODUCCIÓN ........... 79 \n2.1 \nLógica ................................................................................................... 79 \n2.1.1 \nLógica proposicional ........................................................................ 82",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXIV \n2.1.2 \nLógica de primer orden .................................................................... 88 \n2.1.3 \nCuantificadores ................................................................................ 92 \n2.1.4 \nRazonamiento .................................................................................. 93 \n2.2 \nReglas de producción .......................................................................... 104 \n2.2.1 \nEncaminamiento hacia adelante ..................................................... 106 \n2.2.2 \nEncaminamiento hacia atrás .......................................................... 109 \nCAPITULO 3 .............................................................................................................. 116 \n3 \nMETODOS Y ESTRATEGIAS DE BUSQUEDA .................................... 116 \n3.1 \nBúsqueda no informada ...................................................................... 116 \n3.1.1 \nBúsqueda preferentemente por amplitud ....................................... 117 \n3.1.2 \nBúsqueda primero en profundidad ................................................. 120 \n3.1.3 \nBúsqueda de profundidad limitada ................................................ 122 \n3.1.4 \nBúsqueda por profundización iterativa .......................................... 124 \n3.1.5 \nBúsqueda de costo uniforme .......................................................... 128 \n3.2 \nBúsqueda informada ........................................................................... 131 \n3.2.1 \nBúsqueda avara (primero el mejor) ............................................... 132 \n3.2.2 \nBúsqueda A* .................................................................................. 134 \n3.3 \nOptimización ....................................................................................... 137 \n3.3.1 \nBúsqueda local ............................................................................... 138 \n3.3.2 \nBúsqueda de escalada de colinas ................................................... 140 \n3.3.3 \nVariantes de escalada de colinas .................................................... 143 \n3.3.4 \nRecocido simulado ......................................................................... 153 \n3.3.5 \nProgramación lineal ....................................................................... 157 \n3.3.6 \nSatisfacción de restricciones .......................................................... 158 \n3.3.7 \nBúsqueda de retroceso ................................................................... 163 \n3.3.8 \nInferencia ....................................................................................... 164",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXV \n3.4 \nArboles de decisión ............................................................................. 167 \n3.4.1 \nEstructura de los árboles de clasificación ...................................... 172 \n3.4.2 \nEvaluación del modelo ................................................................... 176 \nBIBLIOGRAFÍA ........................................................................................................ 182 \nDE LOS AUTORES ................................................................................................... 186 \nPATRICIO XAVIER MORENO VALLEJO ............................................................... 186 \nGISEL KATERINE BASTIDAS GUACHO ............................................................... 187 \nPATRICIO RENE MORENO COSTALES ................................................................. 188",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXVI \nÍNDICE DE FIGURAS \n \nFigura 1.1 John McCarthy ................................................................................................ 2 \nFigura 1.2 Áreas de investigación de la inteligencia artificial ....................................... 15 \nFigura 1.3 Alan Turing ................................................................................................... 22 \nFigura 1.4 Esquema de un agente ................................................................................... 25 \nFigura 1.5 Rompecabezas ............................................................................................... 26 \nFigura 1.6 Tamaño de recipientes en litros ..................................................................... 27 \nFigura 1.7 Robots jugando futbol ................................................................................... 30 \nFigura 1.8 Arquitectura Reactiva Simple ....................................................................... 51 \nFigura 1.9 Arquitectura Deliberante ............................................................................... 52 \nFigura 1.10 Arquitectura por Finalidad .......................................................................... 53 \nFigura 1.11 Arquitectura Basado en el razonamiento humano ...................................... 54 \nFigura 1.12 Arquitectura de agente de reforzamiento .................................................... 55 \nFigura 1.13 Arquitectura de agente de aprendizaje profundo ........................................ 56 \nFigura 1.14 Arquitectura de agente multiagente ............................................................ 58 \nFigura 1.15  Red semántica ............................................................................................ 65 \nFigura 1.16 Árbol de decisión ........................................................................................ 71 \nFigura 2.1: Tamaño de recipientes ................................................................................. 97 \nFigura 3.1 Árbol binario ............................................................................................... 118 \nFigura 3.2 Árbol de búsqueda....................................................................................... 123 \nFigura 3.3 Árbol con límite de 2 ................................................................................... 123 \nFigura 3.4 Grafo de búsqueda....................................................................................... 129 \nFigura 3.5 Máximo global y Máximo local .................................................................. 141 \nFigura 3.6 Mínimo global y Mínimo local ................................................................... 141 \nFigura 3.7 Máximo local plano y hombro .................................................................... 142 \nFigura 3.8 N-Reinas ...................................................................................................... 142 \nFigura 3.9 Cursos que toman los estudiantes ............................................................... 158 \nFigura 3.10 Grafo de los cursos .................................................................................... 159 \nFigura 3.11 Asignación de días a las variables ............................................................. 164 \nFigura 3.12 Uso de la heurística VMR ......................................................................... 166 \nFigura 3.13 Heurística de grado ................................................................................... 166",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXVII \nFigura 3.14 Asignación de día a la variable C .............................................................. 167 \nFigura 3.15 Árbol de decisión binario .......................................................................... 172 \nFigura 3.16 Fases de entrenamiento y prueba .............................................................. 175 \nFigura 3.17 Matriz de Confusión .................................................................................. 178",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXVIII \nÍNDICE DE TABLAS \nTabla 1-1 Factores de diseño .......................................................................................... 28 \nTabla 1-2 Propiedades del entorno de trabajo y ejemplos de agentes ............................ 31 \nTabla 2-1 Conectores básicos de la lógica proposicional ............................................... 83 \nTabla 2-2 Tablas de verdad para operadores lógicos ..................................................... 83 \nTabla 2-3 Modelos posibles ............................................................................................ 86 \nTabla 2-4 Base de conocimiento en base a P .................................................................. 87 \nTabla 2-5 Base de conocimiento en base a Q ................................................................. 87 \nTabla 2-6 Base de conocimiento en base a R ................................................................. 88 \nTabla 2-7 Fases del proceso de encaminamiento hacia adelante .................................. 108",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXIX \nRESUMEN \nEl presente estudio sobre inteligencia artificial inicia con la cronológica histórica \nde la inteligencia artificial, cómo esta ciencia contribuye e influye en diversas áreas en la \nactualidad, se analiza el diseño de los agentes inteligentes, las propiedades de sus entornos \nde trabajo, la forma en que adquieren el conocimiento y lo representan los humanos, para \npoder ofrecer un formato accesible y utilizable por sistemas de inteligencia artificial.   \nLa lógica es fundamental en la inteligencia artificial para la representación del \nconocimiento a través de la lógica proposicional y de primer orden. Mediante la inferencia \nse realiza el razonamiento lógico y la toma de decisiones en sistemas inteligentes. Las \nreglas de producción que son expresiones lógicas permiten representar las bases de \nconocimientos. \nSe examinan varios métodos y estrategias de búsqueda no informada e informada, \ncon el propósito de seleccionar la solución más adecuada de entre un conjunto de \nalternativas posibles se analiza los procesos de optimización. Los árboles de decisión al \nser ampliamente utilizados se revisa su estructura y el modelo empleado en su evaluación. \n \n \n \nPalabras clave: Inteligencia Artificial, Conocimiento, Agentes, Búsquedas",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \nXX \nINTRODUCCIÓN \nLa inteligencia artificial se encarga de representar las diferentes formas de \nconocimiento que posee el ser humano. Sus herramientas son la abstracción y la \ninferencia que le permiten crear sistemas de computación no convencionales los cuales \nson capaces de aprender nuevas tareas en base a la información proporcionada y tomar \ndecisiones en entornos diversos en los cuales debe actuar. \nLa base de la inteligencia artificial se encuentra en el influyente artículo de Alan \nTuring, \"Computing Machinery and Intelligence\", el cual sostiene que las máquinas \ndeben considerarse inteligentes si pueden comportarse como humanos. \nEste libro, está dividido en cuatro capítulos, en los cuales se explora los \nfundamentos y usos de la inteligencia artificial. El primer capítulo profundiza en los \nconceptos básicos de la inteligencia artificial. Analiza su evolución desde la década de \n1950 y se examina cómo otras disciplinas han ayudado para su desarrollo; tales como las \nmatemáticas, filosofía, psicología, lingüística y ciencia de la computación. Se destaca el \nimpacto de la inteligencia artificial en numerosos sectores como la ciencia, ingeniería, \nempresas, medicina y planificación estratégica. \nAdemás, se trata sobre el concepto de agentes inteligentes, se explora sus diseños, \nanalizando su efectividad, identificando varias arquitecturas de programas para agentes. \nSe busca resolver problemas mediante el razonamiento basado en el conocimiento y su \nrepresentación desde la perspectiva de la inteligencia simbólica. \nLa lógica es tratada en el capítulo II, constituye una técnica para la representación \ndel conocimiento utilizando proposiciones y operadores lógicos. Mediante las cláusulas \nde Horn se representa el conocimiento, del cual, se parte para poder razonar y luego \nejecutar decisiones inteligentes. \nEl Capítulo III, está relacionado a las búsquedas, que constituyen estrategias \nesenciales en la inteligencia artificial para alcanzar metas específicas. Se explora tanto las \nformas de búsquedas no informadas como las informadas, destacando sus diferencias y \naplicaciones. También se aborda los conceptos de optimización y árboles de decisión. \nEste libro está diseñado para ofrecerles a ustedes estimados lectores una sólida \ncomprensión de los fundamentos de la inteligencia artificial. Nuestro objetivo es \nanimarlos a que indaguen el potencial que posee la inteligencia artificial y contribuir a su \ndesarrollo.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n1 \nCAPITULO 1 \n1 EXPLORANDO LA INTELIGENCIA ARTIFICIAL \nA la pregunta ¿qué es la inteligencia? la respuesta constituye que es la capacidad \nde establecer relaciones, las cuales se manifiestan en los seres humanos a través del \npensamiento y la parte intelectual, y en los animales de manera puramente sensorial por \nmedio de los sentidos (Artasanchez & Joshi, 2020). Los humanos tenemos múltiples \naspectos que son parte de la inteligencia, como la capacidad de comunicación, \naprendizaje, razonamiento abstracto y resolución de problemas, mientras en los animales \nla inteligencia está relacionado a poderse adaptar al medio ambiente, manifestándose \ncomo la capacidad que poseen de la percepción, memoria y toma de decisiones. Entre los \nhumanos y los animales compartimos rasgos básicos de inteligencia como la conciencia \ndel entorno y la habilidad para responder a estímulos (McCarthy, 1956). \nLa reflexión simbólica y de autorreflexión nos permite trascender el mundo \ntangible y sensorial, crear cultura y tecnología, ganar experiencia y entender \nconceptualmente el mundo que nos rodea de forma objetiva. La aplicación del \nconocimiento es útil en el análisis y resolución de problemas, en el razonamiento durante \nla toma de decisiones; fomenta la predisposición al descubrimiento, invención, \ncreatividad e innovación. La inteligencia permite a las personas afrontar situaciones \ncomplejas de forma oportuna, rápida y razonada, y tener la capacidad de predecir el \ndesarrollo y los cambios en el entorno que nos rodea. \nEl año 1950 marca el inicio formal de la inteligencia artificial, debido a que fue \nentonces cuando se buscó dotar a las máquinas de recursos para resolver problemas de \nmanera autónoma, sin depender del apoyo humano. \nSi bien la noción de máquina ha estado presente durante muchos años, fue Alan \nTuring quien sentó las bases de la inteligencia artificial a finales de la Segunda Guerra \nMundial, en particular al estudiar científicamente las máquinas inteligentes. Turing había \nestado trabajando en la teoría de la computabilidad desde la década de 1930 y desarrolló \nuna de las primeras computadoras electromecánicas, se le recuerda por haber desarrollado \nuna máquina para descifrar códigos llamada \"bombe\" en Bletchley Park, Reino Unido, \nque descifraba mensajes encriptados con la máquina alemana Enigma. En octubre de \n1950, mientras trabajaba en la Universidad de Manchester publicó su artículo \"Computing \nMachinery and Intelligence\" en la revista Mind (Oxford University Press), donde",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n2 \nintrodujo la prueba de Turing, el aprendizaje autónomo, los algoritmos genéticos y el \naprendizaje por refuerzo, sentando las bases conceptuales para que los científicos \ncomenzaran a explorar cómo crear programas capaces de resolver problemas ellos \nmismos, sin la intervención humana. Este artículo es considerado el punto de partida que \nimpulsó la investigación formal en inteligencia artificial, dando origen a una nueva \ndisciplina dedicada a replicar la inteligencia humana en las máquinas. El legado de Turing \nha inspirado décadas de avances en aprendizaje automático, procesamiento de lenguaje \nnatural y otros campos clave de la IA. \nEn 1956, el informático John McCarthy (1927-2011) acuñó \nel término \"Inteligencia Artificial\" y organizó el influyente \nproyecto de investigación Dartmouth Summer Research \nProject on Artificial Intelligence, en el que participaron \nvarios \ncientíficos \nestadounidenses \nde \nmatemáticas, \npsicología, ciencias de la computación y teoría de la \ninformación como Marvin Minsky, Allen Newell, Arthur \nSamuel y Herbert Simon. En aquella época, las \ncomputadoras se utilizaban para tareas aritméticas con \nherramientas de programación muy primitivas. El entusiasmo y esfuerzo pionero de \nMcCarthy y sus colegas en Dartmouth sentaron las bases conceptuales y metodológicas \npara el nacimiento de la IA como campo formal. Su trabajo en esas primitivas condiciones \ninformáticas es digno de reconocimiento por impulsar una disciplina que décadas después \ntendría aplicaciones transformadoras. McCarthy se refiere a esa época como la era de \n\"¡Mira mamá, ahora sin manos!\".  \nDesde sus inicios, la Inteligencia Artificial (IA) ha tenido como objetivo replicar \ny ampliar las capacidades humanas mediante la imitación y expansión de la inteligencia \nhumana mediante medios y técnicas artificiales. Para lograr este propósito, la IA se ha \ncentrado en el desarrollo de modelos computacionales que abordan el comportamiento \ninteligente. Su enfoque se centra en la creación de sistemas informáticos capaces de \nrealizar actividades como la percepción, el razonamiento, el aprendizaje, la asociación, la \ntoma de decisiones y la resolución de problemas complejos.  \nEl progreso que se ha alcanzado en la actualidad en IA ha permitido automatizar \nactividades que antes solo los expertos humanos podían realizar debido a su complejidad \n \nFigura 1.1 John \nMcCarthy \nFuente: Wikipedia",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n3 \no necesidad del juicio de un experto, la IA ha redefiniendo lo que entendemos por \nprocesos cognitivos e inteligentes, hiendo más allá de las restricciones inherentes a la \nbiología humana (Whitby, 2009). \nLa Inteligencia Artificial representa una disciplina dentro de la informática que \nbusca construir máquinas capaces de funcionar de manera autónoma en entornos \ncomplejos y en constante cambio, creando sistemas que sean capaces de adaptarse y \nresponder de manera efectiva a situaciones desafiantes. \n1.1 \nBreve historia cronológica de la inteligencia artificial \nEn 1943, Warren McCulloch y Walter Pitts presentaron el primer modelo de red \nneuronal artificial capaz de aprender y resolver funciones lógicas. Durante la década de \n1950, la investigación en inteligencia artificial se enfocó principalmente en los juegos. \nEn 1951, Minsky y Edmonds construyeron el primer computador basado en una red \nneuronal llamado SNARC. En 1956, Arthur Samuel desarrolló el primer programa \nheurístico de juego con capacidad de aprendizaje. Ese mismo año, Allen Newell, Herbert \nSimon y Cliff Shaw inventaron el programa heurístico llamado Logic Theorist, que \nresolvió correctamente 38 de los primeros 52 teoremas del Principia Mathematica. Este \ntrabajo marcó el inicio de la investigación en psicología cognitiva utilizando ordenadores.  \nEn 1957, Noam Chomsky presentó su obra \"Estructuras Sintácticas\", destacando \nla importancia de la sintaxis en la investigación del lenguaje formal (Chomsky, 2004). En \n1958, John McCarthy inventó el lenguaje Lisp, una herramienta utilizada para la \ninvestigación en inteligencia artificial que podía procesar tanto valores numéricos como \nsímbolos (McCarthy, 1960). McCarthy también fue pionero en el desarrollo del concepto \nde tiempo compartido (Barski, 2010). \nA principios de la década de 1960, la investigación en inteligencia artificial se \ncentró principalmente en algoritmos de búsqueda y resolución de problemas generales. \nAllen Newell, Herbert Simon y Cliff Shaw desarrollaron un programa llamado GPS \n(General Problem Solver), que era un sistema definido por objetos y operadores que se \naplicaban a dichos objetos. GPS pudo resolver problemas como las Torres de Hanoi. El \nsistema utilizaba reglas heurísticas para aprender a partir de sus propios descubrimientos \ny seguía un enfoque similar al de los humanos para resolver problemas, estableciendo un \nplan, aplicando axiomas y reglas, y analizando medios y fines para modificar la resolución \ndel problema hasta alcanzar el objetivo.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n4 \nEn 1961, Marvin Minsky publicó el artículo \"Pasos hacia la Inteligencia \nArtificial\", estableciendo una terminología unificada para la investigación en inteligencia \nartificial. En 1962, Frank Rosenblatt desarrolló el Perceptrón, una red neuronal utilizada \npara el reconocimiento visual de patrones, aunque tuvo un impacto limitado en ese \nmomento. \nEn 1965, Edward Feigenbaum, Bruce Buchanan, Joshua Lederberg y Carl \nDjerassi desarrollaron el primer sistema experto llamado DENDRAL, utilizado para el \nanálisis químico. Ese mismo año, Alan Robinson propuso el principio de la Resolución. \nEn 1968, Ross Quillian introdujo la Red Semántica como una representación del \nconocimiento. En 1969, se fundó la Conferencia Conjunta Internacional de Inteligencia \nArtificial (IJCAI), que comenzó a celebrarse cada dos años y, a partir de 2016, se lleva a \ncabo anualmente. La revista Intelligence Artificial se publica bajo los auspicios de la \nIJCAI desde 1970.  \nDespués de la década de 1970, cuando las redes neuronales no cumplieron sus \npromesas, época conocida como el \"AI hype\", la financiación y las actividades de \ninvestigación se redujeron drásticamente. Esto se conocio como el \"invierno de la IA\". A \nprincipios de la década de 1970, el campo de la inteligencia artificial se enfocó hacia el \nestudio y la comprensión del lenguaje natural, así como a la representación avanzada del \nconocimiento. Durante este período, se observaron progresos significativos en diversas \nramas de la IA, marcando un hito en su desarrollo. \nEn 1972, un avance fundamental fue la publicación de Terry Winograd sobre el \nprograma SHRDLU. Este programa se distinguió por su habilidad pionera en comprender \nel lenguaje natural, específicamente el inglés, demostrando una comprensión profunda y \ncontextual de las interacciones lingüísticas. SHRDLU no solo representó un logro técnico \nimportante, sino que también estableció un marco conceptual crítico para las \ninvestigaciones futuras en la comprensión del lenguaje dentro del campo de la inteligencia \nartificial. Alain Colmerauer, en la Universidad de Marsella en Francia, desarrolló el \nlenguaje de programación Prolog en el mismo año. Prolog se convirtió en un lenguaje \nampliamente utilizado en la programación de IA debido a su capacidad para trabajar con \nla lógica y el razonamiento (Colmerauer & Roussel, 1996). \nEn 1973, Roger Schank propuso la teoría de la dependencia conceptual, que se \ncentraba en la comprensión del lenguaje natural basada en el conocimiento y la",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n5 \nrepresentación semántica. Esta teoría contribuyó al avance en el procesamiento del \nlenguaje natural en la IA. \nMarvin Minsky publicó en 1974 la teoría del sistema de marco (A Framework for \nRepresenting Knowledge), que fue una contribución importante en la representación del \nconocimiento en la IA (Baader, 2003). Esta teoría posibilitó que las máquinas ordenaran \ny estructuraran la información de una forma parecida a como lo hacen los seres humanos, \nlo que simplificó el proceso de entendimiento y razonamiento (Minsky & others, 1974). \nEn ese mismo año, Edward Shortliffe desarrolló el sistema experto MYCIN como \nparte de su tesis doctoral, implementado en Lisp, era capaz de diagnosticar trastornos en \nla sangre y prescribir medicación correspondiente. Este sistema experto fue un hito en el \ncampo médico y demostró el potencial de la IA en el diagnóstico y tratamiento de \nenfermedades (Shortliffe, 1977). Durante esta época, también se desarrollaron sistemas \nexpertos más avanzados, como el EURISKO, que tenía la capacidad de mejorar \nautomáticamente su conjunto de reglas heurísticas mediante la inducción. \nAdemás, en los años 70 se lograron otros avances notables, como la \npopularización de los algoritmos genéticos gracias al trabajo de John Holland, y la \nresurrección de las redes neuronales con la creación del algoritmo de retropropagación \n(backpropagation) por parte de Paul John Werbos. Este algoritmo sigue siendo \nampliamente utilizado en el aprendizaje supervisado para el entrenamiento de redes \nneuronales (Pham & Karaboga, 2012). Asimismo, en esta década se construyó el primer \nrobot capaz de comprender el inglés y se desarrolló el primer vehículo autónomo, \nmarcando importantes avances en la interacción entre la IA y el mundo físico. \nEn 1977, Edward Feigenbaum publicó un paper titulado \"El arte de la inteligencia \nartificial: Temas y estudios de caso en ingeniería del conocimiento\" en el quinto IJCAI. \nEn esta publicación dice que la ingeniería del conocimiento es el arte de aplicar los \nprincipios y herramientas de la investigación en IA para abordar problemas de \naplicaciones difíciles que requieren conocimientos especializados para su solución \n(Brachman & Levesque, 2004). \nEn 1978, John P. McDermott introdujo un hito en el campo de la inteligencia \nartificial con el desarrollo del sistema experto R1, marcando uno de los primeros éxitos \nsignificativos en esta área. Compuesto por aproximadamente 2500 reglas, R1 fue \nimplementado por DEC (Digital Equipment Corporation) para optimizar los procesos de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n6 \npedidos de clientes, facilitando la selección de componentes adecuados para sistemas \ninformáticos. Este logro no solo demostró la utilidad práctica de los sistemas expertos, \nsino que también abrió camino para su aplicación en el mundo empresarial. \nPosteriormente, a mediados de la década de 1980, se produjeron avances \nimportantes en el algoritmo de aprendizaje por retroalimentación, originalmente \ndesarrollado por Bryson y Ho en 1969. Estas mejoras fueron importantes para el progreso \nde los métodos de aprendizaje automático, potenciando significativamente el rendimiento \ny la eficiencia en el entrenamiento de sistemas basados en IA, lo que representó un avance \nclave en la evolución de las técnicas de inteligencia artificial. \nDurante los años 80, la Inteligencia Artificial se consolida como una ciencia en sí \nmisma. Judea Pearl en 1982 promueve la idea de los sistemas expertos normativos que se \nbasan en normas y principios de racionalidad formal, los cuales actúan racionalmente de \nacuerdo con las leyes de la teoría de la decisión, sin intentar replicar directamente el \nproceso de razonamiento humano. En 1986, Eric Horvitz y David Heckerman que han \nrealizado contribuciones significativas en áreas como el aprendizaje automático, la toma \nde decisiones basada en datos y la bioinformática, respaldaron la idea de Pearl.  \nEn ese mismo año, Rumelhart y McClelland publicaron aplicaciones de \nalgoritmos de aprendizaje en informática y psicología, lo que dio lugar al establecimiento \ndel enfoque del conexionismo basado en redes neuronales. Este enfoque revivió el interés \nen las redes neuronales como una herramienta poderosa para el aprendizaje automático y \nestableció una nueva dirección en la investigación y desarrollo de IA. \nEn 1988, Judea Pearl publica el influyente texto \"Probabilistic Reasoning in \nIntelligent Systems\", que incorpora conceptos de probabilidades y teoría de decisiones en \nel campo de la inteligencia artificial. Este trabajo fue fundamental para avanzar en el uso \nde modelos probabilísticos en la toma de decisiones en sistemas inteligentes. \nEn 1995, Russell y Norvig retomaron el trabajo en agentes totales, sistemas que \nbuscan encontrar soluciones a partir de información de entrada continua. En 1997, la \ncomputadora Deep Blue de IBM venció al ajedrecista ruso Garry Kasparov considerado \nuno de los mejores jugadores de ajedrez, este hecho situó a la inteligencia artificial como \nprotagonista en el ámbito tecnológico y demostró el potencial que tiene al desafiar a \nexpertos humanos en juegos complejos. \nEn el año 2000, se construyó el robot ASIMO, que era capaz de desplazarse en",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n7 \ndos pies, dar la mano y contestar a preguntas simples. En 2002, la empresa Cognitec \ndesarrolla el primer sistema comercial de reconocimiento facial a partir de imágenes o \nvideos. En 2006, se presentó el prototipo del robot programable y autónomo NAO. En \n2009, se lograron desarrollar robots sociales que son capaces de detectar emociones e \ninteractuar con niños autistas.  \nA partir del 2010 hasta la actualidad, se ha desarrollado el aprendizaje profundo \n(DL Deep Learning), que es un tipo especial de red neuronal que tiene más de una capa \noculta. Esto solo es posible con el aumento de la potencia informática, especialmente de \nlas unidades de procesamiento gráfico (GPU) y algoritmos mejorados. Hasta ahora, el DL \nha superado muchos otros algoritmos en un gran conjunto de datos.  \nEn 2014, se produjo un acontecimiento importante en el campo de la inteligencia \nartificial cuando el chatbot Eugene Goostman logró superar el test de Turing, considerado \nun indicador crítico en la evaluación de la capacidad de las máquinas para imitar la \ninteligencia humana en el diálogo. Este logro no solo demostró avances significativos en \nel desarrollo de sistemas de conversación automatizados, sino que también abrió un \ndebate sobre la complejidad y la verosimilitud de las interacciones entre humanos y \nmáquinas, marcando un punto de referencia en la historia de la inteligencia artificial. \nEn el año 2016, AlphaGo, un programa de IA creado por DeepMind Technologies, \nalcanzó notoriedad mundial al vencer a Lee Sedol, un campeón global en Go, un \nmilenario y desafiante juego de estrategia chino caracterizado por su alta complejidad y \nlas numerosas posibilidades que ofrece cada partida. Este logro marcó un punto de \ninflexión, generando un renovado interés y avances significativos en el ámbito de la \ninteligencia artificial, evidenciando así su capacidad para abordar tareas de gran \ncomplejidad y para la toma de decisiones estratégicas. \nUn hito importante en la intersección de la inteligencia artificial y la biología se \nalcanzó en 2020 gracias a DeepMind, los creadores de AlphaGo. Desarrollaron \nAlphaFold, una versión mejorada de su sistema de IA, que logró descifrar un desafío que \nhabía perplejado a los biólogos por más de cinco décadas: el plegamiento de proteínas. \nEste fenómeno, en el que las proteínas obtienen su forma tridimensional específica, es \nimportante para comprender su función dentro del organismo. Este avance es \nfundamental, debido a que desentraña cómo las células operan y cómo se manifiestan \ndiversas enfermedades a nivel molecular, debido a la extraordinaria complejidad de este",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n8 \nproceso. \nA partir del 2021, los avances en inteligencia artificial han sido impresionantes, \ntransformando diversos sectores de manera significativa. Un claro ejemplo es el modelo \nGPT de OpenAI, que ha marcado un antes y un después en la forma en que las máquinas \nentienden y generan lenguaje, siendo útil en una variedad de aplicaciones que incluyen \ndesde la generación automatizada de contenido hasta soporte en servicios al cliente. Por \notro lado, los modelos como BERT, desarrollados por Google, han revolucionado la \nmanera en que se procesa el lenguaje en búsquedas en línea y otras aplicaciones, logrando \nuna mayor precisión y relevancia en las respuestas brindadas. IBM Watson Health ha \ntransformado el sector médico con su capacidad para analizar extensos volúmenes de \ndatos médicos, contribuyendo a diagnósticos más acertados y tratamientos \npersonalizados. \nLa empresa Boston Dynamics ha sobresalido con sus robots Atlas y Spot, que se \nhan convertido en herramientas importantes para tareas de inspección y rescate, así como \nen aplicaciones industriales, demostrando la evolución y adaptabilidad de la robótica. \nHugging Face, ha permitido la accesibilidad al aprendizaje profundo y procesamiento del \nlenguaje natural a un público más amplio. En el terreno creativo, proyectos como AIVA \n(Artificial Intelligence Virtual Artist) están trabajando en la composición musical \nmediante la inteligencia artificial y DeepArt explora nuevas posibilidades en el arte visual \na través de la tecnología de IA. Google AI for Earth está utilizando la inteligencia artificial \npara el análisis de datos medioambientales, en la búsqueda de soluciones sostenibles, que \naborden los retos más críticos del cambio climático.  \nEl campo de la inteligencia artificial se suele confundir con la ciencia de datos, el \nbig data y la minería de datos, pero en realidad representan disciplinas diferentes. La \nciencia de datos se enfoca principalmente en la manipulación y el análisis de datos, \nincluyendo el manejo de grandes volúmenes de datos (big data) y la minería de datos; de \nforma frecuente emplea técnicas de aprendizaje automático (Machine Learning) y \naprendizaje profundo (Deep Learing) para el procesamiento de datos. \nLa transformación digital ha generado una inmensa cantidad de datos, los cuales \nprovienen de diversas fuentes, al no poder ser analizados de manera eficiente con las \nherramientas y algoritmos tradicionales de bases de datos; la inteligencia artificial, el big \ndata y la minería de datos han desarrollo algoritmos sofisticados ( algoritmos de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n9 \naprendizaje automático, algoritmos de clasificación y regresión, algoritmos de \nagrupamiento y algoritmos de minería de datos), que posibilitan a las empresas tomar \ndecisiones basadas en datos y brindar a los usuarios acceso a información relevante de \nmanera rápida y cómoda en sus actividades diarias. \nGoogle Search y Google Maps proporcionan resultados de búsqueda relevantes y \nsugerencias de navegación personalizadas comparado con productos similares, Spotify \nrecomienda música que se ajuste a los gustos y preferencias del usuario y Netflix emplea \nla IA para sugerir películas y series que probablemente interesen al usuario, basándose en \nsus visualizaciones anteriores y preferencias. Todas estas plataformas populares \nincorporan algoritmos avanzados de inteligencia artificial para realizar su trabajo.  \nAl usar uno de los siguientes asistentes personales, Alexa de Amazon, Siri de \niPhone, Cortana de Microsoft, Bixby de Samsung o Google Assistant, observamos que \nentiende lo que hablamos, ejecutando de forma eficiente la tarea solicitada. Las redes \nsociales como Facebook, Pinterest y Google Fotos, tienen incorporado el reconocimiento \nfacial, a través de técnicas sofisticadas de visión por computadora que mejora la \ninteractividad y seguridad de sus usuarios. \nEn el ámbito empresarial, la robótica, los sistemas expertos y el aprendizaje \nautomático están transformando los procesos y brindando oportunidades de innovación \nen los negocios. \nActualmente, se están desarrollando herramientas y plataformas de ciencia de \ndatos que permiten la aplicación de algoritmos de inteligencia artificial. Algunos \nejemplos de estas plataformas incluyen RapidMiner, Anaconda y Python.  \nLos líderes de la industria tecnológica, como Google, Microsoft, Meta Platforms, \nAmazon, Oracle y OpenAI están profundamente comprometidos con la inteligencia \nartificial. Esta tecnología se está integrando profundamente en diversos aspectos de \nnuestra vida cotidiana, influyendo en nuestras decisiones y siendo importante en las \nestrategias empresariales, la salud pública, la seguridad y las finanzas. En el futuro \ndebemos esperar un desarrollo significativo en aplicaciones web, videojuegos y robótica \nautónoma, veremos cada vez más vehículos autónomos circulando por las calles, robots \nsociales ayudando a las personas en su vida diaria y exploradores planetarios llegando a \nlugares más lejanos en el universo. Asimismo, las aplicaciones en el ámbito \nmedioambiental y el ahorro energético serán de gran importancia, al igual que en los",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n10 \ncampos de la economía, la sociología y el arte (Lee & Qiufan, 2021). \n \n1.2 \nContribuciones de las ciencias a la inteligencia artificial \nVarias ciencias han aportado al desarrollo de la Inteligencia Artificial, entre ellas \nse tiene: \nLa filosofía ha planteado diversas teorías sobre el razonamiento y el aprendizaje, \nconcibiendo a la mente como una máquina que funciona a partir del conocimiento, \ncodificado en un lenguaje interno y al considerar que el pensamiento sirve para determinar \ncuál es la acción correcta que se debe emprender (McCarthy, 1990).  \nUn parte relevante en el desarrollo del razonamiento deductivo es la lógica \nsilogística propuesta por el filósofo Aristóteles, considerada el primer sistema formal de \nrazonamiento deductivo, la cual establece reglas precisas para derivar conclusiones \nválidas a partir de premisas, esto a contribuido al desarrollo posterior de la lógica y ha \ninfluido en los fundamentos de la inteligencia artificial. \nDesde la perspectiva de la inteligencia artificial, se han explorado puntos de vista \nmás avanzados y sofisticados para comprender el razonamiento y el aprendizaje; que  \ninvolucran el uso de algoritmos de aprendizaje automático, redes neuronales y técnicas \nde procesamiento de lenguaje natural, permitiendo a las máquinas no solo realizar \nrazonamiento deductivo, sino también abordar problemas complejos de manera más \neficiente y aproximarse a la toma de decisiones basadas en datos y modelos de \nconocimiento. \nLas matemáticas son fundamentales en el desarrollo de teorías formales \nrelacionadas con la lógica, las probabilidades, la teoría de decisiones y la computación. \nLa lógica matemática permite tratar con declaraciones y razonamientos que pueden ser \nverdaderos o falsos, mientras que la teoría de probabilidades aborda situaciones de \nincertidumbre y riesgo.  \nEn el libro \"Una investigación de las leyes del pensamiento\" de George Boole se \nencuentra el desarrollo del álgebra booleana que se ha convertido en una herramienta \nesencial en la lógica digital y la computación para la representación de reglas básicas de \nrazonamiento en actividades mentales, permitiendo manipular datos y realizar \noperaciones lógicas en las computadoras y otros dispositivos electrónicos. \nLas matemáticas siguen siendo esenciales en el ámbito de la inteligencia artificial.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n11 \nLas redes neuronales y los algoritmos de aprendizaje automático son modelos \nmatemáticos que permiten a las máquinas aprender de los datos y realizar inferencias \ncomplejas para tomar decisiones o realizar acciones basadas en la información procesada.  \nLa teoría de la computación proporciona el marco teórico y los principios que \nguían la creación y el funcionamiento de algoritmos que minimicen el uso de recursos, \ntiempo de computación y memoria; mientras que los fundamentos matemáticos aportan \nlas herramientas y técnicas necesarias para formular y resolver problemas de manera \nlógica y precisa (Domkin, 2021). \nLa psicología tiene gran importancia en el estudio y entendimiento de la mente \nhumana, al ser una ciencia, se enfoca en explorar y comprender los procesos cognitivos \n(como el pensamiento, la memoria, la percepción y la toma de decisiones) y emocionales \n(los sentimientos y las emociones) que caracterizan el comportamiento humano. \nLa idea de que los humanos procesan información ha contribuido a modelar los \nsistemas de inteligencia artificial, inspirándose en la forma en que los humanos pensamos \ny tomamos decisiones. Los enfoques teóricos y conceptuales de la psicología sobre el \nprocesamiento del lenguaje natural, la percepción visual y la toma de decisiones, han \ninfluido en el diseño de algoritmos y modelos utilizados en los sistemas de la inteligencia \nartificial. \nLa IA no se centra exclusivamente en imitar la mente humana. También incorpora \nelementos de matemáticas, estadística e informática, lo que permite a las máquinas \nrealizar tareas cognitivas específicas y tomar decisiones en diversos contextos, a veces de \nmanera diferente a como lo haría un ser humano. La lingüística es importante en la \ninteligencia artificial al proporcionar teorías y herramientas para comprender la estructura \ny el significado del lenguaje humano. El lenguaje es un componente fundamental de la \ncomunicación y su comprensión y generación son elementos esenciales en muchos \nsistemas de inteligencia artificial. \nLa lingüística es la ciencia del lenguaje que posee un enfoque sistemático para el \nanálisis de la gramática (estructura y reglas del lenguaje), semántica (significado de las \npalabras y frases) y pragmática (uso del lenguaje en contextos específicos) del lenguaje. \nEl estudio detallado de las reglas y patrones lingüísticos, ha permitido los avances \ntecnológicos en el campo de la inteligencia artificial y la computación, permitiendo a las \nmáquinas entender y generar lenguaje, así como para producir texto comprensible para",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n12 \nlos humanos. \nLa colaboración entre la lingüística y la inteligencia artificial ha sido un factor \nimportante para el progreso del procesamiento del lenguaje natural (PLN), que permite a \nlas máquinas entender, interpretar y generar lenguaje humano de forma similar a cómo lo \nhacen las personas. Otras aplicaciones son la traducción automática; los chatbots, que \npueden interactuar en lenguaje natural con los usuarios; y los sistemas de diálogo, que \nfacilitan una comunicación fluida y natural con las máquinas. \nLa lingüística ha sido fundamental en la creación de recursos como bases de datos \nléxicas (listas de palabras y sus significados), corpus textuales (grandes colecciones de \ntextos escritos o transcripciones de habla) y modelos de conocimiento lingüístico. Estos \nrecursos son indispensables para entrenar y mejorar los sistemas de IA, proporcionando \nla información necesaria para que las máquinas aprendan y entiendan el lenguaje humano. \nLa ciencia de la computación proporciona los lenguajes de programación que \nson el medio por el cual se escriben y se ejecutan los algoritmos de inteligencia artificial \ny los marcos de desarrollo, que ofrecen estructuras y librerías predefinidas para facilitar \nla creación de aplicaciones de inteligencia artificial.  \nAlan Turing es una figura fundamental en el origen de la ciencia de la \ncomputación debido a sus contribuciones innovadoras y su visión de lo que podrían ser \nlas computadoras y su funcionamiento. Sus teorías y modelos proporcionan el marco \nconceptual para comprender cómo las máquinas pueden no solo procesar información, \nsino también realizar tareas que requieren algún nivel de inteligencia, como el \naprendizaje, el razonamiento y la adaptación. \nEn el ámbito de la IA, los programas y algoritmos son fundamentales para \ncapacitar a las máquinas para que realicen tareas consideradas inteligentes como la \nresolución de problemas hasta la imitación de comportamientos humanos como el \naprendizaje y la toma de decisiones. Los programas demandan una cantidad significativa \nde recursos computacionales, incluyendo un alto poder de procesamiento y una gran \ncapacidad de memoria. La eficiencia de un algoritmo se refiere a cuán bien utiliza los \nrecursos disponibles (como tiempo de cómputo y memoria) para lograr sus objetivos \nLa ciencia de la computación ha avanzado en el procesamiento de datos \n(capacidad de manejar y transformar datos en información útil), el aprendizaje automático \n(sistemas capaces de aprender y mejorar a partir de la experiencia), la optimización de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n13 \nalgoritmos (velocidad y uso de recursos) y la gestión de grandes volúmenes de \ninformación (procesar y analizar grandes conjuntos de datos).  \nLa neurociencia se centra en entender el funcionamiento del cerebro humano a \nniveles: molecular, celular y de comportamiento. Este estudio permite desarrollar \nmodelos y principios que son aplicados en la creación de inteligencia artificial. También, \nproporciona información valiosa sobre cómo se procesa el lenguaje en el cerebro humano, \nque es utilizado en el procesamiento de lenguaje natural dentro de la inteligencia artificial. \nLa neurociencia ha permitido obtener un conocimiento más profundo de la \nfuncionalidad cerebral y de los procesos de procesamiento de información dentro del \ncerebro. Este conocimiento es valioso para los expertos en inteligencia artificial, debido \na que les ofrece inspiración basada en los mecanismos y procesos cerebrales reales para \ndesarrollar algoritmos y modelos en el campo del aprendizaje automático. \nLa neurociencia ha revelado principios fundamentales sobre cómo funcionan las \nredes neuronales en el cerebro y cómo este tiene la capacidad de cambiar y adaptarse a \ntravés del aprendizaje (plasticidad cerebral). Estos descubrimientos son importantes para \nel diseño de algoritmos en el aprendizaje automático, especialmente en el desarrollo de \nredes neuronales artificiales. Estos algoritmos buscan imitar los principios biológicos del \ncerebro humano para mejorar la eficiencia y capacidad de procesamiento en la \ninteligencia artificial. \nLa ciencia cognitiva es decisiva en el estudio de las actividades mentales \nhumanas, como la percepción, el aprendizaje, la memoria, el pensamiento y la conciencia. \nEsta disciplina integra conocimientos de varias áreas de estudio como la psicología que \ncontribuye con la comprensión del comportamiento y los procesos mentales; la lingüística \nque aporta conocimientos sobre el lenguaje y su relación con el pensamiento; la filosofía \nque ofrece marcos conceptuales y éticos; la neurociencia que brinda información sobre la \nestructura y función del cerebro; y la inteligencia artificial que ayuda a modelar y simular \nprocesos cognitivos. Juntas, estas disciplinas permiten una comprensión más completa de \ncómo se desarrollan y trabajan las actividades mentales en los seres humanos. \n La investigación en ciencia cognitiva busca descubrir cómo funcionan \ninternamente los procesos a través de los cuales los seres humanos reciben, procesan y \ncomprenden la información que obtienen de su entorno para desarrollar máquinas que \npuedan procesar e interpretar información sensorial (como imágenes, sonidos, texturas)",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n14 \nde manera similar a cómo lo hace un ser humano.  \nLa investigación en ciencia cognitiva también ha explorado el pensamiento \nhumano, incluyendo la resolución de problemas, la toma de decisiones y el razonamiento. \nEstos procesos cognitivos han sido estudiados y modelados para desarrollar algoritmos y \nsistemas de inteligencia artificial capaces de realizar tareas complejas de manera lógica y \neficiente. \nLos descubrimientos, que detallan los procesos mediante los cuales los humanos \nadquieren conocimientos (aprendizaje), los retienen (memoria) y los recuperan cuando es \nnecesario, proporcionan una base sólida para la creación de modelos sofisticados en el \ncampo del aprendizaje automático.  \nSe ha explorado el pensamiento humano en la búsqueda de entender cómo los \nhumanos abordan y solucionan situaciones complejas, y cómo procesan información para \nllegar a conclusiones con el objetivo de crear máquinas con inteligencia artificial que \nimiten el comportamiento humano. \nComprender qué es la conciencia y cómo funciona sigue siendo un desafío en \nbúsqueda de entender en profundidad la mente humana, a pesar de estos esfuerzos que se \nhan hecho en la inteligencia artificial, simular completamente la conciencia humana es \nun desafío significativo y aún no se ha logrado. Los modelos actuales pueden aproximarse \na ciertos aspectos de la conciencia, pero la experiencia subjetiva y la autoconciencia plena \nson elementos particularmente difíciles de replicar en una máquina (McDermott, 2007). \n1.3 \n Areas de investigación de la inteligencia artificial \nLa inteligencia artificial (IA) representa un cambio significativo y un avance \nconsiderable en el campo de la tecnología informática, muestra el progreso que ha tenido \nen comparación con generaciones anteriores, que se centraban principalmente en realizar \ncálculos numéricos (como los usados en aplicaciones científicas o comerciales), \nactualmente la IA se orienta hacia tareas más complejas y abstractas, que incluyen la \nmanipulación simbólica (trabajar con información representada mediante símbolos, como \nen el procesamiento del lenguaje) y la emulación de comportamientos inteligentes \n(intentar replicar o simular formas de inteligencia similares a las humanas, como el \nreconocimiento de patrones, la toma de decisiones, y el aprendizaje).  \nLas áreas de la IA en las cuales se está investigando en la actualidad son \npresentadas en la figura 1.2, se han agrupado partiendo de las formas de representación",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n15 \ndel conocimiento en la inteligencia artificial que son: la representación simbólica y la \nrepresentación no simbólica y también se puede observar combinadas de las dos \nrepresentaciones. \nLa representación simbólica es un método para modelar y manipular el \nconocimiento utilizando símbolos (palabras, números o iconos) que se eligen y se utilizan \nde manera estructurada y lógica. Por ejemplo, en un sistema simbólico, una palabra como \n\"elefante\" = “mamífero paquidermo de gran tamaño” es un símbolo que representa un \nconcepto específico en el mundo real. \nLa representación no simbólica, en lugar de usar reglas específicas y símbolos \ndefinidos, utiliza patrones y modelos matemáticos o estadísticos que aprenden de los \nejemplos y datos. Por ejemplo, en una red neuronal utilizada para el reconocimiento de \nimágenes, no hay un símbolo específico para \"elefante\", sino que el conocimiento sobre \nqué constituyen estos animales se aprende (de muchas fotos de elefantes) y se almacena \nen los patrones de conexión entre las neuronas de la red. \n \n \nFigura 1.2 Áreas de investigación de la inteligencia artificial \nElaborado por los Autores \nSe presenta una breve explicación de cada una de las áreas den investigación en \ninteligencia artificial: \nRepresentación Simbólica: \n1. Sistemas Expertos:  Utilizan reglas para representar el conocimiento y la lógica \npara deducir nuevas informaciones.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n16 \n2. Procesamiento del Lenguaje Natural (PLN): Se enfoca en la comprensión y \ngeneración de lenguaje humano mediante reglas gramaticales y semánticas. \n3. Robótica Cognitiva: Los robots son capaces de interpretar su entorno y reconocer \nlos objetos y situaciones que encuentran, tienen la capacidad de interactuar \nfísicamente con su entorno, tomando o moviendo los objetos (Franceschetti, \n2018).  \n4. Razonamiento Automatizado: Las máquinas o sistemas informáticos son capaces \nde pensar y llegar a conclusiones de manera similar a como lo haría un ser \nhumano, proceso que lo realizan de manera automática y estructurada mediante \nun programa o algoritmo. \n5. Interacción Hombre-Máquina: Es el estudio y la parte práctica de cómo las \npersonas se comunican o interactúan con las computadoras y otros dispositivos \ntecnológicos, buscando que sea fluido y sencillo como hablar o interactuar con \notro ser humano. \n6. Ontologías y Representación del Conocimiento: Se trata de crear modelos que \npuedan representar el conocimiento de manera que las computadoras lo entiendan \ny lo manejen eficientemente, utilizando entidades, atributos, y relaciones \nsimbólicas (Poole & Mackworth, 2010). \nRepresentación No-Simbólica: \n1. Aprendizaje Automático: Se tienen los siguientes tipos de aprendizaje. \na) Aprendizaje Supervisado: Estos modelos de inteligencia artificial se utilizan para \nrealizar tareas de clasificación o regresión, se entrenan usando un conjunto de \ndatos que han sido etiquetados con anterioridad (Xiao, 2022). \nb) Aprendizaje No Supervisado: Los modelos trabajan identificando patrones en \ndatos que no han sido etiquetados, para locual usan técnicas de grupamiento o \nreducción de dimensionalidad. \nc) Aprendizaje por Refuerzo: Son modelos (agentes) que aprenden a tomar \ndecisiones mediante experimentación e interacción con el medio ambiente, \nreciben recompensas o penalizaciones en función de las acciones que realizan.  \n2. Redes Neuronales y Aprendizaje Profundo: Es un tipo de tecnología que intenta \nimitar la forma en que el cerebro humano procesa la información. Las redes \nneuronales son sometidas a un proceso llamado \"entrenamiento\", durante el cual",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n17 \nla red ajusta sus parámetros internos (llamados \"pesos sinápticos\") para mejorar \nsu capacidad de realizar la tarea deseada (Haykin, 2009).  \n3. Visión por Computadora: Busca que las computadoras procesen y analicen el \ncontenido visual (imágenes, videos) obtenido mediante cámaras y sensores del \nmundo que les rodea. \n4. Procesamiento de Lenguaje Natural basado en Aprendizaje Automático: Usa \nmodelos estadísticos y redes neuronales para el entendimiento, interpretación y \ngeneración de lenguaje humano de manera efectiva.  \n5. Sistemas de Recomendación: Son sistemas informáticos que se basan en \nalgoritmos de aprendizaje profundo y estan diseñados para sugerir \nautomáticamente productos, servicios, información o acciones a los usuarios. \n6. Bioinformática y Análisis de Datos Biomédicos: Utiliza técnicas informáticas y \nestadísticas para entender y analizar los datos. La bioinformática se centra en el \nanálisis de datos a nivel molecular, como los genes y proteínas, mientras que el \nanálisis de datos biomédicos incluye datos relacionados con la salud y la biología. \n7. Análisis Predictivo y Minería de Datos: Son técnicas que buscan patrones (como \ntendencias comunes o repetitivas), correlaciones (relaciones entre diferentes \nvariables) y conocimientos a partir de grandes volúmenes de datos para predecir \ntendencias o comportamientos futuros. \n8. Integración de Conocimiento en Modelos de Aprendizaje Automático: Se refiere \nal proceso de aprovechar la información y estructuras que ya existen he \nincorporárlas en los modelos de aprendizaje automático. \n9. Simulación y Modelado Basado en Agentes: Se usa agentes autónomos para \nsimular comportamientos y sistemas complejos y dinámicos. Cada agente en el \nmodelo representa una entidad con su propio conjunto de características y reglas \nde comportamiento. Esta técnica es útil en el campo de la inteligencia artificial \ndistribuida, donde se busca comprender y replicar comportamientos colectivos o \nde enjambre, como los observados en la naturaleza. \n10. Robótica Basada en Aprendizaje Automático: Incorpora técnicas de aprendizaje \nautomático en la robótica para mejorar las capacidades de percepción y decisión \nde los robots, especialmente en entornos que son dinámicos y no estructurados \n(Franceschetti, 2018).",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n18 \nRepresentación Simbólica y Representación No-Simbólica: \n1. Procesamiento del Lenguaje Natural (PLN) Híbrido: Estudia cómo hacer que las \ncomputadoras sean capaces de analizar, entender y generar lenguaje humano de \nforma automática. Usa métodos simbólicos como el análisis sintáctico basado en \nreglas gramaticales y la representación semántica basada en reglas. Combina con \nmétodos no simbólicos, como el aprendizaje profundo. Se emplean en la \ntraducción automática entre idiomas, el análisis de sentimientos y la generación \nde texto.  \n2. Sistemas Expertos Mejorados: Los sistemas expertos tradicionales, basados en \nconocimiento simbólico y reglas, se pueden enriquecer con técnicas de \naprendizaje automático para manejar la incertidumbre, aprender patrones y \ncapturen excepciones al manejar grandes volúmenes de datos.  \n3. Robótica Cognitiva Avanzada: Los robots utilizan algoritmos de aprendizaje \nprofundo para interpretar lo que perciben a través de sus sensores y están \nequipados con sistemas que siguen reglas predefinidas para planificar sus acciones \ny tomar decisiones (Franceschetti, 2018). Estos robots pueden manejar una \nvariedad de situaciones y tareas en diferentes entornos, realizando ajustes según \nsea necesario para adaptarse a cambios inesperados en su entorno. \n4. Sistemas de Recomendación Híbridos: Combinan el análisis de patrones de \ncomportamiento de usuarios (aprendizaje no simbólico) con reglas basadas en \nconocimiento específico del dominio (aprendizaje simbólico) para proporcionar \nrecomendaciones más precisas y contextuales. Son asistentes inteligentes que te \nsugiere cosas basándose en lo que te gusta y en conocimientos específicos de un \nárea determinada. \n5. Integración de Conocimiento en Aprendizaje Automático: Se utiliza en proyectos \nque buscan integrar bases de conocimiento estructuradas (simbólicas) dentro de \nmodelos de aprendizaje automático (no simbólicos) para mejorar la interpretación \ny generalización de los modelos. \n6. Ontologías en Aprendizaje Automático: Se usa ontologías y estructuras de \nconocimiento simbólico para guiar y mejorar el proceso de aprendizaje en \nmodelos no simbólicos, especialmente en dominios específicos como la medicina \no la biología (García Serrano, 2012).",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n19 \n7. Inteligencia Artificial Explicable (XAI): Busca desarrollar modelos de IA, \nespecialmente los basados en aprendizaje profundo, que puedan explicar sus \ndecisiones y procesos de una manera comprensible para los humanos, a menudo \nintegrando elementos simbólicos en la explicación de modelos no simbólicos. \n1.4 \nInfluencia significativa de la inteligencia artificial  \nLa importancia de la inteligencia artificial radica en el hecho de que se relaciona \ncon la mayoría de campos de investigación a través de diferentes disciplinas tales como: \nlas ciencias de la ingeniería (ayuda a diseñar sistemas más eficientes y seguros), la \neconomía (permite analizar tendencias de mercado y predecir cambios económicos)  y la \nmedicina (contribuye al diagnóstico y tratamiento de enfermedades, e incluso en la \ninvestigación de nuevos medicamentos), siendo usada la IA como un medio para hacer \nfrente a muy complicados y difíciles procesos de cómputo, así como a los problemas \ncognitivos. Al ser la IA una de las principales corrientes de tratamiento de la información, \npuede ahora ofrecer soluciones a los problemas utilizando los avances e innovaciones \nentre una amplia gama de sub-áreas que inducen el pensamiento y razonamiento en los \nmodelos y sistemas desarrollados. \nSe espera que las empresas que utilizan aplicaciones de Inteligencia Artificial \nmejoren la capacidad de analizar los datos a través de múltiples variables, puedan detectar \nfraudes y gestionen de mejor manera las relaciones con los clientes para obtener una \nventaja competitiva. \nAltos directivos de muchas empresas utilizan sistemas de planificación estratégica \nbasados en IA para tener una asistencia en funciones como: análisis de la competencia, el \ndespliegue de tecnología y la asignación de recursos. También se utilizan programas para \nayudar en el diseño de la configuración de equipos, distribución de productos, \nasesoramiento en el cumplimiento y evaluación de personal. La IA está contribuyendo en \ngran medida en la organización, planificación de la gestión y control de las operaciones, \ny continuará haciéndolo con más frecuencia a medida que se refinan los programas. \nLa IA también es influyente en la ciencia y la ingeniería, las aplicaciones \ndesarrolladas se utilizan para organizar y manipular las cantidades cada vez mayores de \ninformación disponibles para los científicos e ingenieros, se emplea en clasificaciones \nbiológicas, en la creación de circuitos semiconductores y componentes de automóviles. \nLa IA se utiliza en la difracción y análisis de imágenes, en las plantas de energía y en el",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n20 \ndiseño de las estaciones espaciales, uno de sus mayores usos es en la robótica. \nPor la cantidad de habitantes que viven en el planeta tierra cada vez más se \nnecesita usar de forma eficiente los recursos materiales y humanos, para lo cual podemos \nutilizar el poder que tienen las computadoras y la IA, en la agricultura para  controlar \nplagas y manejar cultivos en forma más eficiente; en las fábricas en la realización de \nmontajes peligrosos y actividades tediosas (labores de inspección y mantenimiento); en  \nmedicina en el diagnóstico a pacientes, detectar pacientes que están en mayor riesgo de \ncomplicaciones, supervisar la condición de los pacientes, descubrir sutiles interacciones \nentre los medicamentos que ponen a los pacientes en riesgo de sufrir efectos secundarios \ngraves, administrar tratamientos y preparar estudios estadísticos; en el trabajo doméstico \nasistir en la limpieza de la casa, preparación de alimentos, a brindar asesoría acerca de \ndietas, compras, supervisión y gestión de consumo energético y seguridad del hogar; en \nlas escuelas apoyar en la formación de los estudiantes, especialmente en aquellas materias \nconsideradas complejas; colaborar con los humanos expertos en el análisis para la \nsolución de problemas difíciles o en el diseño de nuevos dispositivos. \nSe ha convertido en algo común de nuestras vidas el uso del GPS (Global \nPositioning System) para escoger la mejor ruta, recibir estados del tráfico, usar teléfonos \ninteligentes que entienden nuestro lenguaje, asistentes inteligentes como Cortana de \nMicrosoft y Siri de Apple; la búsqueda inteligente que realiza el buscador de Google y \nBing, el traductor y lector de documentos de Google. Algoritmos inteligentes que detectan \nlos rostros mientras estamos tomando una foto con el celular y reconocen las caras de las \npersonas cuando se publican las fotos en Facebook. Los usuarios de Amazon reciben \nrecomendaciones sobre libros, los de Netflix sobre películas. Aceleración de las portátiles \nal adivinar lo que se hará a continuación. Los coches inteligentes que se conducen a sí \nmismos, que pueden enfrentar situaciones complicadas, que reconocen la voz para una \ninteracción natural, que están desarrollando BMW, Tesla, Google. La lucha contra el \nspam (correo basura) a través de clasificadores bayesianos y otras técnicas probabilísticas \nhan mostrado su eficacia. Los militares están usando aviones no tripulados, drones y \nrobots para investigar en lugares peligrosos. \nEn la actualidad existe dispositivos con IA que permiten que la gente ciega vea, \nlos sordos escuchen, y los discapacitados y ancianos puedan caminar, e incluso correr. \nLas galaxias están siendo exploradas en mutuo apoyo entre los astrónomos",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n21 \nexperimentados y las máquinas. \nLa presencia de los métodos de Inteligencia artificial ha puesto a los seres \nhumanos a pensar en los riesgos potenciales de sus avances, piensan algunas personas \nque los sistemas de IA se podrían convertir en superinteligentes y poner en peligro la \nsupervivencia de la humanidad, pero se tiene a la AAAI (Association for the \nAdvancement of Artificial Intelligence) que está encargada de incentivar el avance en la \nciencia y tecnología de la inteligencia artificial y promocionar su uso responsable. \nLos errores de programación en software de inteligencia artificial deben ser \nconsiderados, por lo que se requiere de la verificación y validación del software debido a \nla creciente complejidad y el uso en funciones delicadas como en automóviles, robots \nquirúrgicos y sistemas de armas.  Un desafío técnico es garantizar que los sistemas \nintegrados de forma automática a través de métodos estadísticos se comporten \ncorrectamente en el proceso de aprendizaje automático. Otro desafío es garantizar el buen \ncomportamiento cuando un sistema de IA se encuentra con situaciones imprevistas. Los \nvehículos automatizados, robots para el hogar, y los servicios inteligentes en la nube \ndeben funcionar bien, incluso cuando reciben insumos sorprendentes o confusos (Lalanda \net al., 2013). \nOtro riesgo que está presente son los ciberataques a los cuales los programas de \nIA son también vulnerables, y si se piensa en lo que podría suceder al estar los algoritmos \nde IA encargados de tomar decisiones de alto poder. Por lo que se requiere la \ninvestigación en seguridad cibernética para estar seguros que los algoritmos de IA y los \nsistemas que se desarrollan basados en estos pueden sobrevivir los ataques cibernéticos a \ngran escala. \nUn aspecto importante de cualquier sistema de IA que interactúa con la gente es \nque debe razonar sobre lo que las personas piensan en lugar de llevar a cabo los comandos \nde manera literal, para juzgar si lo que se le pide que realice es normal o razonable para \nla mayoría de la gente. \n1.5 \nTuring y la Evaluación de la Inteligencia de las Máquinas",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n22 \nTuring (1912-1954) propuso la Máquina Niño, en la \nque se crearía un agente inteligente básico y se sometería a un \ncurso de educación para proporcionarle conocimiento. En su \nartículo de 1950, \"Computing machinery and intelligence\", \nTuring (Figura 1.3) argumentó que si una máquina puede \nactuar como un humano, entonces se puede considerar que es \ninteligente (Turing, 2009). El Test de Turing se diseñó para \nproporcionar una definición operacional y satisfactoria de \ninteligencia, basada en la incapacidad de diferenciar entre entidades inteligentes \nindiscutibles y seres humanos (Floridi, 2023). Según este test, un computador supera la \nprueba si un evaluador humano no puede distinguir si las respuestas a una serie de \npreguntas planteadas son de una persona o no. \nLa prueba de Turing tiene mucha importancia en la investigación y el desarrollo \nde la inteligencia artificial, debido a que permite realizar la evaluación de la capacidad de \nuna máquina de imitar el comportamiento humano. A continuación se indica los \nrequerimientos de la prueba de Turing: \nEl Procesamiento de Lenguaje Natural (NLP Natural Language Processing) \ncapacita a las computadoras para comunicarse eficazmente en inglés y otros idiomas. Las \naplicaciones del NLP van mas allá de la traducción automática, extendiéndose al \nreconocimiento y comprensión del lenguaje humano, en búsqueda de que las máquinas \npueden mantener conversaciones que sean indistinguibles de las que mantienen los \nhumanos. \nLa Representación del Conocimiento permite poder almacenar lo que se conoce \no siente, la computadora debe ser capaz de almacenar y recuperar de forma eficiente la \ninformación que va obteniendo e infiriendo autónomamente. En la actualidad se \ninvestigan las técnicas de almacenamiento de información para que exista fácil \naccesibilidad y sea utilizable por los sistemas inteligentes.  \nEl Razonamiento automático utiliza la información almacenada para responder a \npreguntas y extraer nuevas conclusiones, esta temática se trata a través de los sistemas \nexpertos que buscan llegar a conclusiones lógicas a partir de hechos o premisas \nintroducidas inicialmente en el sistema; otra forma es a través de las redes probabilísticas \ncomo las redes Bayesianas o de Markov que permiten realizar predicciones y llegar a \nFigura 1.3 Alan Turing \nFuente: Elliott & Fry",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n23 \nconclusiones aun cuando existe incertidumbre. \nEl Aprendizaje automático permite a las máquinas adaptarse a nuevas \ncircunstancias, detectar y extrapolar patrones. Permite que las máquinas sean capaces de \naprender cosas nuevas, de adaptarse al medio; para lo cual en la actualidad se usan \ntécnicas basadas en redes neuronales y métodos probabilísticos como las redes bayesianas \no de Markov (Croitoru et al., 2018). \nLa Visión computacional, es una disciplina esencial, porque capacita a sistemas \ninteligentes para percibir objetos y comprender su entorno a través de imágenes. Su \ndesarrollo persigue la ambiciosa meta de igualar la capacidad de percepción visual \nhumana utilizando medios electrónicos para interpretar y comprender imágenes. La \ncomprensión de la imagen se puede considerar como el proceso de esclareser información \nsimbólica a partir de los datos visuales, empleando modelos que se fundamentan en \nprincipios de geometría, física, estadística y teoría del aprendizaje. \nLa Robótica, usada para manipular y mover objetos, tomando en cuenta el peso, \nla forma, la presión que debe aplicarse para no dañar el objeto y saber los movimientos a \nrealizar para trasladar el objeto a su destino. En el presente constituyen máquinas \nautomatizadas que pueden tomar el lugar de los humanos en entornos peligrosos o \nprocesos de fabricación, o parecerse a los humanos en apariencia en el comportamiento \ny la cognición. \n1.6 \nAgentes inteligentes \nEl paradigma principal en el campo de la Inteligencia Artificial es el modelo \nracional, que sostiene que una máquina es considerada inteligente si piensa y se comporta \nde manera racional. Este enfoque se apoya en técnicas de lógica y en el concepto de \nagentes desarrollado por Russell y Norvig. Los agentes toman decisiones basadas en el \nrazonamiento y las conclusiones extraídas de la información disponible, priorizando la \nopción más conveniente en función de los datos y el tiempo disponible. \nEl agente humano tiene un cuerpo con un conjunto de sensores que incluye la \nvisión, la audición, el olfato, el gusto, la piel, el sentido vestibular para el equilibrio, la \nnocicepción relacionada al dolor, también tiene una serie de sistemas actuadores que \nincluyen dedos, brazos y piernas y otros sistemas de control motores como el cerebro y \nel sistema nervioso central. \nEn el ámbito de la Inteligencia Artificial, un agente inteligente, también conocido",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n24 \ncomo agente, es una entidad autónoma que existe en un entorno y se guía por la \ninformación que recibe a través de sensores. Actúa de manera racional utilizando \nactuadores para llevar a cabo acciones. En un instante dado, un agente toma decisiones \nbasadas en la secuencia completa de percepciones que ha recibido hasta ese momento. \nPara realizar esta tarea, utiliza un sistema de control que mapea las percepciones en \nacciones (figura 1.4). Un ejemplo de agente sería un automóvil autónomo que debe tomar \ndecisiones para llegar a su destino. \nEn el ámbito de la Inteligencia Artificial, el sistema de control de un agente se \nrefiere al algoritmo avanzado responsable de convertir percepciones captadas a través de \nsensores en acciones específicas. Este algoritmo opera dentro de una arquitectura análoga \na la de una computadora, dotada de sensores físicos y actuadores para interactuar con el \nentorno. Un Agente Inteligente se define como: \nAgente = Arquitectura + Programa \nEl sistema de control es esencial para el funcionamiento del agente, debido a que \npermite que este interprete la información del entorno a través de los sensores y tome \ndecisiones lógicas sobre las acciones a emprender utilizando los actuadores. Es como el \ncerebro del agente, procesando la información entrante y generando respuestas adecuadas \nen base a su programación. \nLa arquitectura computacional permite que el agente interactúe con el medio \nambiente de manera autónoma y realice las tareas para las que fue diseñado. Los sensores \npermiten capturar datos del entorno y se transmiten al sistema de control, que analiza y \ntoma decisiones en función de la programación establecida, para proceder a continuación, \na envíar las señales apropiadas a los actuadores, que ejecutan las acciones \ncorrespondientes en el medio ambiente. \nLa arquitectura más simple puede ser la computadora que posee un teclado y un \nmouse que constituyen los sensores y tiene el actuador que es el monitor. Las \npercepciones de los sensores son utilizadas por el programa quien se encarga que las \nacciones generadas se muestren a través de la pantalla del monitor (Leija, 2021). Para \nescribir el programa se requiere un lenguaje de programación como lisp, prolog, phyton, \nC++, java, matlab, etc.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n25 \n \nFigura 1.4 Esquema de un agente \nElaborado por los Autores \nLa Inteligencia Artificial se enfoca en el desarrollo de programas que puedan \nmostrar un comportamiento racional, utilizando una pequeña cantidad de código en lugar \nde tener una tabla con un gran número de entradas. Un ejemplo de esto es el cálculo de \nlas raíces cuadradas, en el pasado, las personas utilizaban tablas con los resultados de las \nraíces cuadradas para diferentes números. Sin embargo, con el avance de la IA, se ha \nlogrado reemplazar estas tablas por programas que tienen unas pocas líneas en las \ncalculadoras electrónicas, lo que permite calcular fácilmente la raíz cuadrada de cualquier \nnúmero. \nEste enfoque basado en programas más compactos y generales es un objetivo de \nla IA. En lugar de tener que almacenar y consultar una gran cantidad de datos específicos, \nse busca desarrollar algoritmos que puedan inferir y generalizar patrones a partir de \ninformación limitada. Esto permite que los programas de IA sean más flexibles y capaces \nde abordar una amplia gama de situaciones sin requerir una lista exhaustiva de casos \nespecíficos. \n1.7 \nDiseño del agente \nEl agente racional se esfuerza por tomar decisiones acertadas en el momento \noportuno, con el objetivo de lograr resultados óptimos. Para evaluar el desempeño de un \nagente en su entorno, es fundamental medir su éxito en función de la secuencia de \nacciones realizadas y las percepciones recibidas. Un estado se refiere a una configuración \nparticular del agente en su entorno, mientras que el estado inicial indica el punto de \npartida del agente. \nLas acciones que toma el agente conducen a una secuencia de estados a medida \nque interactúa con su medio ambiente, si la secuencia coincide con la secuencia deseada, \nse considera que el agente ha actuado correctamente. Las acciones son simplemente \nAgente \nSensores \nActuadores \nSist\nPercepciones \nAcciones \nMedio \n \nA\nmbiente",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n26 \nopciones que pueden elegirse en cualquier estado dado, y su elección tiene un impacto \ndirecto en cómo evoluciona el agente en el entorno. \nUn agente racional debe tomar decisiones informadas y eficientes, considerando \nlas percepciones y el conocimiento disponible, con el fin de maximizar la consecución de \nsus objetivos. Al observar el entorno y tomar de decisiones adecuadas, el agente puede \nadaptarse y aprender a actuar de manera más inteligente en situaciones futuras. \nLa capacidad de un agente para seleccionar las acciones más apropiadas en cada \nestado y lograr un rendimiento satisfactorio es un desafío importante en el campo de la \ninteligencia artificial.  \nLos investigadores y expertos en IA se dedican a desarrollar algoritmos y técnicas \nque permitan a los agentes racionales tomar decisiones óptimas en una amplia variedad \nde situaciones, contribuyendo así al avance y aplicación de esta disciplina.  \n \nFigura 1.5 Rompecabezas \nFuente: Wikipedia \nUn estado se refiere a una configuración específica en la que se encuentra un \nagente dentro de su entorno. Tomemos como ejemplo un rompecabezas (figura 1.5) de \n15 piezas: cada estado representa una disposición particular en la que los números están \nordenados en el tablero. Las acciones, por otro lado, son las elecciones que se pueden \nrealizar en un estado dado. \nCuando se recibe un estado como entrada, el sistema devuelve como salida el \nconjunto de acciones que se pueden llevar a cabo en ese estado en particular. Siguiendo \nel ejemplo del rompecabezas de 15, las acciones disponibles en un estado dado están \ndeterminadas por las formas en que los cuadrados se pueden deslizar dentro de la \nconfiguración actual. Por ejemplo, si el cuadrado vacío se encuentra en el medio, hay 4 \nacciones posibles; si está junto a un borde, hay 3 acciones disponibles; y si está en una \nesquina, solo hay 2 acciones posibles.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n27 \nEstas acciones permiten al agente interactuar y modificar su estado en el entorno, \nbuscando lograr un objetivo específico. La capacidad de seleccionar las acciones más \nadecuadas en función de un estado dado es esencial para que el agente resuelva \nproblemas, tome decisiones informadas y maximice su rendimiento en el entorno en el \nque se encuentra. \nEn el campo de la Inteligencia Artificial, se desarrollan algoritmos y técnicas que \npermiten a los agentes racionales determinar de manera eficiente las acciones disponibles \nen cada estado y tomar decisiones óptimas para alcanzar sus metas. El estudio y avance \nde estas capacidades de toma de decisiones en la IA contribuyen al desarrollo de sistemas \nmás inteligentes y eficientes en diversos dominios de aplicación. \nLa secuencia de estados se muestra a continuación con otro ejemplo. Se tienen \ntres recipientes (figura 1.6), cuyas capacidades son doce litros, ocho litros y tres litros, \nademás un grifo de agua. Se desea obtener un litro de agua utilizando los recipientes, para \nlo cual puede llenar los recipientes o vaciar de un recipiente a otro, o vaciar el agua de un \nrecipiente en el suelo. Existen algunas secuencias de estados que se pueden seguir, a \ncontinuación, se muestra una de ellas. \n \nFigura 1.6 Tamaño de recipientes en litros \nElaborado por los Autores \n [12,8,3] Tamaño de los tres recipientes en litros \n [0,0,0] Todos los recipientes en un inicio se encuentran vacíos (Estado inicial)    \n [12,0,0] El recipiente de 12 litros se llena con agua del grifo (Estado intermedio)    \n [4,8,0]   Se vierte el agua del recipiente de 12 litros en el de 8 litros (Estado               \nintermedio)    \n[1,8,3]   Se vierte el agua del recipiente de 12 litros que contiene 4 litros en el de 3litros",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n28 \n(Estado intermedio)    \n[1,0,0] En el recipiente de 12 litros queda el 1 litro de agua, como las otras              \ncantidades de líquido no son las buscadas se derrama en el suelo (Estado               final)  \nEste ejemplo muestra una secuencia de estados que nos permite obtener un litro \nde agua utilizando los recipientes mencionados. Cada estado representa una \nconfiguración específica de los recipientes y las acciones realizadas (llenar, transferir, \nvaciar) nos permiten llegar al estado deseado. Este tipo de problemas de razonamiento y \nplanificación son abordados mediante técnicas de inteligencia artificial, que permiten \nencontrar soluciones óptimas o aproximadas a través de algoritmos específicos. \nLa capacidad de representar y manipular estados, así como de planificar \nsecuencias de acciones para lograr un objetivo, es fundamental en el campo de la IA. \nEstas habilidades permiten a los sistemas inteligentes resolver problemas complejos y \ntomar decisiones informadas en una amplia variedad de dominios, desde problemas de \noptimización hasta tareas de planificación y control. \nPara el diseño del agente se establecen cuatro factores que se describen a \ncontinuación en la tabla 1-1. \nTabla 1-1 Factores de diseño \nFactores \nde \ndiseño \nConceptualización \nMedida \nde \nrendimiento \n    Quien define la medida de rendimiento es el diseñador del agente, \nel cual establece los requisitos y objetivos específicos en función del \nentorno donde va a trabajar el agente, incluyendo métricas como la \nprecisión (qué tan correctas son las acciones o respuestas del agente), \neficiencia (qué cantidad de recursos que consume el agente para \nrealizar su tarea), velocidad de reacción(qué tan rápido puede \nresponder o actuar el agente) y la satisfacción del usuario (cómo se \nsienten los usuarios acerca de las interacciones con el agente). Estas \nmétricas sirven para que el diseñador ajuste y calibre adecuadamente \nel agente. \nEntorno \nde \ntrabajo \n    El entorno de trabajo es la estructura física, lógica y digital donde \nel agente realiza sus tareas y toma decisiones, es el lugar donde \ninteractúa con objetos y entidades presentes (otros agentes, humanos,",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n29 \nherramientas); el diseñador debe identificar posibles problemas que \nel agente tiene que enfrentar y proceder a desarrollar estrategias y \nalgoritmos que permitan que pueda el agente realizar sus tareas de \nmanera eficiente y competitiva.   \nPercepciones \n    Las percepciones es la capacidad del agente para obtener \ninformación del medio ambiente que lo rodea a través de sensores. \nLos sensores son los dispositivos que permiten al agente captar datos \ny señales del entorno, que le proporcionan información al agente \nsobre diferentes aspectos como el estado físico, la presencia de \nobjetos, eventos o cualquier otro tipo de estímulo relevante.  \nMediante estos datos el agente pueda comprender y tomar decisiones \nadecuadas en su entorno. \nAcciones \n    Las acciones representan el efecto que tiene el agente sobre su \nmedio ambiente, utilizando actuadores, estos son dispositivos o \nmecanismos que permiten al agente interactuar físicamente con el \nentorno y realizar cambios o ejecutar acciones específicas. Estos \nactuadores pueden variar según el tipo de agente y la aplicación para \nla cual están destinados, e incluir elementos como motores, brazos \nrobóticos, sistemas de manipulación, entre otros. \n    La capacidad de realizar acciones al agente le permite manifestar \nsu comportamiento y llevar a cabo tareas en su entorno. El agente \nmediante los actuadores, puede realizar acciones como mover \nobjetos, desplazarse en el espacio, modificar configuraciones o \nejecutar cualquier otra acción física requerida en el contexto. \nElaborado por los Autores \nEn el diseño del agente denominado robot que juega al futbol (figura 1.7) la \nmedida de rendimiento constituye: partidos ganados, partidos empatados, partidos \nperdidos, goles a favor, goles en contra. El entorno de trabajo va a ser el campo de juego, \nla pelota, sus compañeros de juego, los robots adversarios. Para que pueda realizar las \npercepciones se requiere una cámara, sensores táctiles, acelerómetro, sensores de \norientación. Para efectuar acciones necesita dispositivos de locomoción como las piernas \nque le permitan trasladarse de un lugar a otro y dispositivos para patear el balón.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n30 \n \nFigura 1.7 Robots jugando futbol \nFuente: El País España \nEl agente racional además de recopilar información debe aprender lo máximo \nposible de lo que está percibiendo, la configuración inicial del agente debe reflejar un \nconocimiento preliminar del entorno, pero a medida que adquiere experiencia el \nconocimiento se debe modificar y aumentar. \nLas funciones del agente se calculan en tres períodos que son: \n• Durante el diseño de agente: Los encargados de diseñar el agente realizan cálculos, \npara que el agente posea el conocimiento inicial requerido. \n• El agente pensando en el próximo estado: Cuando el agente piensa en la siguiente \noperación, realiza más cálculos. \n• El agente aprende de la experiencia: Producto de la experiencia el agente lleva a cabo \nmás cálculos para decidir cómo modificar su forma de comportarse. \nEl agente racional debe tener un comportamiento autónomo que le permita \naprender a determinar cómo compensar el conocimiento incompleto o parcial inicial, \npudiendo de esta forma ser capaz de navegar en su entorno sin la guía de una entidad \nexterna (un operador humano), pueda buscar metas en su entorno, resolver \nproblemas. \nEl agente debe poder subsistir a través del tiempo en el medio ambiente que \nse lo ubique, e interactuar con otros agentes para proporcionar información o que le \nproporcionen información, o comunicarse con los usuarios. Tener movilidad le \npermite al agente migrar entre sistemas a través de una red, tener la capacidad de \naprender y adaptarse al entorno. En el proceso de aprendizaje los sensores deben \nmapear el entorno, para que el sistema de control de las órdenes adecuadas a los \nactuadores quienes demuestran una conducta o comportamiento inteligente que",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n31 \nsatisfaga un conjunto de restricciones definidas.  \nDespués de las suficientes experiencias interaccionando con el entorno, el \ncomportamiento del agente racional será independiente del conocimiento que poseía \ninicialmente.    Esto significa que el agente ha adquirido la capacidad de adaptarse y \nresponder de manera inteligente a diferentes situaciones sin depender únicamente de \nsu conocimiento previo. \n1.7.1 Propiedades del entorno de trabajo \nLas propiedades del entorno de trabajo se refieren a las características y cualidades \ndel ambiente en donde un agente o sistema de inteligencia artificial ejecuta sus acciones. \nLas propiedades del entorno influyen en cómo un agente puede percibir y actuar, y pueden \nvariar ampliamente según la aplicación específica. Es necesario categorizar los entornos \nde trabajo (Tabla 1-2) en los que el agente inteligente va a desenvolverse, esto ayuda en \nsu diseño. \nTabla 1-2 Propiedades del entorno de trabajo y ejemplos de agentes \nENTORNO \nCARACTERÍSTICAS \nEJEMPLOS \nDE AGENTES \nTotalmente \nobservable \n \n   En un entorno totalmente observable, \nlos \nsensores \ndel \nagente \ndeben \nproporcionar \nuna \nrepresentación \ncompleta y fiable del estado del medio \nambiente en que se desenvuelve, en \ncada momento. El agente debe detectar \ny capturar todos los aspectos que son \nrelevantes en la toma de decisiones que \nestán en función de las medidas de \nrendimiento (MacKay, 2003). En estos \nentornos \nel \nagente \nno \nnecesita \nmantener ningún estado interno para \nsaber qué sucede en el mundo. \n   Al existir una visión integral y \ndetallada del estado actual, se facilita la \ntoma de decisiones informadas sin \no Ayudante \nde \nmatemáticas \no Juego de Ajedrez \no Sistema \nde \nNavegación GPS \no Laberinto \ncon \nvisibilidad completa  \no Sistema \nde \nMonitoreo \nde \nSensores \no Agente \nde \nreconocimiento de \nvoz \no seguimiento \nde \nobjetos \no análisis de datos",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n32 \nincertidumbre, el agente no requiere \nmantener un histórico para completar \nla información faltante o inferir \naspectos ocultos del entorno. La \ncapacidad de observación completa y \nsin limitaciones brinda al agente una \nventaja al comprender de manera \nprecisa el contexto en el que actúa, \npoder tomar decisiones adecuadas en \ntiempo real y realizar cálculos exactos \ndel beneficio, importancia de una \ndeterminada acción, o la recompensa \nesperada \nbasado \nen \nel \nestado \nobservable.   \no control de calidad \no reconocimiento \nfacial \n \nParcialmente \nobservable \nEn \nlos \nentornos \nparcialmente \nobservables la percepción del agente es \nafectada por la presencia de ruido \n(Lindley, 2013) o la utilización de \nsensores poco exactos o porque el \nagente no recibe información completa \ndel sistema; esta percepción limitada o \nincompleta le dificulta la obtención de \nuna visión global y precisa del estado \ndel \nentorno, \npudiendo \ngenerar \nincertidumbre en el agente. \n   El agente al no tener acceso a una \nrepresentación directa y completa del \nestado en el que se encuentra, se ve \nobligado a realizar inferencias y \nestimaciones \npara \nobtener \nuna \ncomprensión aproximada del estado \nactual. En búsqueda de enfrentar esta \no Poker \no Tráfico en tiempo \nreal \no Laberinto \ncon \nvisibilidad limitada \no Predicción del clima \no Robot que juega al \nfutbol \no Juego del veintiuno \n(Black jack). \no Robot clasificador \nde baldosas \no Robot de limpieza \nautónomo \no Asistente \nvirtual \ninteligente \no reconocimiento de \nobjetos",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n33 \nsituación se debe incluir la utilización \nde algoritmos de filtrado que procesen \nsecuencias \nde \ndatos \nruidosos \no \nincompletos y técnicas de fusión de \ndatos que combinen la información \nentregada por los sensores de tal forma \nque se pueda mejorar la precisión de la \npercepción. \no Sistema \nde \ndetección \ny \nprevención \nde \nfraudes \no diagnóstico médico \nDeterminista \n   En los entornos deterministas, el \nsiguiente estado del medio ambiente \nestá totalmente determinado por la \nacción realizada en el estado actual. Al \nejecutar una acción específica, el \nresultado o estado siguiente del \nentorno es predecible de manera \nprecisa y no hay incertidumbre \ninvolucrada \n(Samuel, \n1959). \nLa \nrelación causa-efecto entre las acciones \ndel agente y los estados del entorno, \nnos indica, que cualquier acción que el \nagente realice tiene un resultado \nespecífico y directo en el entorno. \no Ayudante \nde \nmatemáticas \no Juego de ajedrez \no Laberinto \nsin \nobstáculos móviles \no Operaciones \nmatemáticas \no Control de sistemas \nfísicos \nEstocástico \n   En los entornos estocásticos, el \ncambio del entorno está sujeto a cierto \ngrado de aleatoriedad o incertidumbre \ndebido a las acciones del agente; \naunque el agente tome una acción \nespecífica, el resultado o estado \nsiguiente \ndel \nentorno \nno \npueda \npredecirse con total certeza, este puede \nvariar debido a factores aleatorios o no \ncompletamente \nconocidos \nasí \nse \no Robot que juega al \nfutbol. \no Robot clasificador \nde baldosas \no Mercados \nfinancieros \no Tráfico de vehículos \no Clima \no Juego de póker",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n34 \nconozca el estado actual.  \n   Debido a la incertidumbre presente \nen \nel \nentorno \nestocástico, \nla \nprobabilidad \nde \nlos \ndiferentes \nresultados puede modelarse utilizando \nmodelos probabilísticos para tomar \ndecisiones informadas y racionales. \nEstratégico \n   En los entornos estratégicos, el \nmedio ambiente es determinista para el \nagente, lo que significa que el estado \nsiguiente \ndel \nentorno \nestá \ncompletamente determinado por las \nacciones del agente.  \n   Al existir otros agentes en el entorno \nse \nintroduce \ncierto \nnivel \nde \nincertidumbre estratégica, debido a que \nlas acciones de los otros agentes \npueden influir en el estado siguiente \ndel entorno de manera impredecible; \nesto requiere que el agente considere \ndiferentes \nestrategias \ny \ntome \ndecisiones adaptativas para enfrentar \nlos posibles resultados de las acciones \nde los otros agentes.  \n   Para lograr el agente sus objetivos en \nestos entornos que son dinámicos y \ncompetitivos, deben poder analizar y \nanticipar las acciones de los otros \nagentes. \no Juego del veintiuno \n(black jack) \no Ajedrez \no Poker \no Negociación \ny \nsubastas \no Competencia \nempresarial \no Estrategia militar \no Videojuegos \nde \nestrategia en tiempo \nreal (RTS) \no Planificación \nlogística \no Sistemas de gestión \nde tráfico \no Simuladores \nde \nvuelo \n \n \nEpisódico \n   En un entorno episódico, cada estado \nen el que se encuentra el agente no \ndepende de los estados anteriores, por \no Búsqueda \nen \nlaberintos \no Robot \nclasificador",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n35 \nlo que una acción realizada en un \nestado no tiene influencia en los \nestados futuros, cada estado constituye \nun episodio atómico. El agente no tiene \nuna memoria de larga duración y cada \ninteracción con el entorno se considera \ncomo \nun \nepisodio \nseparado \ne \nindependiente.  \n   Para la toma de decisiones y realizar \nacciones el agente se basa únicamente \nen la información disponible en el \nestado actual, sin tener en cuenta el \nhistorial de estados o acciones pasadas. \n   Esto simplifica el modelado y la \nsolución de problemas en entornos en \nlos que la secuencia de acciones no \ntiene una influencia acumulativa en los \nresultados futuros. \nde baldosas \no Recolección \nde \nobjetos \no Juegos \nde \ncartas \ncomo el Solitario \no Juegos \nde \nplataformas (Super \nMario Bros) \no Juegos de escape \no Simulaciones \nde \nemergencias \no Juegos \nde \nrol \n(Dungeons \n& \nDragons) \no Juegos de lógica y \nacertijos \n \n \nSecuencial \n   En los entornos secuenciales, las \ndecisiones tomadas en un momento \ndado pueden afectar a las decisiones y \nresultados \nfuturos, \ncada \nestado \ndepende del histórico anterior.   \n   El agente debe evaluar no solo el \nimpacto inmediato que tienen sus \nacciones, sino también   considerar \ncuidadosamente las consecuencias de \nsus acciones y tomar decisiones \nestratégicas \npara \nmaximizar \nsu \nrendimiento total en el transcurso del \ntiempo.  \n   La secuencialidad y la necesidad de \no Navegación en un \nentorno \ndesconocido \no Juegos de ajedrez \no Toma de decisiones \nen tiempo real \no Robot que juega al \nfutbol \no Ayudante \nde \nmatemáticas \no Juego del veintiuno \n(Black jack) \no Sistemas de control \nde inventario",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n36 \nplanificación a largo plazo hacen que \nestos entornos de trabajo sean más \ndesafiantes y requieran algoritmos y \nenfoques especializados para la toma \nde decisiones y el control inteligente \ndel \nagente, \nque \nmaximice \nlos \nresultados positivos a lo largo del \ntiempo. \no Planificación \ny \nprogramación \nde \nrutas \no Juegos de aventuras \no exploración \n \nEstático \n   En un entorno estático, mientras el \nagente delibera sobre la acción \nsiguiente el entorno no cambia. El \nagente no tiene que enfrentarse con \ncambios inesperados o dinámicos en su \nentorno mientras toma decisiones o \nrealiza acciones. Los entornos estáticos \nson más fáciles de entender y predecir, \nfacilitando el diseño de los agentes y \nalgoritmos \nque \nfuncionan \neficientemente en estos entornos. \no Juego del veintiuno \n(Black jack) \no Rompecabezas \no Laberinto \no Clasificación \nde \nimágenes \no Sistemas \nde \ndetección de spam \no Sistemas de filtrado \nde contenido \no Sistemas \nde \ndiagnóstico médico \no Sistemas \nde \nrecomendación \nde \nproductos \no Análisis de datos \nfinancieros \n \nDinámico \n   En los entornos dinámicos, el \nentorno puede experimentar cambios \nmientras el agente está considerando la \nacción futura que va a realizar. Estos \ncambios pueden ser el resultado de \neventos externos, interacciones con \notros agentes o incluso como resultado \no Robot que juega al \nfutbol \no Robot clasificador \nde baldosas \no Tráfico \nde \nvehículos \no Juego de ajedrez",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n37 \nsus propias acciones. \n \n   El agente, debe poder adaptarse y \ntomar decisiones en tiempo real a \nmedida que el entorno evoluciona.  \nDebe \nser \ncapaz \nde \ndetectar \ny \ncomprender los cambios en su entorno, \nactualizar su conocimiento y ajustar su \ncomportamiento en consecuencia. \n   Para hacer frente a los entornos \ndinámicos, los agentes utilizan técnicas \ncomo la monitorización constante del \nentorno, la detección de cambios, la \nplanificación en tiempo real y el \naprendizaje adaptativo. Estas técnicas \nhacen que el agente tome decisiones \ninformadas y adapte su estrategia a los \ncambios del entorno. \no Simulaciones \nde \nvuelo \no Sistemas \nde \natención \nmédica \npersonalizada \no Sistemas \nde \nrecomendación \npersonalizada \no Sistemas \nde \nsimulación de vida \nartificial \no Sistemas de gestión \nde energía \no Sistemas \nde \nlogística \ny \ndistribución \n \nSemiestático \n   El \nentorno \nsemiestático \nno \nexperimenta cambios significativos, se \nmantiene relativamente constante a lo \nlargo del tiempo en términos de sus \ncaracterísticas \nfísicas \ny \nde \nconfiguración. \nSin \nembargo, \nel \nrendimiento puede variar a medida que \nse desarrolla el agente, esto se debe a la \ncapacidad que tiene de aprender, \nadaptarse y mejorar en el tiempo. \n   El \nagente \npuede \ntambién \nexperimentar mejoras en su capacidad \nde \ntomar \ndecisiones, \nresolver \nproblemas o alcanzar sus objetivos a \no Ayudante \nde \nmatemáticas \no Juegos de mesa \no Sistemas de gestión \nde inventario \no Planificación \nde \nrutas de transporte \no Configuración \nde \nredes \no Sistemas \nde \nrecomendación \nde \ncontenido \no Sistemas de gestión \nde \nrecursos",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n38 \nmedida que adquiere experiencia y \nconocimiento. \n   Los \nagentes \npara \nmejorar \nsu \nrendimiento \nutilizan \ntécnicas \nde \naprendizaje automático, optimización \ny toma de decisiones basadas en datos. \nnaturales \no Sistemas \nde \nplanificación urbana \no Sistemas \nde \noptimización \nde \nenergía \no Sistemas \nde \natención al cliente \n \n \nDiscreto \n   En los entornos discretos, el conjunto \nde estados, las acciones y percepciones \nque puede experimentar el agente, \ncomo el espacio de búsqueda, son \nfinitos y claramente definidos. El \nagente tiene un número limitado y \nespecífico de estados en los puede \nencontrarse, así como tambien un \nconjunto definido de acciones y \npercepciones que puede realizar y \nrecibir. \n   La discreción en los entornos \nproporciona una estructura clara y bien \ndefinida, que facilita la modelización y \nel análisis del comportamiento del \nagente. Los estados, acciones y \npercepciones se pueden representar \nmediante \nvariables \ndiscretas \no \ncategorías específicas, que simplifica \nel diseño y la implementación de \nalgoritmos y estrategias de toma de \ndecisiones. \n   Al tener un número finito de estados, \nacciones y percepciones, es posible \no Ayudante \nde \nmatemáticas \no Juego del veintiuno \n(Black jack) \no Juego de ajedrez \no Sistema \nde \nnavegación en una \ncuadrícula \no Solución de puzles \no Juego de laberintos \no Juego de estrategia \npor turnos \no Juego de palabras \no Tres en raya \no Juego de damas \no Solución \nde \ncrucigramas \no Simulación de vida \nartificial \no Simulación \nde \ntráfico peatonal \no Control \nde \ninventario \no Sistemas de control",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n39 \nrealizar \nun \nmapeo \ndetallado \ny \nsistemático de todas las posibles \ncombinaciones, lo que permite una \nplanificación precisa y una evaluación \ncompleta de las estrategias del agente. \n   La naturaleza discreta de los entornos \nproporciona una base sólida para la \naplicación de técnicas matemáticas, \nalgoritmos de búsqueda, optimización \ny aprendizaje. Esto incluye métodos \ncomo \nlos \nárboles \nde \nbúsqueda, \nalgoritmos de programación dinámica \ny técnicas de aprendizaje automático \nbasadas en modelos discretos. \nde producción \n \n \nContinuo \n   En los entornos continuos, el número \nde estados posibles es extremadamente \namplio e incluso infinito. En el \ntranscurso del tiempo, los estados del \nmedio ambiente experimentan cambios \ncontinuos, esto hace que la percepción \ndel agente en cada instante sea única y \nvaríe \nde \nforma \ncontinua. \nEn \nconsecuencia, el agente se ve obligado \ntomar decisiones y acciones continuas \npara adaptarse y responder a estos \ncambios dinámicos. \n   Dado que el número de estados es \nextenso, resulta imposible mapear y \nexplorar exhaustivamente todas las \nposibilidades. Para poder abordar \nproblemas en entornos continuos es \nnecesario utilizar enfoques basados en \no Robot que juega al \nfutbol. \no Robot clasificador \nde baldosas. \no Sistema de control \nde vuelo de un avión \no Brazo robótico \no Sistema \nde \nnavegación \nautónoma \nde \nvehículos \no Simulaciones \nde \nfísica \no Control de procesos \nindustriales \no Gestión de carteras \nde inversión \no Control de sistemas",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n40 \ntécnicas como el análisis de funciones \nde valor, algoritmos de optimización \nnumérica y métodos basados en \nmodelos probabilísticos; que permiten \nrepresentar y aproximar los estados y \nacciones de manera continua, esto \nfacilita la toma de decisiones mediante \nla maximización de una función \nobjetivo o la adaptación a patrones y \ncambios en el medio ambiente. \n   En \nlos \nentornos continuos, \nel \naprendizaje \ny \nla \nadaptación \nes \nimportante. Los agentes inteligentes \ndeben ser capaces de aprender de la \nexperiencia y mejorar sus acciones en \nfunción \nde \nla \nretroalimentación \ncontinúa proporcionada por el entorno \n(Gelfond & Kahl, 2014).  \n   Es necesario el uso de técnicas de \naprendizaje automático y algoritmos de \ncontrol adaptativo para ajustar y \nmejorar su rendimiento a medida que \ninteractúan con el medio ambiente. \nde \nenergía \nrenovable \no Robot \nde \nmanipulación \nde \nobjetos \no Sistema de control \nde tráfico aéreo \no Simulaciones \nde \nfluidos \no Optimización \nde \ncarreteras \ny \ntransporte \no Sistemas \nde \nrecomendación \npersonalizados \no Control de sistemas \nde \nenergía \nrenovable \nAgente individual \n   En los entornos de agente individual, \nsolo un agente interactúa de manera \nautónoma con el medio ambiente. Por \nlo tanto, no hay necesidad de \ninteracción o colaboración directa con \notros agentes, centrándose toda la \nactividad en el agente principal. \n   En estos escenarios, el agente \nindividual asume la responsabilidad \no Asistente virtual en \nun \nteléfono \ninteligente \no Robot de limpieza \no Sistema \nde \nrecomendación de \npelículas \no Agente de comercio \nelectrónico",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n41 \ncompleta de percibir su entorno, tomar \ndecisiones y ejecutar acciones que se \nalinien \ncon \nsu \nobjetivo \ny \nlas \ncondiciones específicas del entorno. La \nausencia de interacciones directas con \notros agentes reduce la complejidad de \nlas dinámicas de interacción y las \nestrategias a considerar. \n   Aunque el agente trabaja de forma \nindividual, puede estar inmerso en \nesenarios donde existen otros agentes \nde forma indirecta, como sistemas \nautomatizados \no \nprogramas \nde \nsoftware que son importantes en la \nconfiguración o en el control del \nentorno. \nAunque \nno \ninteractúan \ndirectamente con el agente principal, \nestos \nelementos \npueden \nafectar \nsignificativamente las condiciones y \nrestricciones del entorno, perjudicando \nlas decisiones y acciones del agente \nindividual. \no Chatbot de servicio \nal cliente \no Robot clasificador \nde baldosas \no Asistente personal \nen un dispositivo \ndoméstico \ninteligente \no Agente \nde \nsalud \npersonal \no Agente \nde \nseguridad \ndoméstica \no Agente \nde \nentrenamiento \nfísico \no Agente \nde \naprendizaje \nde \nidiomas \n \n \n \nMultiagente \n   En los entornos multiagente, están \npresentes dos o más agentes que \ninteractúan \nentre \nsí, \npudiendo \ncompetir, cooperar o una combinación \nde ambos. Estos agentes perseguen \nobjetivos y acciones independientes, \npudiendo generar dinámicas complejas \ny estratégicas en el entorno. \n   En estos entornos, los agentes \npueden tener diferentes niveles de \no Tráfico inteligente \no Simulaciones \nde \npoblaciones \no Robot que juega al \nfutbol \no Ayudante \nde \nmatemáticas. \no Juego del veintiuno \n(Black jack) \no Juegos en línea",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n42 \nconocimiento, \nhabilidades \ny \ncapacidades, que influyan en su \ncomportamiento y toma de decisiones. \n   Los agentes pueden estar equipados \ncon sensores para percibir el entorno y \nactuadores para realizar acciones que \nafecten al entorno. La interacción entre \nlos agentes puede ser directa o \nindirecta, \ny \npuede \ninvolucrar \ncomunicación, \nnegociación, \ncoordinación o competencia. \n   El comportamiento de los agentes \npuede ser determinista o estocástico, \nevolucionado a lo largo del tiempo a \nmedida que los agentes aprenden y se \nadaptan al entorno. \no Sistemas \nde \nnegociación \nelectrónica \no juegos competitivos \no Sistemas \nde \nrecomendación \ncolaborativa \no Sistemas de gestión \ndel tráfico aéreo \no Sistemas \nde \ncoordinación \nde \nrobots en almacenes \no Juegos de estrategia \nen tiempo real en \nlínea \nElaborado por los Autores \n1.7.2 Clases de agentes \nA continuación, se describen algunos de los agentes utilizados en inteligencia \nartificial: \nAgentes inteligentes: Han transformado el diseño de las interfaces de usuario \ninteligentes, cuyo objetivo es reducir la sobrecarga de información del usuario. Para \nlograrlo, utilizan técnicas de filtrado de información basadas en el aprendizaje de las \nnecesidades del usuario y las circunstancias en las que se realizan determinadas acciones \n(Brookshear & Brylow, 2020). Por ejemplo, en las interfaces de correo electrónico, los \nagentes pueden notificar al usuario la llegada de un nuevo correo que le interesa, evitando \nla distracción de en mensajes no deseados. \nLas interfaces inteligentes aplican algoritmos de aprendizaje automático y \nprocesamiento de lenguaje natural en el análisis del contenido de los mensajes, en la \nidentificación de su relevancia y la presentación al usuario de únicamente la información \nmás importante y pertinente. De esta manera, se mejora la eficiencia y la experiencia del \nusuario, al evitar la necesidad de revisar manualmente grandes volúmenes de \ninformación.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n43 \nAgentes sintéticos: Estos agentes han revolucionado los entornos de realidad \nvirtual, especialmente en la industria del entretenimiento, como películas, programas de \ntelevisión y publicidad, permitiendo generar imágenes por computadora que evitan la \nnecesidad de construir maquetas complicadas para efectos especiales o de alquilar \ngrandes cantidades de vestuario para escenas con multitudes. \nLa inteligencia artificial y las técnicas de generación de gráficos por computadora \npermiten simular personajes y objetos virtuales de manera realista, adaptándose a las \nnecesidades de cada producción. La capacidad de trabajo autónomo que realizan estos \nagentes agiliza el proceso de producción y reduce los costos asociados.  \nOfrecen flexibilidad creativa al permitir la generación de mundos virtuales \ndetallados y escenas impactantes que antes serían difíciles o costosas de lograr, han \nabierto nuevas posibilidades en la creación de efectos visuales y en la representación de \nsituaciones complejas. \nAgentes conversacionales: Llamados también Chatterbots son programas \ndiseñados para llevar a cabo conversaciones de forma auditiva o textual. Estos agentes \nencuentran aplicaciones en diversos campos, como el servicio al cliente y la adquisición \nde información. Su objetivo principal es simular la interacción humana y brindar \nrespuestas relevantes y coherentes a través de la identificación de patrones en el lenguaje. \nLos primeros chatterbots fuero Eliza (1966) y Parry (1972) permitían mantener \nconversaciones básicas con los usuarios. En la actualidad debido a los avances en \ninteligencia artificial y procesamiento del lenguaje natural, los modernos chatterbots son \ncapaces de comprender el contexto, analizar el tono y el significado de las palabras, e \nincluso aprender de las interacciones previas para mejorar sus respuestas. \nLos Chatterbots son ampliamente utilizados en aplicaciones de atención al cliente, \nasistentes virtuales y plataformas de chat en línea. Su capacidad para mantener \nconversaciones coherentes y proporcionar información relevante ha demostrado ser una \nherramienta valiosa en la automatización de tareas y en la mejora de la experiencia del \nusuario. \nEl lenguaje de marcas de Inteligencia Artificial (AIML - Artificial Intelligence \nMarkup Language) es un intérprete que se utiliza para construir agentes conversacionales. \nAIML está especialmente diseñado para la creación de agentes de software con capacidad \nde comprensión y generación de lenguaje natural, conocidos como Alicebots. Estos",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n44 \nagentes son capaces de mantener conversaciones con usuarios y proporcionar respuestas \nadecuadas en función de los patrones de entrada definidos en las categorías. \nAgentes móviles: Son agentes que tienen la capacidad de moverse o migrar de un \nhost a otro en un entorno distribuido, poseen autonomía, tienen la capacidad de aprender, \nde percibir su entorno y responder de forma oportuna (Eze, 2022). Estos agentes pueden \nejecutarse en diferentes máquinas sin necesidad de llevar consigo su propio código, lo \nque les permite aprovechar recursos distribuidos de manera eficiente. \nLos agentes móviles son capaces de gestionar grandes volúmenes de información \ny facilitar la comunicación en tiempo real, esto hace que sean adecuados para aplicaciones \nque requieren interacciones dinámicas y respuestas rápidas. Estos agentes se utilizan en \ndiversos contextos, como: supervisión y optimización de tráfico en las redes, sistemas de \nmonitoreo y control, optimización de recursos, distribución de tareas, aplicaciones de \ncolaboración, motores de búsqueda, asistentes personales, aprendizaje en la nube. \nAgentes reactivos simples: Estos agentes toman decisiones basándose únicamente \nen la percepción actual del entorno, sin mantener un estado interno. Su comportamiento \nse basa en respuestas directas a los estímulos del entorno en tiempo real, sin considerar el \npasado ni planificar el futuro de manera explícita. Estos agentes se centran en generar \nrespuestas rápidas y efectivas a situaciones presentes, sin tener en cuenta el historial. \nEstos agentes son adecuados en casos donde el estado actual del entorno \nproporciona suficiente información para tomar decisiones inmediatas. Son eficientes en \ntérminos de tiempo de respuesta y recursos computacionales, debido a que no requieren \nmantener un modelo interno ni realizar un procesamiento exhaustivo de la información. \nEjemplos de agentes reactivos simples son: un termostato inteligente que toma \ndecisiones basándose únicamente en la información actual de la temperatura ambiente, \nun robot seguidor de línea que utiliza sensores para detectar una línea en el suelo y tomar \ndecisiones en tiempo real para seguir la línea. \nAgentes reactivos basados en modelos: Estos agentes mantienen un modelo \ninterno del mundo que utilizan para tomar decisiones. Este modelo es una representación \ninterna del estado del entorno y cómo evoluciona en respuesta a las acciones del agente. \nEstos agentes tienen la capacidad de anticipar los efectos de sus acciones y \nplanificar a corto plazo. Utilizan su modelo interno para simular diferentes secuencias de \nacciones posibles y evaluar los resultados esperados antes de tomar una decisión, esto les",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n45 \npermite considerar las consecuencias a corto plazo y seleccionar la acción que mejor se \nalinee con sus objetivos o criterios de rendimiento. \nLos agentes reactivos basados en modelos son especialmente útiles en entornos \ndonde es necesario planificar y tomar decisiones considerando las consecuencias futuras. \nPor ejemplo, en un juego de ajedrez, el agente puede simular diferentes movimientos y \nevaluar cómo afectarían al tablero y a su posición futura. Esto les permite tomar \ndecisiones estratégicas y anticiparse a las jugadas del oponente (Knott, 2017). \nAgentes basados en objetivos: Estos agentes tienen metas u objetivos bien claros \nde lo que desean alcanzar en su entorno. Se guían por la evaluación de su estado actual \nen relación con dichos objetivos y toman acciones que los acerquen a ellos. \nEstos agentes mantienen un modelo interno del estado del entorno y utilizan este \nmodelo para evaluar qué tan cerca están de alcanzar sus metas. Analizan las posibles \nacciones disponibles y seleccionan la que mejor se alinee con sus objetivos. Esta selección \nse basa en algún tipo de función de evaluación que considera factores como el costo, la \nutilidad o la probabilidad de éxito. \nA medida que el agente toma acciones y su estado cambia, vuelven a evaluar su \nposición en relación con los objetivos y ajustan sus decisiones. También pueden \nconsiderar diferentes opciones y seleccionar la que maximice la probabilidad de alcanzar \nsus metas (MacKay, 2003). \nLos agentes basados en objetivos son muy útiles en entornos en los que se \nestablecen metas claras y los caminos para lograrlas pueden ser diversos. Por ejemplo, en \nun sistema de planificación de rutas, un agente basado en objetivos si tiene como objetivo \nllegar a un destino específico debe considerar diferentes rutas posibles en función del \ntiempo, la distancia o las restricciones de tráfico. \nAgentes basados en utilidad: Estos agentes evalúan las acciones posibles en \ntérminos de su utilidad o valor esperado, tomando decisiones que maximizan dicha \nutilidad. \nLa utilidad representa la medida de satisfacción o beneficio que el agente espera \nobtener al tomar una determinada acción en un estado dado. Cada acción posible se evalúa \nen función de la utilidad esperada, que se ha estimado que proporcionará al agente. \nEstos agentes de inteligencia artificial no se limitan a evaluar únicamente los \nresultados inmediatos de sus acciones; también consideran cuidadosamente las",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n46 \nimplicaciones a largo plazo y las probabilidades asociadas a cada posible resultado (Das, \n2008). Para ello, aplican modelos avanzados o funciones de utilidad que les permiten \ncalcular la utilidad esperada de cada opción de acción, seleccionando aquella que \nmaximice su valor global. \nLa función de utilidad incorpora una variedad de factores, incluyendo los \nobjetivos específicos del agente, los costes asociados a cada acción, los riesgos e \nincertidumbres presentes en el entorno, así como las preferencias propias del agente. \nUtilizando esta función, el agente es capaz de asignar valores numéricos a diferentes \nacciones y realizar comparaciones objetivas entre ellas, lo que le facilita la toma de la \ndecisión más óptima y estratégica dentro del contexto en el que trabaja. \nUn ejemplo de aplicación de agentes basados en utilidad es en sistemas de \nrecomendación, donde el agente busca maximizar la utilidad del usuario ofreciendo \nrecomendaciones personalizadas que se ajusten a sus preferencias y necesidades. \nAgentes basados en conocimiento: Estos agentes utilizan conocimiento experto \no reglas específicas para tomar decisiones, basándose en una base de conocimientos \npreviamente definida. Se trata de agentes que aplican razonamiento lógico y utilizan \nreglas o algoritmos específicos para resolver problemas o responder preguntas. \nEl conocimiento experto proveniente de expertos humanos en un dominio \nespecífico se captura y codifica en forma de reglas o declaraciones lógicas. Este \nconocimiento incluye hechos, reglas, relaciones y restricciones relevantes para el dominio \nen cuestión. \nLos agentes basados en conocimiento utilizan su acervo de información \nespecializada para realizar inferencias complejas y tomar decisiones informadas. \nEmplean técnicas sofisticadas como la lógica proposicional, la lógica de predicados o \nsistemas avanzados basados en reglas para procesar y razonar sobre el conocimiento \nacumulado, conduciéndoles a conclusiones lógicas y fundamentadas. \nEl proceso de toma de decisiones en estos agentes implica una búsqueda \nmeticulosa en su base de conocimientos para identificar reglas o hechos pertinentes a la \nsituación específica. Luego, aplican razonamiento lógico detallado para derivar \nconclusiones coherentes. Estas conclusiones son trascendentales, debido a que guían al \nagente en la selección de acciones más adecuadas o en la generación de respuestas \nprecisas a los desafíos que enfrentan.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n47 \nLos agentes basados en conocimiento son especialmente útiles en dominios en los \nque se dispone de un conocimiento experto bien definido y estructurado. Se utilizan en \nsistemas de diagnóstico médico, asistentes virtuales, sistemas de recomendación o en \ncualquier otro contexto en el que se requiera un razonamiento lógico basado en \nconocimiento específico. \nAgentes multiagente: Son sistemas compuestos por varios agentes individuales \nque interactúan y colaboran entre sí para lograr un objetivo común o resolver un problema \nde manera cooperativa. Cada agente en el sistema es autónomo y puede tener diferentes \ncaracterísticas, habilidades y conocimientos (Eze, 2022). \nLa interacción entre los agentes se llevarse a cabo a través de diferentes \nmecanismos, como la comunicación directa, el intercambio de información, la \nnegociación y la coordinación. Los agentes comparten conocimientos, realizan tareas \nespecíficas, cooperan en la toma de decisiones y coordinan acciones para alcanzar un \nobjetivo conjunto. \nLos sistemas multiagente son utilizados en una amplia gama de aplicaciones, \ncomo la logística, el tráfico inteligente, la gestión de recursos, la robótica colaborativa y \nlos juegos en línea, entre otros. En estas aplicaciones, los agentes trabajan juntos para \nabordar problemas complejos que requieren la colaboración de múltiples entidades. \nAgentes basados en aprendizaje: Representan una categoría avanzada de \nsistemas inteligentes, dotados de la capacidad de auto-mejora y adaptación a través de la \nexperiencia. Estos agentes incorporan algoritmos de aprendizaje automático de última \ngeneración para procesar y aprender de los datos obtenidos de su entorno. \nEl proceso de aprendizaje en estos agentes es sofisticado e implica no solo el \nreconocimiento de patrones y la identificación de relaciones, sino también la extracción \ny análisis profundo de información pertinente de los datos de entrada. Aprenden mediante \nun proceso continuo de retroalimentación, donde comparan los resultados actuales con \nlos objetivos o resultados ideales, y ajustan sus métodos y estrategias en consecuencia. \nCon el tiempo, estos agentes evolucionan y optimizan su comportamiento, \ntomando decisiones cada vez más precisas y efectivas basadas en el cúmulo de \nexperiencias pasadas y el conocimiento acumulado. Esta capacidad de adaptación y \naprendizaje continuo los hace extraordinariamente eficaces en una amplia variedad de \nentornos y aplicaciones.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n48 \nExisten diversos métodos de aprendizaje utilizados por agentes basados en el \naprendizaje, cada uno con características y aplicaciones distintas. En el aprendizaje \nsupervisado, los agentes trabajan con conjuntos de datos etiquetados, aprendiendo a \nclasificar o predecir nuevos datos basándose en ejemplos previos (Xiao, 2022). Por otro \nlado, en el aprendizaje no supervisado, los agentes exploran datos sin etiquetar para \ndescubrir patrones y estructuras ocultas por sí mismos. Mientras tanto, en el aprendizaje \npor refuerzo, los agentes mejoran su rendimiento interactuando directamente con el \nentorno, siendo recompensados o penalizados según las consecuencias de sus acciones. \nLos agentes basados en aprendizaje tienen la notable capacidad de adaptarse y \nperfeccionar su desempeño con la exposición a más datos y experiencias. Estos sistemas \najustan continuamente sus modelos internos y estrategias, optimizando su \ncomportamiento para alcanzar los objetivos. \nEstos agentes encuentran aplicación en una amplia gama de campos, incluyendo \nreconocimiento de voz, visión por computadora, recomendación de productos, análisis de \ngrandes conjuntos de datos y toma de decisiones en tiempo real. Mediante el uso del \naprendizaje automático, estos agentes pueden procesar y aprender eficientemente de \ngrandes volúmenes de datos, adaptándose a entornos y requerimientos en constante \ncambio. \nAgentes basados en reglas: Son sistemas inteligentes que utilizan un conjunto de \nreglas predefinidas para tomar decisiones y realizar acciones en función de la información \ndisponible. Estas reglas pueden estar basadas en conocimiento experto o en reglas lógicas, \ny son diseñadas por expertos en el dominio específico del problema. \nEl funcionamiento de estos agentes se basa en la evaluación de condiciones y la \naplicación de acciones correspondientes. Cada regla consta de una condición o conjunto \nde condiciones que deben ser satisfechas para que la regla se aplique, y una acción que se \nllevará a cabo si se cumplen las condiciones. \nCuando un agente recibe información del entorno, evalúa las reglas una por una \nen orden y verifica si las condiciones de cada regla se cumplen. Si encuentra una regla \ncuyas condiciones se satisfacen, el agente ejecuta la acción asociada a esa regla. Si \nninguna regla se cumple, el agente puede tener una regla predeterminada o una acción \npor defecto a realizar. \nLos agentes basados en reglas son especialmente útiles cuando el dominio del",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n49 \nproblema es bien estructurado y se pueden identificar claramente las reglas que guían el \ncomportamiento del agente. Estos agentes son utilizados en sistemas expertos, donde el \nconocimiento de un experto en un campo específico se codifica en forma de reglas para \nrealizar tareas de diagnóstico, asesoramiento o toma de decisiones. \nAgentes basados en comportamiento: Estos sistemas inteligentes son diseñados \npara emular el comportamiento de seres vivos, ya sea humano u otros organismos. Estos \nagentes se centran en replicar acciones y respuestas específicas en función de estímulos \ndel entorno, con el objetivo de generar un comportamiento realista y coherente. \nEl enfoque principal de estos agentes es la simulación de patrones de \ncomportamiento observados en seres vivos. Estos patrones pueden incluir movimientos, \nreacciones a estímulos, toma de decisiones y acciones que se asemejan a las de \norganismos reales. Para lograrlo, estos agentes suelen utilizar técnicas como los \nalgoritmos de inteligencia artificial y el modelado de sistemas complejos. \nLos agentes basados en comportamiento son comunes en simulaciones y juegos, \ndonde se busca recrear entornos virtuales con comportamientos realistas. Por ejemplo: \njuegos de simulación de vida, juegos de simulación de ciudades o de mascotas virtuales; \nlos agentes basados en comportamiento pueden imitar acciones y respuestas similares a \nlas de los seres vivos para proporcionar una experiencia de juego más inmersiva. \nEstos agentes también se utilizan en aplicaciones de entrenamiento y aprendizaje, \ndonde se busca replicar comportamientos específicos para fines educativos o de \nentrenamiento. Por ejemplo, en simuladores de vuelo, los agentes basados en \ncomportamiento pueden replicar las acciones y reacciones de pilotos reales para enseñar \na los usuarios cómo operar una aeronave. \nAgentes híbridos: Estos agentes son sistemas inteligentes que combinan \ncaracterísticas y técnicas de diferentes tipos de agentes que se mencionaron \nanteriormente. Estos agentes aprovechan las fortalezas de múltiples enfoques para lograr \nun desempeño óptimo en una variedad de situaciones. \nLa idea detrás de los agentes híbridos es capitalizar las ventajas de diferentes \nparadigmas de agente para abordar de manera efectiva problemas complejos y dinámicos. \nPor ejemplo, un agente híbrido puede combinar elementos de agentes reactivos y basados \nen conocimiento. Esto significa que el agente toma decisiones rápidas y eficientes en \nsituaciones conocidas utilizando reglas o conocimiento predefinido, y también puede",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n50 \nadaptarse y aprender de nuevas situaciones utilizando técnicas de aprendizaje automático. \nOtro ejemplo es un asistente virtual en un dispositivo móvil. Este agente puede \nutilizar un enfoque reactivo para responder rápidamente a comandos de voz o preguntas \nfrecuentes, aprovechando patrones y reglas predefinidas. Al mismo tiempo, puede \nincorporar técnicas de aprendizaje automático para mejorar su capacidad de entender el \ncontexto del usuario y brindar respuestas más personalizadas y precisas. \nCada tipo de agente tiene sus propias fortalezas y limitaciones, y la elección del \ntipo de agente adecuado dependerá del problema o la tarea específica que se esté \nabordando. La selección del tipo de agente correcto es fundamental para lograr un \nrendimiento óptimo en sistemas de Inteligencia Artificial. \n1.7.3 Arquitecturas de programas para agentes \nEstas arquitecturas se basan en los objetivos aplicativos del agente. Las \narquitecturas de agentes a ser revisadas son: arquitectura reactiva simple, arquitectura \ndeliberante, arquitectura por finalidad, arquitectura basada en el razonamiento humano, \narquitectura de agente de reforzamiento, arquitectura de agente de aprendizaje profundo, \narquitectura de agente multiagente. \na) Arquitectura reactiva simple \nLa arquitectura reactiva simple es una forma básica de diseño de agentes en la que \nel comportamiento del agente se basa en una correspondencia directa entre el estímulo \nrecibido y la respuesta generada. En esta arquitectura, el agente no posee habilidades de \ntoma de decisiones sofisticadas, sino que simplemente reacciona al entorno en el que se \nencuentra. El agente percibe el entorno a través de sensores y, en función de esa \npercepción, elige la acción más apropiada para interactuar con el entorno. Esta elección \nde acción se realiza mediante reglas de condición-acción (si-entonces), que establecen la \nconexión entre la percepción actual y la acción a tomar. \nEsta arquitectura es adecuada para entornos simples donde las percepciones \nhistóricas no son relevantes y solo se requiere una respuesta inmediata y directa al \nestímulo presente. Puede ser implementada en hardware o mediante software con \nalgoritmos de búsqueda rápidos. \nEs importante destacar que esta arquitectura solo funciona correctamente en \nentornos totalmente observables, es decir, cuando el agente tiene acceso a toda la \ninformación relevante del entorno. Si hay partes del entorno que no son observables,",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n51 \npueden surgir problemas debido a la falta de información completa para tomar decisiones \nprecisas. \n \nFigura 1.8 Arquitectura Reactiva Simple \nElaborado por los Autores \nLa figura 1.8 representa de manera esquemática un agente que utiliza la \narquitectura reactiva simple. Este agente está equipado con sensores que le permiten \npercibir el estado del mundo en el que trabaja, también cuenta con actuadores que le \npermiten llevar a cabo acciones específicas en respuesta a esa percepción. \nEl agente utiliza los sensores para recopilar información sobre el entorno y generar \nuna representación interna del estado actual del mundo. Basándose en esta información, \nel agente consulta las reglas de condición-acción predefinidas que tiene almacenadas. \nEstas reglas establecen condiciones específicas, que cuando se cumplen, indican qué \nacción debe tomar el agente. Una vez que el agente determina la acción adecuada en \nfunción de las reglas de condición-acción, utiliza los actuadores para llevar a cabo esa \nacción en el entorno. Estas acciones pueden incluir manipulación física, interacción con \notros agentes o cualquier otro tipo de respuesta que sea necesaria en ese contexto. \nb) Arquitectura deliberante \nLa arquitectura deliberante, representada en la figura 1.9, es una estructura más \ncompleja que la arquitectura reactiva simple. Esta arquitectura es adecuada para entornos \nparcialmente observables, donde el agente necesita tener en cuenta un historial reciente \nde información para tomar decisiones. \nA diferencia de la arquitectura reactiva simple, el agente deliberante tiene la \ncapacidad de deliberar sobre la acción a realizar en función de la información disponible",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n52 \ny el estado actual del entorno. Para esto, el agente recopila y analiza tanto la información \nsobre la evolución del entorno como las posibles consecuencias de sus acciones. \n \nFigura 1.9 Arquitectura Deliberante \nElaborado por los Autores \n \nEl proceso de selección de acción en un agente de IA puede implementarse a \ntravés de reglas de producción o mediante el empleo de redes neuronales, dependiendo \nde la complejidad del problema y la disponibilidad de información. Las reglas de \nproducción proporcionan un marco lógico y estructurado para evaluar opciones y tomar \ndecisiones, mientras que las redes neuronales, con su capacidad de aprendizaje profundo \ny adaptativo, permiten al agente analizar y procesar una gama más amplia y compleja de \ndatos para seleccionar la acción más pertinente que le permita alcanzar sus objetivos. \nLa arquitectura deliberante, es particularmente valiosa en el manejo de problemas \ncomplejos y en la realización de tareas de planificación avanzada. En esta arquitectura, el \nagente es capaz de ejecutar secuencias de acciones de forma estratégica y calculada, con \nel fin de lograr objetivos específicos dentro de su entorno. Esta capacidad para deliberar \ny planificar a largo plazo es un aspecto importante en el diseño de agentes inteligentes \ndestinados a resolver tareas que requieren un nivel superior de cognición y adaptación \n(Gelfond & Kahl, 2014). \nc) Arquitectura por finalidad \nLa arquitectura por finalidad, representada en la figura 1.10, es una estructura que \nse basa en la idea de que el agente debe tener una comprensión clara de su objetivo final \npara tomar decisiones efectivas en cada estado del entorno. Además de la percepción del \nmundo en cada nuevo estado, es necesario tener información sobre la dirección en la que",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n53 \nel agente desea llegar, de modo que pueda evaluar si los estados intermedios alcanzados \npor las acciones tomadas lo acercarán o alejarán de su objetivo final. \n \nFigura 1.10 Arquitectura por Finalidad \nElaborado por los Autores \n \nEn esta arquitectura, el agente tiene flexibilidad para modificar su conocimiento \ny adaptarse en función de las decisiones que va tomando. El estado actual del entorno se \nactualiza constantemente a través de los sensores del agente, y cuando se identifica una \nacción que se puede realizar, el agente la lleva a cabo mediante el control de sus \nactuadores. \nLas estrategias de búsqueda son un ejemplo concreto de esta arquitectura. El \nagente utiliza técnicas de búsqueda para explorar el espacio de posibles acciones y \nencontrar una secuencia de acciones que lo lleve hacia su objetivo final. A medida que el \nagente recopila información a través de la percepción y realiza acciones, puede evaluar si \nse está acercando o alejando de su objetivo, y ajustar su estrategia en consecuencia. \nd) Arquitectura basada en el razonamiento humano \nLa arquitectura que se muestra en la figura 1.11 es un ejemplo de una arquitectura \nde agente basada en el razonamiento humano. En este caso, el agente opera en un entorno \nparcialmente observable, lo que significa que no tiene acceso completo a toda la \ninformación del entorno. Sin embargo, el agente es capaz de formarse una idea del estado \ndel medio ambiente en el que existe utilizando la información disponible a través de sus \nsensores. \nEn esta arquitectura, el agente tiene objetivos que actúan como su motivación",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n54 \nprincipal para alcanzar una meta deseada. Para lograr esto, el agente necesita seleccionar \nuna o más acciones que modificarán el estado del medio ambiente con el fin de satisfacer \nsu necesidad de alcanzar la meta. Esta toma de decisiones se realiza considerando los \nobjetivos y evaluando cómo cada acción contribuirá a su logro. \n \n \nFigura 1.11 Arquitectura Basado en el razonamiento humano \nElaborado por los Autores \n \nLa arquitectura es especialmente útil cuando existen objetivos conflictivos y se \nrequiere buscar un equilibrio entre ellos para alcanzar la meta deseada. También es \nadecuada cuando hay múltiples objetivos y existe incertidumbre sobre la posibilidad de \nalcanzarlos todos. En tales casos, el agente necesita evaluar las probabilidades de éxito \nde cada objetivo y tomar decisiones que maximicen las posibilidades de alcanzar la meta \ngeneral. \ne) Arquitectura de agente de reforzamiento \nEl agente por refuerzo emplea una técnica de aprendizaje automático que permite \na un agente aprender a tomar decisiones secuenciales óptimas a través de la interacción \ncon su medio ambiente. Las decisiones óptimas el agente las toma mediante la \nmaximización de una recompensa numérica. El agente interactúa con su medio ambiente \ny recibe una señal de recompensa cada vez que realiza una acción. \nEl agente no se guía mediante instrucciones explícitas sobre las acciones a tomar, \nen su lugar, adquiere conocimiento a través de la experiencia y el error. Cada vez que el \nagente realiza una acción, el entorno le otorga una recompensa numérica. La meta del",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n55 \nagente es maximizar la acumulación de estas recompensas a lo largo del tiempo. \nEn el aprendizaje por refuerzo, surge un desafío fundamental: encontrar el \nequilibrio adecuado entre la exploración de nuevas acciones y la explotación de aquellas \nacciones que han demostrado producir recompensas significativas. El agente (figura 1.12) \ndebe aprender a explorar lo suficiente para descubrir estrategias efectivas y luego \naprovechar esas estrategias para maximizar sus recompensas. \n \nFigura 1.12 Arquitectura de agente de reforzamiento \nElaborado por los Autores \nEl agente utiliza una política para determinar qué acción tomar en función de su \nestado actual y de su conocimiento. La política puede ser determinista o estocástica, \ndependiendo de si siempre elige la misma acción en un estado dado o si toma decisiones \nbasadas en probabilidades. \nEl núcleo fundamental del aprendizaje por refuerzo radica en la habilidad de \naprender de manera progresiva a largo tiempo, a medida que se actualizan valores \ndenominados valores de acción o funciones de valor. Estos valores proporcionan una \nestimación de la utilidad prevista al ejecutar una acción específica en un estado particular. \nDentro del campo del aprendizaje por refuerzo, se encuentran diversos algoritmos \ndestacados, como Q-learning, SARSA, DDPG (Deep Deterministic Policy Gradients) y \nA3C (Asynchronous Advantage Actor-Critic). Cada uno de estos algoritmos se \nespecializa en abordar aspectos específicos del aprendizaje por refuerzo, como la \nexploración, la estimación de valores y política de actualización. \nf) Arquitectura de agente de aprendizaje profundo \nEsta arquitectura (figura 1.13) representa una categoría avanzada de enfoques en",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n56 \nla inteligencia artificial, fundamentada en el uso de redes neuronales profundas o DNN \n(Deep Neural Networks). Estas redes, compuestas por múltiples capas de neuronas \nartificiales interconectadas, están diseñadas para aprender de grandes volúmenes de datos \ny realizar tareas específicas de manera autónoma (Haykin, 2009). Imitando la \ncomplejidad del cerebro humano, estas redes permiten a las máquinas identificar \npatrones, realizar predicciones y resolver problemas complejos sin necesidad de \nintervención humana directa. El aprendizaje profundo, impulsado por estas redes, ha \nrevolucionado campos como el procesamiento de lenguaje natural, la visión por \ncomputadora, la generación de texto, los videojuegos, la traducción automática, la \nrobótica, la toma de decisiones y las simulaciones avanzadas. \nUna Red Neuronal Profunda se estructura en múltiples capas de neuronas \nartificiales. Cada capa consiste en un conjunto de neuronas, también conocidas como \nnodos o unidades, y se clasifican generalmente en tres categorías: la capa de entrada, una \no varias capas ocultas, y la capa de salida. La profundidad de estas redes se define por el \nnúmero de capas ocultas presentes entre la entrada y la salida. A mayor número de capas \nocultas, más 'profunda' se considera la red, lo que implica una mayor capacidad para \naprender características complejas y abstractas de los datos. \n \nFigura 1.13 Arquitectura de agente de aprendizaje profundo \nElaborado por los Autores \nLa profundidad en las redes neuronales profundas permite una representación \njerárquica de los datos. A medida que los datos pasan a través de las capas, las \ncaracterísticas y abstracciones se vuelven progresivamente más complejas y abstractas. \nEsto significa que la red puede aprender automáticamente características simples en las \nprimeras capas, como bordes y texturas, y luego construir representaciones más \nabstractas, como formas y objetos, en capas posteriores. \nEntrenar redes neuronales profundas puede ser un desafío computacional, debido \na que la retropropagación de gradientes (el algoritmo utilizado para ajustar los pesos de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n57 \nla red) puede volverse inestable en redes profundas (Kowaliw et al., 2014). Sin embargo, \nse han desarrollado técnicas como la normalización de lotes, funciones de activación \napropiadas y optimizadores avanzados para abordar estos desafíos y permitir el \nentrenamiento eficiente. \nAdemás de las redes neuronales estándar existen las Redes Neuronales \nConvolucionales (CNN) que son excelentes para el procesamiento de datos estructurados \na través de matrices bidimensionales, como la clasificación y segmentación de imágenes \ny las Redes Neuronales Recurrentes (RNN) que son efectivas para datos secuenciales, \ncomo el procesamiento de lenguaje natural (Haykin, 2009).  \nEl Aprendizaje por Reforzamiento Profundo (DRL) es un subcampo esencial en \nel que los agentes emplean redes neuronales profundas para aprender a tomar decisiones \nsecuenciales en entornos interactivos, esto se logra a través de la retroalimentación de \nrecompensas, donde la red es entrenada con el objetivo de maximizar las recompensas \nacumuladas a lo largo del tiempo. \ng) Arquitectura de agente multiagente \nLa arquitectura multiagente (figura 1.14) representa un enfoque innovador y \nfascinante en el campo de la inteligencia artificial y la robótica. Este enfoque se centra en \nel diseño y la implementación de sistemas en los que múltiples agentes, ya sean entidades \nautónomas como robots, programas de software o incluso seres humanos, colaboran para \nalcanzar objetivos tanto individuales como colectivos (Franceschetti, 2018). A través de \nsu interacción y cooperación, estos agentes pueden abordar problemas y ejecutar tareas \ncon mayor eficacia que si operaran de forma aislada. \nEsta arquitectura destaca por su potencial para crear sistemas inteligentes \naltamente adaptativos, capaces de funcionar eficientemente en entornos cambiantes y \nbajo condiciones complejas y dinámicas. Entre sus aplicaciones prácticas más relevantes \nse encuentran el desarrollo de vehículos autónomos, la robótica avanzada, la planificación \nlogística, los sistemas de transporte inteligentes, la gestión de tráfico en ciudades \ninteligentes, la simulación de sistemas complejos y el desarrollo de modelos financieros \nsofisticados. \nCada agente dentro de una arquitectura multiagente opera como una entidad \nautónoma, equipado con sus propias metas y capacidades de toma de decisiones. Esto \npermite que cada agente tome decisiones de manera independiente, basándose en su",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n58 \nconocimiento particular y objetivos individuales, contribuyendo así a la eficacia y \nadaptabilidad del sistema en su conjunto. \n \n \nFigura 1.14 Arquitectura de agente multiagente \nElaborado por los Autores \nTeniendo los agentes objetivos individuales pueden al mismo tiempo trabajar \njuntos para lograr objetivos colectivos. Esta dualidad permite una amplia gama de \naplicaciones, desde sistemas de control de tráfico aéreo, donde los aviones individuales \nbuscan sus rutas óptimas mientras evitan colisiones, hasta sistemas de recomendación en \nlínea, donde los agentes (en calidad de algoritmos de recomendación) trabajan juntos para \nbrindar recomendaciones personalizadas a los usuarios. \nLa comunicación entre agentes es esencial, pueden comunicarse directa o \nindirectamente para compartir información relevante, coordinar acciones y tomar \ndecisiones informadas. La comunicación puede ser unidireccional o bidireccional y puede \nimplicar intercambios de datos, mensajes, señales, eventos o incluso lenguaje natural en \nsistemas más avanzados. La elección de cómo se implementa la comunicación entre \nagentes depende de la aplicación específica y de los requisitos del sistema. En muchas \narquitecturas multiagente, se utilizan múltiples formas de comunicación en combinación \npara permitir una interacción efectiva entre los agentes. La comunicación efectiva es \nesencial para lograr la colaboración y la coordinación entre los agentes y para alcanzar \nlos objetivos individuales o colectivos en un sistema multiagente. \nEn una arquitectura multiagente, la toma de decisiones distribuida es una \ncaracterística clave, pueden tomar decisiones de manera independiente y cooperativa. \nEsto a menudo involucra la coordinación de acciones para evitar conflictos o \nredundancias y para lograr objetivos comunes (Shi, 2019). \nLos agentes pueden aprender y adaptarse a lo largo del tiempo, utilizando técnicas \nde aprendizaje automático y algoritmos de refuerzo para mejorar sus estrategias y tomar",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n59 \ndecisiones más efectivas. Este aprendizaje puede ser individual o colectivo, donde los \nagentes comparten conocimientos. \nEstas arquitecturas son adecuadas para modelar entornos dinámicos donde las \nsituaciones cambian constantemente. Los agentes deben adaptarse y reaccionar en tiempo \nreal a nuevas circunstancias. \nLa escalabilidad es un reto importante en sistemas con un gran número de agentes, \nla arquitectura debe ser eficiente para manejar múltiples agentes y garantizar un \nrendimiento adecuado. \n1.8 \nEl conocimiento \nEl razonamiento humano, que se fundamenta en el conocimiento acumulado para \nderivar conclusiones, sirve como base para el desarrollo de sistemas en el campo de la \nInteligencia Artificial. En IA, la investigación se puede dividir en dos corrientes \nprincipales: la inteligencia simbólica y la inteligencia computacional. \nLa inteligencia simbólica, también conocida como IA tradicional, se enfoca en la \nresolución de problemas mediante un razonamiento basado en conocimientos explícitos. \nEsta vertiente utiliza representaciones simbólicas y reglas lógicas para procesar \ninformación y deducir soluciones. Este enfoque se caracteriza por la programación de \nalgoritmos complejos y la manipulación de símbolos para emular tareas cognitivas. \nPor otro lado, la inteligencia computacional aborda la resolución de problemas a \npartir de la conexión y análisis de datos. Esta corriente incluye técnicas avanzadas como \nredes neuronales artificiales, algoritmos genéticos, sistemas difusos (fuzzy logic), \nprogramación evolutiva y vida artificial (Martinsanz & Peñas, 2005). Estas técnicas se \ninspiran en el funcionamiento de sistemas biológicos y tienen como objetivo replicar su \ncapacidad innata de aprendizaje y adaptación, permitiendo a los sistemas de IA mejorar \ny evolucionar de forma autónoma. \nAmbas categorías de investigación en IA tienen sus propias fortalezas y \naplicaciones. La inteligencia simbólica es efectiva para problemas que se pueden expresar \nen términos lógicos y que requieren razonamiento basado en reglas y conocimiento \nexplícito. Por otro lado, la inteligencia computacional es útil en problemas donde los datos \nson complejos y se requiere un enfoque más basado en el aprendizaje y la adaptación. \nLa Inteligencia Artificial (IA) se puede entender como la ciencia que se ocupa de \nla ingeniería del conocimiento, abordando la representación, adquisición y aplicación del",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n60 \nmismo para resolver problemas reales. En este contexto, la IA actúa como un conjunto de \nideas y enfoques acerca de cómo representar y utilizar el conocimiento, así como el \ndesarrollo de sistemas informáticos que puedan aprovechar dicho conocimiento. \nDesde un punto de vista práctico, la IA se centra en el diseño y construcción de \nsistemas inteligentes capaces de simular el pensamiento humano y tomar decisiones \ninformadas. Esto implica desarrollar algoritmos, modelos y herramientas que permitan \ncapturar el conocimiento de expertos en un dominio particular y utilizarlo para resolver \ntareas complejas. \nDesde la perspectiva científica, la Inteligencia Artificial (IA) se dedica a explorar \ny explicar diversas formas de inteligencia a través de la representación del conocimiento \ny su aplicación en el desarrollo de sistemas informáticos. \nLa representación del conocimiento es un componente trascendente en el campo \nde la Inteligencia Artificial, debido a que se refiere a cómo se almacena y organiza la \ninformación esencial para realizar tareas específicas. Para lograr una representación \neficaz, se utilizan diversas técnicas y herramientas, como estructuras de datos avanzadas, \nontologías, bases de conocimiento y sistemas expertos, adaptándose al dominio específico \ny a los objetivos del sistema (Poole & Mackworth, 2010). \nEl éxito en la construcción de sistemas de IA depende en gran medida de \ndesarrollar representaciones del conocimiento que sean no solo adecuadas sino también \nmanipulables de manera eficiente. Una representación inadecuada impediría una gestión \nefectiva del conocimiento. Esto conlleva la necesidad de seleccionar métodos de \ncodificación de la información que resulten comprensibles y manejables por el sistema \nde IA. \nUna representación del conocimiento bien diseñada es vital para la capacidad de \nun sistema de IA de ejecutar tareas inteligentes, incluyendo el procesamiento de lenguaje \nnatural, la toma de decisiones informadas, la planificación estratégica y la resolución de \nproblemas complejos. Además, una representación bien estructurada es fundamental para \nfacilitar el proceso de aprendizaje automático, permitiendo al sistema adquirir nuevo \nconocimiento y mejorar su desempeño a través de la experiencia. \nLa elección de la representación del conocimiento también está influenciada por \nla naturaleza del problema y el tipo de datos involucrados. Por ejemplo, en problemas de \nprocesamiento de texto, se pueden utilizar técnicas basadas en lenguaje natural y modelos",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n61 \nde lenguaje para representar la información. En problemas de visión por computadora, se \npueden emplear redes neuronales convolucionales para extraer características y \nrepresentar las imágenes. Para tareas de diagnóstico médico suelen utilizarse sistemas \nexpertos basados en reglas, mientras que para aplicaciones de procesamiento de lenguaje \nnatural se prefieren representaciones distribucionales como embeddings o modelos de \nlenguaje. \nLa mayoría de la conducta inteligente se basa en una representación directa del \nconocimiento, para lo cual la lógica formal proporciona un enfoque importante. El \nconocimiento, en especial el llamado conocimiento común (analizar, conjeturar, \npronosticar y decidir), es la base del comportamiento inteligente. \nLa Ciencia Cognitiva abarca el estudio de las percepciones humanas y el \nprocesamiento mental de la información, desde la entrada sensorial hasta la resolución \nde problemas complejos. Esto incluye las actividades intelectuales de individuos y de la \nsociedad en su conjunto, además de la investigación sobre las características tanto de la \ninteligencia humana como de la inteligencia artificial (Shi, 1990). \nConsiderada una base teórica fundamental para la Inteligencia Artificial, la \nciencia cognitiva es un campo interdisciplinario que se ha desarrollado a partir de la \npsicología moderna, ciencias de la Información, neurociencia, matemáticas, ciencia \nlingüística, antropología, filosofía natural y otras disciplinas relevantes. La convergencia \nde estos campos ha permitido una comprensión más profunda de los procesos mentales \ny cognitivos que subyacen a la inteligencia y la toma de decisiones, tanto en humanos \ncomo en sistemas de IA. \nLa ciencia cognitiva proporciona una base teórica sólida para el diseño y \ndesarrollo de sistemas de IA que buscan emular el pensamiento y el comportamiento \nhumano. Al combinar conocimientos sobre el funcionamiento del cerebro, la percepción, \nel lenguaje, el aprendizaje y la memoria, se puede mejorar la capacidad de los sistemas \nde IA para procesar información, aprender de la experiencia y tomar decisiones \ninteligentes. \nEn el ámbito de la IA, la ciencia cognitiva ha influido en la creación de modelos \ny algoritmos inspirados en el funcionamiento del cerebro y los procesos mentales \nhumanos. Por ejemplo, las redes neuronales artificiales están basadas en la estructura y \nfuncionamiento de las neuronas biológicas, y se utilizan para realizar tareas de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n62 \naprendizaje y reconocimiento de patrones. \nEl conocimiento, que representa el conjunto de hechos e información acumulada \npor la humanidad, es un elemento clave en la modelación de los diversos aspectos del \nmundo que nos rodea. Su recopilación y procesamiento son esenciales para facilitar la \ntoma de decisiones adecuadas y oportunas, impulsando a su vez el aprendizaje y la \nadquisición de nuevo conocimiento (Brachman & Levesque, 2004). \nEn el ámbito de la Inteligencia Artificial, el conocimiento adquiere una relevancia \ncrítica. Los sistemas inteligentes se basan en una amplia gama de datos y conocimientos \nprevios para ejecutar tareas complejas y tomar decisiones informadas. La adquisición y \ngestión eficaz del conocimiento son fundamentales para que los agentes de IA puedan \naprender de sus experiencias y mejorar su rendimiento de manera continua. \nLos progresos en el aprendizaje automático y la minería de datos han abierto \nnuevas puertas para los sistemas de IA, permitiéndoles acceder a vastas cantidades de \ninformación y extraer conocimientos valiosos. Modelos avanzados, como las redes \nneuronales, son capaces de analizar datos para descubrir patrones ocultos, lo que les \npermite aprender y adaptarse a nuevas circunstancias. \nEl proceso de aprendizaje en los sistemas de IA es paralelo al proceso de \nadquisición de conocimiento humano. Mediante la exposición a datos variados y la \nexperiencia acumulada, los agentes de IA perfeccionan su rendimiento y alcanzan una \nmayor precisión en sus predicciones y decisiones. \nEl conocimiento puede ser clasificado en tres formas: \n1) Conocimiento declarativo: El conocimiento declarativo es aquel que se almacena \nen la memoria en forma de hechos, conceptos e ideas estáticas, expresadas mediante \nsentencias o proposiciones acerca del mundo que nos rodea. Estos conocimientos se \npresentan como patrones que permiten encontrar relaciones entre fragmentos de \ninformación. Un ejemplo de conocimiento declarativo podría ser la capacidad de \nrecordar el nombre de las personas, números de teléfono, direcciones, entre otros. \nEn el campo de la Inteligencia Artificial, la representación y utilización del \nconocimiento declarativo son esenciales para que los sistemas inteligentes puedan \nacceder a la información relevante y comprender el entorno en el que operan. \nMediante la utilización de patrones y relaciones almacenados, los algoritmos de IA \npueden identificar características significativas, realizar inferencias y resolver",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n63 \nproblemas específicos. Esta forma de conocimiento es fundamental para que los \nagentes inteligentes tomen decisiones adecuadas y actúen de manera informada en un \namplio rango de situaciones (Baral, 2003). \n2) Conocimiento procedimental: Este conocimiento implica la habilidad de realizar \nprocesos o acciones específicas para alcanzar objetivos concretos. Se centra en el \n\"saber hacer\", esencial para ejecutar tareas y resolver problemas eficientemente. \nUn ejemplo cotidiano sería el manejo de operaciones matemáticas básicas, \ncomo sumar, restar, multiplicar o dividir, donde seguimos pasos concretos para llegar \na una solución. Similarmente, aprender a conducir implica dominar una serie de \nprocedimientos y técnicas para manejar un vehículo con seguridad. \nEn el ámbito de la Inteligencia Artificial (IA), el conocimiento procedimental \nes vital para desarrollar sistemas avanzados capaces de realizar tareas complejas. Los \nalgoritmos de IA adquieren este conocimiento a través del entrenamiento con grandes \nvolúmenes de datos y la observación de patrones y ejemplos. Una vez internalizado, \neste conocimiento permite a los sistemas de IA aplicar procedimientos aprendidos \npara solucionar problemas y tomar decisiones en una variedad de contextos, imitando \nla capacidad de adaptación y aprendizaje de un ser humano experimentado. \nEste enfoque no solo mejora la claridad y precisión del texto, sino que también \nincorpora aspectos clave de la IA, como el aprendizaje a partir de datos y la capacidad \nde adaptación, para una comprensión más profunda del conocimiento procedimental \nen este campo. \n3) Conocimiento heurístico: Este conocimiento se refiere a las estrategias y reglas \nempíricas utilizadas por los seres humanos para solucionar problemas complejos y \ntomar decisiones de manera ágil y efectiva. Las heurísticas, consideradas atajos \nmentales, se fundamentan en la experiencia y el juicio práctico, permitiendo alcanzar \nsoluciones adecuadas sin un análisis detallado de todas las posibles alternativas \n(Edelkamp & Schrödl, 2011). \nUn claro ejemplo de conocimiento heurístico es la resolución de \nrompecabezas o acertijos mediante métodos previamente exitosos en situaciones \nanálogas. En la vida cotidiana, este tipo de conocimiento se manifiesta en decisiones \nde compra, donde las personas recurren a reglas prácticas, como preferir marcas \nreconocidas o buscar ofertas, para facilitar sus elecciones.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n64 \nEn el contexto de la Inteligencia Artificial, las heurísticas son igualmente \nsignificativas. Los sistemas de IA pueden incorporar técnicas heurísticas para \noptimizar la búsqueda de soluciones en escenarios complejos, como en el desarrollo \nde algoritmos de búsqueda o planificación. En el aprendizaje automático, los modelos \nde IA a menudo aplican heurísticas para mejorar su rendimiento y eficiencia en el \ntratamiento de datos. \nSin embargo, es necesario reconocer que el conocimiento heurístico, aunque \nprovechoso en numerosas situaciones, puede conducir a sesgos y errores en la toma \nde decisiones. Por ello, se recomienda combinar el uso de heurísticas con un enfoque \nanalítico y metódico cuando sea necesario, buscando un equilibrio entre rapidez y \nprecisión en el proceso de decisión. \n1.9 \nRepresentación del conocimiento \nLa representación del conocimiento en IA y su relación con la ciencia cognitiva \nes profunda y multifacética. Los seres humanos procesan y almacenan información de \ndiversas maneras: mediante imágenes mentales, lenguaje (oral o escrito), \nrepresentaciones gráficas, y más. Este conocimiento puede manifestarse de distintas \nformas, como cadenas de caracteres, o como señales eléctricas o magnéticas en \ncomputadoras. \nEn el contexto de la IA, el desafío radica en la transformación de este \nconocimiento, naturalmente comprensible para los humanos, en un formato accesible y \nutilizable por sistemas de inteligencia artificial. Esto implica codificar el conocimiento \nde tal manera que permita a la IA reconocerlo, procesarlo y, cuando sea necesario, inferir \nnuevo conocimiento a partir de él. \nLa representación del conocimiento en IA típicamente se concreta a través de \nformatos escritos y estructuras de datos específicas, como bases de datos, árboles de \ndecisión o redes semánticas, que facilitan su almacenamiento en sistemas informáticos y \nsu manipulación mediante software. La elección de la forma de representación y las \nestructuras de datos depende tanto del tipo de problema a abordar como de las técnicas \nde inferencia que se utilizarán para resolverlo (Ramirez, 2012). \nEl propósito principal de esta representación es dotar a entidades inteligentes, tales \ncomo programas con bases de conocimientos, de la capacidad para tomar decisiones \ninformadas y adaptativas en su entorno. Esta capacidad no se limita a la mera acumulación",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n65 \nde datos: implica comprender y aplicar relaciones, normas y patrones en contextos \ncambiantes, lo cual es fundamental para el razonamiento, el aprendizaje y la adaptación \nde los sistemas de IA. \nEsta perspectiva ampliada resalta la complejidad de trasladar el conocimiento \nhumano a un formato que sea operativo para la IA, enfatizando la importancia de una \nrepresentación del conocimiento que sea tanto comprensible como funcional para los \nsistemas inteligentes.  \n1.9.1 Métodos de representación del conocimiento \nA continuación, se listan algunos métodos que se utilizan para representar el \nconocimiento en la inteligencia artificial: \na) Las redes semánticas (figura 1.15) se presentan como una herramienta valiosa para \nrepresentar las interconexiones entre varios objetos, conectando conceptos o nodos a \ntravés de relaciones, lo que permite representar información de manera organizada y \nestructurada (Markman, 2013). Este enfoque guarda semejanza con una característica \nfundamental de la memoria humana, en la que se tejen numerosas relaciones, de modo \nque pensar en un concepto puede evocar una multitud de otros. Por ejemplo, si en la \nred semántica se sabe que \"Una ballena es un mamífero\" y \"Un mamífero es un \nanimal\", se puede inferir que \"Una ballena es un animal\". La verdadera fortaleza de \nestas redes radica en su capacidad para facilitar la inferencia a partir del conocimiento \nrepresentado. \n \nFigura 1.15  Red semántica \nElaborado por los Autores \nLas redes semánticas facilitan la interpretación del significado en textos al \nvisualizar las conexiones entre conceptos distintos. Un ejemplo sería representar la \nfrase 'Los gatos cazan ratones' mediante nodos correspondientes a 'gatos', 'cazan' y \n'ratones', delineando claramente las relaciones entre estos elementos.\"",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n66 \nLas redes semánticas se emplean en bases de datos y la web semánticas para \nrepresentar y consultar información (Weller, 2010). Sirven como entrada para \nalgoritmos de aprendizaje automático, facilitando que las máquinas entiendan \nrelaciones entre conceptos. Se puede también utilizar para comprender la relación \nentre diferentes productos o contenidos, por ejemplo, pueden las redes relacionar \npelículas según género, actores y directores. Además, los robots pueden usarlas para \nentender el mundo que los rodea, reconociendo objetos y comprendiendo las \nrelaciones entre ellos. \nb) Los marcos se especializan en describir las propiedades y relaciones de un concepto \nespecífico. Piense en los marcos como \"fichas de información\" de un objeto o concepto \nespecífico. Un marco es esencialmente una estructura de datos que representa un \nconcepto estereotipado. Por ejemplo, un marco para \"automóvil\" podría contener \natributos como \"año\", \"color\", \"modelo\" y \"fabricante\", y especificar relaciones como \n\"Propietario: quien posee el automóvil\" o \"clases de automóvil: sedan, suv, deportivo, \nhatchback, crossover, familiar\".  \nSi tomamos como ejemplo el concepto de \"edificio\", un marco relacionado con \neste término podría incluir aspectos específicos como \"cantidad de niveles\", \"material \npredominante\" y \"fecha de construcción\", y podría formar vínculos como \"ubicado en\" \npara señalar una localización o \"diseñado por\" para mencionar al arquitecto \nresponsable. En contraste, una red semántica enfatizaría las relaciones del concepto \n\"edificio\" con otros términos vinculados, tales como \"ciudad\", \"estilo arquitectónico\" \no \"uso residencial\". Es decir, mientras el marco se enfoca en profundizar en las \ncaracterísticas particulares de un concepto, la red semántica ilustra las interacciones \nde este concepto con otros en un contexto más global. \nLos sistemas expertos utilizan marcos para organizar el conocimiento de un área \ndeterminada. Por ejemplo, en el ámbito médico, el marco \"Enfermedad\" podría \ncontener atributos como síntomas, causas y tratamientos. Dentro del Procesamiento \ndel Lenguaje Natural, los marcos facilitan la comprensión de enunciados; como en \n\"Xavier compró un automóvil\", donde se identifican roles semánticos: comprador \n(Xavier), objeto (automóvil) y acción (comprar). En el diseño de videojuegos, un \nmarco podría caracterizar entidades como \"Personaje\", definiendo aspectos como su \ncontextura o habilidades. En diseño de interfaces, un marco referente a un \"Botón\"",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n67 \npodría especificar su posición, tamaño y función. Finalmente, en robótica se puede \nusar para reconocer y actuar en diferentes esenarios, ejemplo un marco \"Obstáculo\" \nofrecería detalles sobre su forma, tamaño y estrategias para esquivarlo. \nc) La lógica proposicional es la forma más básica de lógica, donde cada proposición \ntiene un valor de verdad. Se utiliza principalmente para hacer inferencias. Una \nproposición es una declaración que puede ser cierta o incorrecta, pero no puede ser \nambas cosas simultáneamente. Por ejemplo, \"Hoy es sábado\" es una proposición \nporque, dependiendo del día, podría ser verdadera o falsa.  \nLa lógica proposicional es esencial en el diseño y análisis de circuitos lógicos en \nelectrónica, en dominios donde las decisiones se pueden tomar basadas en reglas y \nhechos concretos, ejemplo, un sistema que diagnostica enfermedades en base a \nsíntomas: \"Si tiene fiebre y tos, entonces puede tener gripe\". También se aplica en la \nresolución de problemas y juegos de estrategia, como el tres en línea, donde se evalúan \nsituaciones con valores de verdad. Es visible en estructuras de control como “if-else\", \ndonde, por ejemplo, se plantea que \"si el usuario se autentica, entonces puede acceder \nal sistema\". Además, es fundamental en juegos que demandan estrategias y un \nrazonamiento lógico sustentado en normas explícitas. \nd) La lógica de predicados representa el conocimiento a través de proposiciones y \ncuantificadores. Esto permite realizar inferencias lógicas y deducciones formales. Por \nejemplo, a partir de las proposiciones \"Todos los humanos son mortales\" y \"Leonardo \nda Vinci es humano\", se puede inferir que \" Leonardo da Vinci es mortal\". \nEn el ámbito del procesamiento del lenguaje natural, la lógica de predicados se \naplica a la interpretación semántica de las oraciones. Un claro ejemplo es la oración \n\"María quiere a Patricio\" que puede representarse como Quiere(María, Patricio). Las \nconsultas en bases de datos, especialmente con lenguajes como SQL, a menudo se \nbasan en principios de lógica de predicados. un ejemplo sería buscar todos los libros \nde un autor determinado. Esta lógica también es esencial en la planificación automática \ny la solución de problemas, debido a que permite razonar sobre acciones, sus \nprecondiciones y resultados. Lenguajes de programación como Prolog están \nestructurados en base a la lógica de predicados y son ideales para abordar desafíos que \ndemandan razonamiento lógico y exploración (Fraser, 1990).  \nAdemás, es utilizada en la representación de conocimiento en ontologías, donde",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n68 \nse esbozan conceptos y sus interconexiones en un dominio concreto. En el campo de \nla robótica, esta lógica facilita la toma de decisiones y planificación, al razonar sobre \nel estado del entorno, las acciones viables y sus implicaciones. \ne) Las Reglas de Producción, son una forma de representar el conocimiento en sistemas \nexpertos y otras áreas de la inteligencia artificial. Estas reglas tienen una estructura \ncondicional, y se pueden entender como instrucciones que indican qué hacer o qué \ninferir bajo ciertas condiciones. Las reglas tienen el formato \"SI ... ENTONCES ...\". \nPor ejemplo, una regla podría ser: \"SI es mamífero ENTONCES es un animal\". Las \nreglas de producción hacen explícito el conocimiento. Esto permite entender \nfácilmente cómo se toma una decisión o se llega a una conclusión. \nEn la robótica y en el control de procesos industriales, las reglas de producción \nson esenciales para establecer respuestas adaptativas ante condiciones concretas del \nentorno. Al reconocer ciertos patrones, es posible activar reglas que categorizan o \ndeterminan decisiones basadas en esos patrones identificados. En el mundo de los \nvideojuegos, estas reglas modelan las acciones de personajes no jugables y establecen \ndinámicas del juego. En el ámbito de las simulaciones, las reglas de producción \norientan las acciones de los agentes dentro de un sistema virtual. Mientras que en el e-\nlearning, estas reglas guían el proceso educativo, ofreciendo retroalimentación y \nsugerencias al estudiante. \nf) Las Redes Bayesianas son estructuras gráficas en forma de grafos acíclicos dirigidos \nque delinean conjuntos de variables junto con sus interdependencias condicionales, \nderivadas de una factorización de la función de distribución conjunta. Estas redes \npermiten representar y procesar información bajo condiciones de incertidumbre \n(Croitoru et al., 2018). Proporcionan una forma estructurada para analizar cómo \ndiferentes variables se relacionan entre sí y cómo la evidencia o información sobre una \nvariable puede modificar nuestras percepciones sobre otras variables.  \nConsidere tres variables: \"Nublado\", \"Lluvia\" y \"Césped mojado\". En este \nescenario, la probabilidad de que el \"Césped esté mojado\" está influenciada por la \n\"Lluvia\". Sin embargo, \"Nublado\" puede condicionar esta relación, debido a que, si el \ndía está nublado, la probabilidad de lluvia aumenta, y consecuentemente, la del césped \nmojado. \nEn el sector médico, estas redes facilitan la estimación de la probabilidad de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n69 \npadecer una enfermedad considerando diversos síntomas presentes. En el campo de la \ngenética, permiten descifrar las interacciones entre genes y determinar cómo éstos \npueden estar relacionados con determinadas enfermedades. Estas redes son esenciales \nen la detección de anomalías y en sistemas avanzados de reconocimiento facial.  \nGracias a su capacidad de análisis, pueden ofrecer recomendaciones personalizadas de \nproductos o contenidos a los usuarios, tomando en cuenta sus historiales y \npreferencias. Además, son herramientas valiosas para prever y diagnosticar fallos en \nsistemas complejos, tales como redes eléctricas o maquinarias industriales. En \nrobótica, apoyan en la percepción sensorial y en la toma de decisiones cuando los \nrobots se enfrentan a situaciones inciertas. Finalmente, son fundamentales en la \npredicción meteorológica y en la simulación de la propagación de enfermedades \ncontagiosas. \ng) Los Modelos de Markov, son modelos estocásticos matemáticos que representan \nsistemas que evolucionan a lo largo del tiempo donde la probabilidad de transición de \nun estado a otro solo depende del estado actual y no de cómo llegó a ese estado, por lo \nque se utilizan para predecir estados futuros basados en estados actuales, sin tener en \ncuenta su historia pasada. Su característica principal es la \"falta de memoria\". \nCuando se lanza una moneda, tiene una probabilidad del 50% de caer en cara y \nuna probabilidad del 50% de caer en cruz. Si se decide jugar un juego en el que se \nlanza la moneda repetidamente y se registra la secuencia de resultados. Al usar un \nModelo de Markov para predecir el resultado del próximo lanzamiento, solo se basaría \nen el resultado del último lanzamiento. No importaría si, en los últimos 12 \nlanzamientos, se obtuvo 9 caras y 3 cruz. Suponga que el último lanzamiento fue cara. \nSegún el modelo, la probabilidad de que el próximo lanzamiento sea una cara sigue \nsiendo del 50%, y la probabilidad de que sea cruz también es del 50%. El modelo no \n\"recuerda\" los lanzamientos anteriores. En situaciones reales, los Modelos de Markov \npueden abordar sistemas con múltiples estados y con probabilidades de transición entre \nellos mucho más elaboradas. \nEn el ámbito del procesamiento de lenguaje natural, los modelos de Markov son \nempleados para construir y perfeccionar modelos de n-gramas, que son esenciales para \nprever la siguiente palabra en una secuencia textual, basándose en la probabilidad de \naparición de ciertas palabras consecutivas. Estos modelos son igualmente valiosos en",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n70 \nbioinformática, donde se utilizan para la predicción de secuencias de ADN o proteínas, \nasí como para simular las transiciones entre distintos estados conformacionales de una \nmolécula. En el contexto clínico, los modelos de Markov ofrecen una estructura para \ndiseñar modelos de decisión en tratamientos médicos, permitiendo representar las \ntransiciones entre los distintos estados de salud de un paciente y las probabilidades \nasociadas a cada cambio.  \nEn el terreno de las telecomunicaciones, estos modelos facilitan la modelización \ndel tráfico de redes, pronosticando la dinámica de la red bajo variadas condiciones. \nSon también fundamentales en la ciencia de datos aplicada a juegos estratégicos como \nel ajedrez o el póker, donde se analizan y desarrollan tácticas basadas en la \nprobabilidad. La confiabilidad y el mantenimiento de sistemas mecánicos y equipos \ntambién se benefician de la aplicación de modelos de Markov para predecir fallos y \noptimizar programas de mantenimiento. Finalmente, en la robótica, contribuyen a la \nplanificación y optimización de rutas para robots autónomos, adaptándose a nuevos \nentornos y desafíos (Eze, 2022). \nh) Los Árboles de Decisión, son herramientas de soporte a la decisión que utilizan \nun modelo de decisiones y sus posibles consecuencias. Poseen una estructura \ngráfica que emula la toma de decisiones humanas, permitiendo visualizar de \nmanera jerárquica múltiples opciones y sus posibles resultados. En el campo del \naprendizaje automático, los árboles de decisión son un tipo de modelo utilizado \npara clasificación y regresión. Un ejemplo (figura 1.16) pude ser decidir si jugar \nfutbol o no en base a las variables llover y viento.  \nEl nodo raiz podría plantear la pregunta ¿Está lloviendo? Si la respuesta es \nafirmativa, podrías optar por no jugar al fútbol, pero si es negativa, avanzarías al \nsiguiente nodo: \"¿Hay viento?\". En caso de que la respuesta sea afirmativa, \npodrías decidir no jugar debido a que el viento podría influir en el juego; si es \nnegativa, entonces elegirías jugar al fútbol.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n71 \n \nFigura 1.16 Árbol de decisión \nElaborado por los Autores \nLas entidades financieras se valen de árboles de decisión para evaluar la viabilidad \nde conceder créditos, integrando variables como el nivel de ingresos, el historial \ncrediticio y la edad del solicitante. Esta herramienta analítica también se aplica para la \nsegmentación de clientes y la personalización de estrategias publicitarias; por ejemplo, \na un cliente que previamente ha adquirido indumentaria deportiva se le podrían mostrar \nanuncios de calzado deportivo, tras verificar sus compras anteriores.  \nEn el procesamiento de lenguaje natural, los árboles de decisión facilitan la \ninterpretación de palabras pronunciadas por un usuario, considerando elementos \nacústicos y el contexto lingüístico. En el ámbito agrícola, contribuyen a tomar \ndecisiones sobre la selección de cultivos, ponderando factores como las características \ndel suelo, la estacionalidad y la susceptibilidad a enfermedades. Las tiendas online \nimplementan árboles de decisión para sugerir productos, basándose en el análisis del \ncomportamiento de navegación y compras previas de los usuarios. Tambien, en tareas \nde clasificación y regresión, estos modelos pueden discernir, por ejemplo, si un correo \nelectrónico es spam, evaluando sus atributos distintivos. \ni) Las Ontologías, se refieren a una representación formal y estructurada de un conjunto \nde conceptos dentro de un dominio y las relaciones entre esos conceptos. Son utilizadas \nen informática y en la web semántica para estructurar y clasificar información. La web \nsemántica es una extensión de la web actual que busca hacer que los datos sean \ncomprensibles no solo para humanos, sino también para máquinas. Las ontologías \nproporcionan un marco estructurado que permite a las máquinas entender y razonar \nsobre los datos. \nLa web semántica se apoya en ontologías para dotar de significado a los datos de \nInternet, facilitando así que las máquinas procesen y respondan ante consultas de alta \ncomplejidad. Un caso representativo es el proyecto DBpedia, que convierte la \ninformación de Wikipedia en datos estructurados accesibles para interrogaciones",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n72 \nsemánticas. En el comercio electrónico, las ontologías son utilizadas para la \norganización y categorización de productos, posibilitando recomendaciones más \nacertadas y una búsqueda más eficiente para los consumidores. Además, estas \nestructuras son herramientas poderosas para la organización, clasificación y \nrecuperación de información; por ejemplo, pueden vincular términos de distintos \nidiomas o establecer conexiones entre autores, sus obras y temáticas correspondientes. \nEn el ámbito empresarial, las ontologías se emplean para la modelización de \nprocesos de negocio, recursos y servicios, contribuyendo a optimizar la gestión y el \nproceso de toma de decisiones. Son también aliadas en la integración y análisis de \ndatos de diversas fuentes, lo cual es decisivo para el estudio de fenómenos complejos \ncomo el cambio climático. Las ontologías constituyen un pilar en el desarrollo de \nsistemas expertos y asistentes virtuales, al permitir que las máquinas interpreten y \nrazonen sobre dominios específicos. En el sector turístico, se utilizan para modelar y \nrelacionar datos sobre destinos, actividades y alojamientos, entre otros, brindando así \nrecomendaciones personalizadas a los viajeros.  \nj) Las Redes Neuronales Artificiales, son modelos computacionales inspirados en cómo \nfuncionan las redes neuronales biológicas del cerebro humano. Se pueden ver como \nun medio de representar el conocimiento a través de conexiones ponderadas entre \nneuronas que están organizadas. Una neurona recibe uno o más inputs, los procesa y \nproduce un output. Cada conexión entre neuronas tiene un peso asociado, que puede \nser positivo (excitatorio) o negativo (inhibitorio). Estos pesos se ajustan durante el \nproceso de aprendizaje. La distribución del conocimiento a través de la red permite a \nlas redes neuronales artificiales generalizar y hacer predicciones sobre datos nunca \nantes vistos. \nLas Redes Neuronales Artificiales (RNA), y en particular las Redes Neuronales \nConvolucionales (CNN), son fundamentales en la identificación de objetos dentro de \nimágenes, el reconocimiento facial y el diagnóstico médico mediante el análisis de \nimágenes clínicas. Por otro lado, las Redes Neuronales Recurrentes (RNN), junto con \nlos modelos de atención y las arquitecturas Transformer, se destacan en aplicaciones \nde procesamiento del lenguaje natural, tales como la traducción automática, la creación \nde contenido textual y el análisis de sentimiento. Además, las RNA son trascendentales \nen el desarrollo de asistentes virtuales y en la transcripción automática de señales de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n73 \naudio.  \nEn la robótica, son pieza clave para el procesamiento de datos sensoriales y la \ntoma de decisiones en vehículos autónomos (Eze, 2022). En el sector de la salud, las \nRNA permiten el reconocimiento y diagnóstico preciso de enfermedades a través de \nimágenes médicas, el análisis de secuencias genéticas y la identificación de patrones \nen registros de salud electrónicos. Específicamente, las Redes Generativas Adversarias \n(GAN) tienen la notable capacidad de generar imágenes, música y textos \nindistinguibles de aquellos creados por seres humanos, abriendo así nuevas fronteras \nen la creación de contenido digital. \nk) Los Marcos Temporales, son sistemas de representación de conocimiento que se \nenfocan específicamente en capturar y manejar la información relacionada con el \ntiempo, como eventos que ocurren antes, después o durante otros eventos. La \ntemporalidad es una dimensión importante en muchos sistemas y aplicaciones, y \nentender las relaciones temporales entre eventos puede ser vital para decisiones, \nrazonamientos y predicciones. Se aplican en la elaboración de planes, en los cuales es \nesencial saber qué tarea precede o sigue a otra para asignar recursos o tiempo de \nmanera efectiva.  \nEn el ámbito médico, la comprensión detallada de la cronología de los síntomas y \nlos tratamientos es esencial para el diagnóstico y la terapia adecuados, lo que subraya \nla importancia del análisis de series temporales. Estas series son igualmente críticas en \nla organización y secuenciación de tareas según la temporalidad, como ocurre en la \nlogística del transporte o en la programación de la producción industrial. En el terreno \nde los videojuegos y las simulaciones, los agentes informáticos emplean marcos \ntemporales para determinar acciones, basándose en la interpretación de eventos \nanteriores, actuales y proyectados. Las bases de datos especializadas en series \ntemporales son importantes en la gestión de datos dinámicos, como en el seguimiento \nde transacciones financieras o en el mantenimiento de registros médicos. Este tipo de \nanálisis temporal es también fundamental en sistemas de reservación, como los de \nhoteles y vuelos, que gestionan la disponibilidad y las reservas en distintos períodos. \n En la industria, se utiliza para monitorear y evaluar el flujo de datos de sensores \ny actuadores a lo largo del tiempo, proporcionando así información valiosa para el \nmantenimiento y la optimización de procesos. Además, es instrumental para el",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n74 \nseguimiento y análisis de variables ambientales, permitiendo una mejor respuesta \nfrente a fenómenos como el cambio climático.  \nLos marcos temporales facilitan la estructuración y secuencia de eventos en \nnarrativas, ya sea en literatura, cine o videojuegos, aportando coherencia y continuidad \na las historias. En situaciones críticas como la gestión de crisis o emergencias, el \nanálisis temporal es vital para tomar decisiones basadas en la evolución de los eventos. \nAsimismo, en la logística, las series temporales son indispensables para rastrear la \ndistribución y entrega de paquetes, asegurando eficiencia y efectividad en la cadena \nde suministro. \nl) La Representación Basada en Casos, en lugar de utilizar reglas generales, esta \nrepresentación utiliza casos específicos o ejemplos previos para tomar decisiones, se \nresuelve nuevos problemas basándose en soluciones a problemas anteriores. Si un \nproblema fue resuelto en el pasado, una situación similar en el presente puede ser \nabordada de manera similar, con algunas adaptaciones si es necesario. Si la solución \nes exitosa, el nuevo problema y su solución se almacenan como un nuevo caso en la \nbase de casos.  \nEl razonamiento basado en casos (RBC) es una herramienta poderosa en la \nmedicina, debido a que permite a los doctores acceder a un repositorio de casos \nclínicos previos, analizando síntomas y diagnósticos similares para optimizar el \nproceso de diagnóstico actual. En el ámbito corporativo, las empresas pueden \nimplementar sistemas de RBC para mejorar el servicio al cliente, aplicando soluciones \nefectivas de situaciones pasadas a consultas nuevas.  \nLos ingenieros, al enfrentarse a desafíos de diseño, pueden utilizar bases de datos \nde casos anteriores para inspirarse y encontrar soluciones innovadoras a problemas \nactuales. El comercio electrónico se beneficia enormemente del RBC, personalizando \nrecomendaciones de productos para clientes basándose en el historial de compras y \nbúsquedas de usuarios con patrones similares. \nLos urbanistas y arquitectos tienen la posibilidad de consultar proyectos previos \npara informar y enriquecer el diseño y planificación de nuevos espacios urbanos. En \nel contexto educativo, el RBC puede facilitar la personalización del aprendizaje, \nofreciendo recursos y ejercicios ajustados a las necesidades individuales, identificadas \na través de desafíos enfrentados por estudiantes en temas equivalentes. En el ámbito",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n75 \nlegal, abogados y jueces pueden aprovechar el análisis de precedentes legales mediante \nRBC para fundamentar decisiones judiciales o desarrollar argumentos robustos en \ncasos actuales. Las entidades financieras pueden mejorar la precisión en la evaluación \nde solicitudes de crédito al comparar con historiales financieros análogos. Finalmente, \nen la agricultura, el RBC puede ser dignificativo para identificar rápidamente y tratar \nenfermedades o plagas, aplicando estrategias de manejo probadas en situaciones \nsimilares previas, lo que resulta en una gestión agrícola más eficiente y efectiva. \nDebido a la diversidad de formas que puede tomar el conocimiento, los desafíos \ninherentes al desarrollo de una representación del conocimiento son complejos, \ninterrelacionados y dependen de los objetivos específicos. En términos generales, el \nobjetivo es lograr que el conocimiento esté representado de tal manera que: \n1. Capturar generalizaciones significativas que faciliten la extrapolación y \naplicación en distintos contextos, manteniendo la pertinencia y la utilidad a pesar \nde la variabilidad de las situaciones. \n2. Ser accesible y comprensible tanto para los expertos que lo proporcionan como \npara los sistemas que lo procesan, promoviendo una sinergia entre el \nconocimiento humano experto y el procesamiento algorítmico. \n3. Permitir modificaciones y actualizaciones de manera ágil y sin fricciones, \nadaptándose a la evolución del conocimiento y a las nuevas informaciones que \nsurgen continuamente. \n4. Ser aplicable en una amplia gama de situaciones, incluso en casos donde la \ninformación no es completa o exacta, demostrando flexibilidad y robustez en la \ninferencia bajo incertidumbre. \n5. Servir como un filtro eficaz para acotar las alternativas durante la búsqueda de \nsoluciones, optimizando así los procesos de toma de decisiones y resolución de \nproblemas. \nEstos principios buscan que la representación del conocimiento en IA sea una herramienta \ndinámica y adaptativa, capaz de soportar procesos complejos de razonamiento y \naprendizaje automático. \nEn el extenso campo de la inteligencia artificial, la representación del \nconocimiento es un pilar fundamental que adopta diversas formas para abordar distintos \ntipos de información y procesamiento:",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n76 \nEl conocimiento declarativo puede representarse mediante modelos relacionales \nen forma de árboles, grafos o redes semánticas y esquemas basados en lógica que \nincluyen la lógica proposicional y lógica de predicados.  \nEl conocimiento procedimental puede ser representado para su almacenamiento \nmediante gramáticas formales implementadas a través de sistemas o lenguajes \nprocedimentales, sistemas basados en reglas (sistemas de producción), diagramas de \nflujo, máquinas de estado, script. \nEl conocimiento heurístico puede ser representado mediante sistemas basados en \nreglas, árboles de decisión, redes neuronales, algoritmos genéticos, sistemas expertos, \nfunciones heurísticas, agentes basados en conocimiento, mapas cognitivos (Edelkamp & \nSchrödl, 2011). \nLas representaciones prácticas incluyen \nelementos tanto declarativos, \nprocedimentales y en ocasiones heurísticos. \n1.10 Agente basado en conocimiento \nLos agentes basados en conocimiento tienen la capacidad de utilizar el \nconocimiento expresado en formas altamente genéricas, combinando y recombinando la \ninformación para adaptarse a diferentes objetivos. Pueden fusionar el conocimiento \ngeneral con las percepciones en tiempo real para inferir aspectos ocultos del estado del \nmundo antes de tomar una decisión sobre cualquier acción. \nSe puede establecer una analogía entre un agente basado en conocimiento y un \nmédico que realiza un diagnóstico en un paciente, deduciendo una enfermedad que no es \ndirectamente evidente antes de decidir un curso de tratamiento. El médico utiliza su \nconocimiento, que está representado en forma de reglas adquiridas a partir de libros y la \nenseñanza de sus profesores, así como patrones de asociación que no puede describir \nexplícitamente. \nLos agentes basados en conocimiento son flexibles y pueden asumir nuevas tareas \nen forma de objetivos explícitamente definidos. Tienen la capacidad de adquirir \ncompetencias de manera eficiente al acceder y aprender rápidamente del conocimiento \ndisponible en su entorno. Además, son capaces de adaptarse a cambios en su entorno al \nactualizar el conocimiento relevante de manera oportuna. \nEl componente principal de un agente basado en conocimiento es su base de \nconocimiento o KB(Knowledge Based), que es un conjunto de sentencias que representan",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n77 \nalguna aserción acerca del mundo. Cada sentencia se expresa en un lenguaje llamado \nlenguaje de representación del conocimiento. Cuando la sentencia se considera como un \nhecho sin depender de otras sentencias, se le denomina axioma.  \nEl mecanismo para añadir sentencias nuevas a la base de conocimiento y preguntar \nqué se sabe en la base de conocimiento es la inferencia que permite derivar nuevas \nsentencias de las antiguas. En los agentes lógicos basados en conocimiento la inferencia \ndebe cumplir con el requisito esencial de que cuando se pregunta a la base de \nconocimiento, la respuesta debe ser producto del contenido existente en la base de \nconocimiento. El proceso de inferencia no puede inventar cosas a medida que avanzan \nlas deducciones que realiza. \nEl siguiente ejemplo ilustra este concepto. Considerar las siguientes sentencias: \n1. Si no llovió, Patricio visitó hoy a Victoria. \n2. Patricio visitó hoy a Victoria o Benjamín, pero no a ambos. \n3. Patricio visitó hoy a Benjamín. \nEstas tres sentencias constituyen la descripción en el nivel de conocimiento, donde \nsolo se ha especificado lo que el agente conoce y en función de su objetivo se va a \ndeterminar su comportamiento, que en este caso es dar respuesta a la pregunta \"¿hoy \nllovió?\", aunque ninguna de las trese esentencias indica si hoy llovió. Así es como se \npuede hacer: en base a la oración 3 si se sabe que es verdadera, se conoce que Patricio \nvisitó a Benjamín. Mirando la oración 2, se sabe que Patricio visitó a Victoria o Benjamín, \ny por lo tanto podemos concluir que:  \n4. Patricio no visitó a Victoria. \nAhora, mirando la oración 1, se entiende que, si no hubiera llovido, Patricio habría \nvisitado a Victoria. Sin embargo, conociendo la oración 4, se sabe que este no es el caso. \nPor lo tanto, podemos concluir \n5. hoy llovió.  \nPara llegar a esta conclusión, se usa la lógica que se basa en la información \nexistente. Se han usado sentencias que son afirmaciones sobre el mundo en un lenguaje \nde representación del conocimiento, que permite a la IA almacenar el conocimiento y lo \nusa para inferir nueva información. \nUn agente basado en conocimiento se puede desarrollar de manera efectiva al \nproporcionarle el conocimiento necesario. Iniciando con una base de conocimiento vacía,",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n78 \nel diseñador del agente puede introducir sentencias una a una, permitiendo al agente \nadquirir gradualmente la capacidad de operar en su entorno. Este enfoque se conoce como \nel método declarativo para construir el sistema. En contraposición, el enfoque \nprocedimental implica la codificación directa de comportamientos deseados como código \nde programa. \nUn agente exitoso a menudo combina elementos tanto declarativos como \nprocedimentales en su diseño, y el conocimiento declarativo a menudo se puede compilar \nen un código procedimental más eficiente. \nAsimismo, es posible dotar a un agente basado en conocimiento de mecanismos \nque le permita aprender de manera autónoma, generando conocimiento general sobre su \nentorno a partir de una secuencia de percepciones. Un agente de aprendizaje puede ser \ntotalmente autónomo.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n79 \nCAPITULO 2 \n2 FUNDAMENTOS DE LÓGICA Y REGLAS DE PRODUCCIÓN \nLa lógica y las reglas de producción son los pilares fundamentales en el campo de \nla inteligencia artificial, que proporcionan las bases lógicas y algorítmicas que permiten \na las máquinas razonar, tomar decisiones y resolv(Feigenbaum & others, 1977)iente y \neficaz (Feigenbaum & others, 1977). Se exploran a fondo, los fundamentos de la lógica \nque constituye el lenguaje formal que se emplea para expresar declaraciones y razonar \nsobre su verdad o falsedad, y las reglas de producción que permiten automatizar tareas \ncomplejas. Comprender estos conceptos es importante para diseñar sistemas de IA y para \nresolver problemas del mundo real. \nSe parte de la lógica proposicional que se centra en la relación entre proposiciones \nsimples y cómo se combinan para formar proposiciones más complejas mediante \noperadores lógicos.  Luego se avanza a la lógica de primer orden, que permite la \nrepresentación de estructuras más complejas y el uso de variables y cuantificadores para \nexpresar relaciones entre objetos (Brachman & Levesque, 2004a). \nTambién se aborda el concepto de cuantificadores, que permiten cuantificar \nconjuntos de elementos y expresar afirmaciones generales. Esto es esencial para el \nrazonamiento deductivo, que implica llegar a conclusiones lógicas a partir de premisas \ndadas. Se examina las reglas de producción, un enfoque práctico en la IA que se basa en \nel uso de reglas condicionales para tomar decisiones y realizar acciones. Estas reglas son \nesenciales para la automatización de tareas y la toma de decisiones en sistemas \ninteligentes. \n2.1 \nLógica \nLa lógica, como disciplina, tiene sus raíces en Aristóteles, pero fue Leibniz quien \nla desarrolló desde una perspectiva matemática y la denominó \"lógica matemática\". Esta \ndisciplina es esencial en el ámbito de la inteligencia artificial, y su aplicación se extiende \nampliamente a diversas áreas, como semasiología, programación lógica, teoría de \nespecificación de software y validación, bases de datos, representación del conocimiento, \nsistemas inteligentes y robótica. La lógica es fundamental en la construcción y desarrollo \nde sistemas inteligentes y en la comprensión de la inteligencia artificial en general. \nLa lógica en la inteligencia artificial requiere de varias partes:   \nLa sintaxis es importante en la determinación de la corrección formal de todas las",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n80 \nsentencias en un lenguaje, y esta idea es especialmente relevante en el contexto de los \nlenguajes de programación (Körner et al., 2022). Las bases de conocimiento están \ncompuestas por sentencias que se expresan de acuerdo con la sintaxis del lenguaje de \nrepresentación que se utiliza. Como ejemplo, para representar la afirmación \"Juan es el \npadre de Alfonso\" en un lenguaje como Prolog, se utilizaría la siguiente sintaxis: Padre \n(Juan, Alfonso). \nLa semántica trata tarta sobre el significado de las sentencias y su valor de verdad \ncon relación al modelo del mundo en el que existe. Este valor de verdad es de naturaleza \nbinaria, es decir, una sentencia puede ser verdadera o falsa en un modelo de mundo \nespecífico. \nEn el contexto de la representación del conocimiento, como en el ejemplo dado \nPadre (Juan, Alfonso), es importante entender que la verdad de una afirmación puede \nvariar según el modelo del mundo o el contexto en el que se evalúe. En el modelo del \nmundo posible diseñado para un sistema de representación de conocimiento, Padre (Juan, \nAlfonso) puede considerarse verdadero, incluso si no es cierto en el mundo real. Esto \nresalta la idea de que el valor de verdad de una afirmación puede ser diferente en \ndiferentes contextos o modelos de mundo, lo que es fundamental en la lógica y la \nrepresentación del conocimiento. \nEl modelo del mundo es una abstracción matemática que se utiliza para definir la \nverdad o falsedad de cada sentencia en el contexto de la representación del conocimiento. \nEste modelo se expresa mediante variables que pueden tomar diferentes valores, lo que \npermite representar una variedad de situaciones y relaciones. \nEn el ejemplo que estamos analizando, la sentencia Padre (x, y) se utiliza para \nexpresar la relación padre-hijo entre dos variables, x e y. Estas variables pueden tomar \ndiferentes valores, como \"Juan\" y \"Alfonso\" en este caso se tendría que Padre (Juan, \nAlfonso), o cualquier otro par de valores, como en \"Alfonso\" y \"Ximena\" que sería \nexpresado como Padre(Alfonso, Ximena). \nEste enfoque basado en variables y modelos de mundo permite representar y \nrazonar sobre una amplia gama de situaciones y relaciones en la inteligencia artificial y \nla representación del conocimiento. \nEl razonamiento lógico en la representación del conocimiento se basa en la \nrelación de implicación lógica entre sentencias. En notación matemática, esta relación se",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n81 \ndenota como α → β, lo que significa que, si la sentencia α es verdadera, entonces la \nsentencia β también debe ser verdadera. En el contexto de una base de conocimiento que \ncontiene hechos verdaderos que representan un modelo del mundo, se pueden deducir \nnuevas afirmaciones lógicas utilizando reglas y relaciones lógicas. \nEn el ejemplo, si la base de conocimiento contiene las sentencias Padre (Juan, \nAlfonso) y Padre(Alfonso, Ximena), se puede deducir la relación de abuelo siguiendo el \nconcepto de que un abuelo es el padre del padre de una persona. Por lo tanto, se puede \nconcluir que Juan es el abuelo de Ximena, debido a que Alfonso es el padre de Ximena, \ny Juan es el padre de Alfonso. Este tipo de razonamiento lógico es fundamental en la \nrepresentación del conocimiento y la inteligencia artificial para inferir nuevas relaciones \ny conocimientos a partir de la información existente en una base de conocimiento. \nLa solidez del algoritmo de inferencia es fundamental para garantizar que las \nimplicaciones lógicas siempre sean verdaderas y coherentes (García Serrano, 2012). En \nel ejemplo que se menciona, la inferencia de la relación de \"abuelo\" se basa en un \nconcepto sólido y bien definido: que un abuelo es el padre del padre de una persona. Si el \nalgoritmo de inferencia está diseñado correctamente y sigue reglas lógicas sólidas, \nentonces esta deducción será siempre válida y producirá resultados precisos y coherentes. \nLa robustez y la solidez de los algoritmos de razonamiento lógico son aspectos \nclave en la representación del conocimiento y la inteligencia artificial, debido a que \npermiten que los sistemas deduzcan nuevas relaciones y conocimientos de manera \nconfiable a partir de la información disponible en la base de conocimiento. Esto es \nesencial para tomar decisiones informadas y realizar tareas de razonamiento de manera \nefectiva. \nLa completitud es una propiedad importante en un algoritmo de inferencia. Un \nalgoritmo de inferencia completo garantiza que todas las sentencias que están implicadas \nlógicamente en la base de conocimiento se derivarán correctamente. En el ejemplo, si se \ntiene las sentencias Padre (Juan, Alfonso) y Padre(Alfonso, Ximena) en la base de \nconocimiento y se quiere inferir la relación de \"abuelo\", un algoritmo completo debería \nser capaz de derivar que Juan es el abuelo de Ximena, debido a que esto está implicado \nlógicamente por las sentencias dadas. \nLa completitud asegura que no se omita ninguna inferencia válida, lo que es \nesencial para que un sistema de representación del conocimiento sea confiable y preciso.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n82 \nEsto significa que el algoritmo de inferencia considerará todas las posibles derivaciones \nlógicas y no dejará ninguna sin explorar, asegurando que las conclusiones sean \nexhaustivas y coherentes. \nLa denotación es esencial para establecer la conexión entre los procesos de \nrazonamiento lógico y el entorno real en el que se encuentra un agente o sistema. En el \nejemplo que se menciona, la afirmación de que \"Juan es el padre de Alfonso\" y \"Alfonso \nes el padre de Ximena\" tiene una denotación en la vida real, lo que significa que existe \nuna familia en la que estas afirmaciones son verdaderas y reflejan relaciones familiares \nreales. \nLa denotación asegura que las inferencias y conclusiones que se hacen en el \ncontexto del razonamiento lógico sean aplicables y relevantes en el mundo real. Esto \ngarantiza que los sistemas de inteligencia artificial puedan tomar decisiones y realizar \nacciones basadas en un conocimiento que refleja de manera precisa el entorno en el que \noperan. \n2.1.1 Lógica proposicional \nLa lógica proposicional es un sistema formal en el que el conocimiento se \nrepresenta mediante proposiciones, que son afirmaciones o declaraciones que pueden ser \nverdaderas o falsas. Estas proposiciones pueden combinarse de diversas maneras \nutilizando operadores lógicos como \"y\" (conjunción), \"o\" (disyunción) y \"no\" \n(negación). \nLas expresiones resultantes en la lógica proposicional pueden interpretarse como \nreglas de inferencia que preservan la verdad, lo que significa que se pueden utilizar para \ndeducir nuevas afirmaciones verdaderas a partir del conocimiento existente o para \nevaluar la validez de las afirmaciones existentes.  \nEste enfoque formal es importante en la representación del conocimiento y el \nrazonamiento en la inteligencia artificial, donde se utilizan lógicas proposicionales para \nmodelar y resolver problemas de manera lógica y coherente. \nUna proposición es una declaración o una oración declarativa simple que puede \nser evaluada como verdadera o falsa. Por ejemplo, la proposición \"el carro es lujoso\" \npuede ser verdadera o falsa según las características del carro en cuestión y cómo se \ndefina \"lujoso\". Además, una proposición puede negarse, lo que daría como resultado la \nproposición opuesta, en este caso, \"el carro no es lujoso\".",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n83 \nLas proposiciones en la lógica proposicional se utilizan para representar \nafirmaciones y hechos que son la base del razonamiento lógico en la inteligencia artificial \ny otros campos relacionados. \nTabla 2-1 Conectores básicos de la lógica proposicional \nNombre \nConector \nSímbolo \nDisyunción \nOR \n˅ \nConjunción \nAND \n˄ \nNegación \nNOT \n¬ \nImplicación \nIF – THEN \n→ \nBicondicional \nIF-Then en ambas direcciones \n↔ \nElaborado por los Autores \nLas proposiciones pueden combinarse para formar proposiciones compuestas, lo \nque permite un razonamiento más complejo. Esto se logra mediante el uso de conectivos \nproposicionales (Tabla 2-1) que permiten combinar, negar o relacionar proposiciones \nsimples para crear proposiciones más elaboradas. Los conectivos básicos de la lógica \nproposicional son fundamentales en este proceso y se utilizan para construir expresiones \nlógicas. \nLas tablas de verdad (Tabla 2-2) son herramientas importantes para comprender \ncómo se comportan las operaciones básicas de la lógica proposicional y cómo afectan la \nverdad o falsedad de las proposiciones compuestas.  \nEstas tablas muestran todas las combinaciones posibles de valores de verdad para \nlas proposiciones involucradas y el valor de verdad resultante de la proposición \ncompuesta. Son una herramienta esencial para el análisis lógico y la evaluación de la \nvalidez de argumentos lógicos. \nTabla 2-2 Tablas de verdad para operadores lógicos \np \nq \nDisyunción \np ˅ q \nConjunción \np ˄ q \nNegación \n¬p \nImplicación \np→q \nBicondicional \np↔ q \nV \nV \nV \nV \nF \nV \nV \nV \nF \nV \nF \nF \nF \nF \nF \nV \nV \nF \nV \nV \nF \nF \nF \nF \nF \nV \nV \nV \nElaborado por los Autores",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n84 \nEl primer conectivo de la tabla 2-2 llamado disyunción, es cierto si al menos uno \nde los disyuntos es verdadero (p o q), cabe mencionar que existen dos tipos de OR: un \nOR inclusivo y un OR excluyente. En un OR excluyente, p ∨ q es falso si p ∧ q es \nverdadero. Es decir, un OR excluyente se requiere que solo uno de sus argumentos sea \nverdadero y no ambos. Un OR inclusivo es verdadero si cualquiera p, q o p ∧ q es \nverdadero. Un ejemplo puede ayudar a entender lo inclusivo frente a lo excluyente. Or \ninclusivo: “para comer el postre, tienes que limpiar tu habitación o lavar los platos”. En \neste caso, si realiza ambas tareas, seguirá recibiendo postre. Or excluyente: “De postre, \npuedes tomar galletas o helado”. En este caso, no puede tener ambos. El OR excluyente \na menudo se abrevia como XOR y un símbolo común para él es ⊕. \nEl segundo es denominado conjunción, es cierto sólo si las dos sentencias son \nverdaderas (p y q).  Cuando estas dos proposiciones, p y q, están conectadas por ∧, la \nproposición resultante P ∧ Q es verdadera solo en el caso de que tanto p como q sean \nverdaderas, en este caso es el AND de los operadores lógicos de la lógica booleana. \nEl Not (¬) invierte el valor de verdad de la proposición. Así, por ejemplo, si P: \n“Está lloviendo”, entonces ¬P: “No está lloviendo”, la tabla muestra la comparación de \ntodas las posibles asignaciones de verdad a las proposiciones. Esta tabla ayuda a \ncomprender mejor los valores de verdad de las proposiciones cuando se conectan con \ndiferentes conectivos lógicos.  \nEl poder de la lógica proposicional entra en juego en el uso de las formas \ncondicionales, cuyas dos formas más básicas se denominan Modus Ponens y Modus \nTollens. El conectador de implicación puede ser considerado como un condicional \nexpresado de la siguiente forma, si p→q es verdadero, entonces q debe ser siempre \nverdadero. Para los casos en los cuales p es falso, la expresión p→q, es siempre verdadera, \nindependientemente de los valores lógicos que tome q, debido a que el operador de \nimplicación no puede hacer inferencias acerca de los valores de q. \nCuando el antecedente(p) es verdadero, toda la implicación es verdadera en el caso \nde que el consecuente (q) sea verdadero (eso tiene sentido: si está lloviendo y estoy \nadentro de la casa, entonces la oración \"si está lloviendo, entonces estoy adentro de la \ncasa\" es verdadero). Cuando el antecedente (p) es verdadero, la implicación es falsa si el \nconsecuente (q) es falso (si estoy afuera mientras llueve, entonces la oración \"Si está \nlloviendo, entonces estoy adentro\" es falsa). Sin embargo, cuando el antecedente (p) es",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n85 \nfalso, la implicación siempre es verdadera, independientemente del consecuente (q). Esto \na veces puede ser un concepto confuso.  \nLógicamente, no se puede aprender nada de una implicación (p → q) si el \nantecedente (p) es falso. Mirando nuestro ejemplo, si no está lloviendo, la implicación no \ndice nada sobre si estoy adentro o no. Podría ser del tipo de interiores y nunca caminar \nafuera, incluso cuando no llueve, o podría ser del tipo de exteriores y estar afuera todo el \ntiempo cuando no llueve. Cuando el antecedente es falso, se dice que la implicación es \ntrivialmente verdadera. \nBicondicional (↔) es una implicación que va en ambas direcciones. Puedes leerlo \ncomo “si y solo si”. P ↔ Q es lo mismo que P → Q y Q → P juntos. Por ejemplo, si P: \n“Está lloviendo”. y Q: “Estoy adentro”, entonces P ↔ Q significa que “Si está lloviendo, \nentonces estoy adentro”, y “si estoy adentro, entonces está lloviendo”. Esto significa que \npodemos inferir más de lo que podríamos con una simple implicación. Si P es falso, \nentonces Q también es falso; si no llueve, se sabe que tampoco estoy adentro, y esto por \ntanto es también verdadero. \nLa lógica proposicional, permite la asignación de un valor verdadero o falso para \nla sentencia completa, no tiene facilidad para analizar las palabras individuales que \ncomponen la sentencia. Por este motivo, la representación de la sentencia del ejemplo “el \ncarro es lujoso” como proposición sería el_carro_es_lujoso. Si se combina esta \nproposición con otra se pueden expresar conceptos más complejos el_carro_es_lujoso y \ntiene_reconocimiento_de_voz. El problema de esta representación es que no es muy \nexpresiva. \nEl modelo entonces es una asignación de un valor de verdad a cada proposición. \nPara reiterar, las proposiciones son declaraciones sobre el mundo que pueden ser \nverdaderas o falsas. Sin embargo, el conocimiento sobre el mundo está representado en \nlos valores de verdad de estas proposiciones. El modelo es la asignación de valores de \nverdad que proporciona información sobre el mundo. \nPor ejemplo, si P: “Está lloviendo”. y Q: “Es miércoles”, un modelo podría ser la \nsiguiente asignación de valor de verdad: {P = Verdadero, Q = Falso}. Este modelo \nsignifica que está lloviendo, pero no es miércoles. Sin embargo, hay más modelos \nposibles en esta situación (por ejemplo, {P = Verdadero, Q = Verdadero}, donde está \nlloviendo un miércoles). De hecho, el número de modelos posibles es 2 elevado al número",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n86 \nde proposiciones. En este caso, teníamos 2 proposiciones, entonces 2²=4 modelos \nposibles. \nLa base de conocimiento KB es un conjunto de sentencias conocidas por un agente \nbasado en conocimiento. Este es el conocimiento que la IA proporciona sobre el mundo \nen forma de sentencias de lógica proposicional que se pueden usar para hacer inferencias \nadicionales sobre el mundo. \nEn el caso de la vinculación (⊨), si α ⊨ β (α vincula β), entonces en cualquier \nmundo donde α sea verdadero, β también lo será (García Serrano, 2012). Por ejemplo, si \nα: “Es un martes de enero” y β: “Es un martes”, entonces sabemos que α ⊨ β. Si es cierto \nque es un martes de enero, también sabemos que es martes. La vinculación es diferente \nde la implicación. La implicación es un conector lógico entre dos proposiciones. La \nvinculación, por otro lado, es una relación que significa qué si toda la información en α \nes verdadera, entonces toda la información en β es verdadera. \nLa inferencia es el proceso de derivar nuevas oraciones a partir de las antiguas. \nExisten múltiples formas de inferir nuevos conocimientos basados en el conocimiento \nexistente. Primero, considérese el algoritmo de verificación de modelo (Model \nChecking). \n• Para determinar si KB ⊨ α (en otras palabras, responde a la pregunta: “¿se puede \nconcluir que α es cierto en base a nuestra base de conocimientos”) \n  1. Se debe enumerar todos los modelos posibles. \n  2. Si en todos los modelos donde KB es verdadero, α también lo es, entonces KB \nvincula α (KB ⊨ α). \nConsidérese el siguiente ejemplo: \nP: Es un miércoles. Q: Está lloviendo. R: Patricio irá a correr. KB: (P ∧ ¬Q) → R \n(en palabras, P y no Q implica R) P (P es verdadera) ¬Q (Q es falsa) Consulta: R \n(Queremos saber si R es verdadera o falsa; ¿KB ⊨ R?) \nPara responder a la consulta utilizando el algoritmo de verificación de modelos, \nenumeramos todos los modelos posibles (Tabla 2-3). \nTabla 2-3 Modelos posibles \nP \nQ \nR \nKB \nFalso \nFalso \nFalso \n \nFalso \nFalso \nverdadero",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n87 \nP \nQ \nR \nKB \nFalso \nverdadero \nFalso \n \nFalso \nverdadero \nverdadero \n \nverdadero \nFalso \nFalso \n \nverdadero \nFalso \nverdadero \n \nverdadero \nverdadero \nFalso \n \nverdadero \nverdadero \nverdadero \n \nElaborado por los Autores \nLuego, se revisa cada modelo y verificamos si es cierto dada nuestra Base de \nconocimiento. \nPrimero, en nuestra KB, sabemos que p es verdadera. Así, podemos decir que la \nKB es falsa en todos los modelos donde p no es verdadera. \nTabla 2-4 Base de conocimiento en base a P \nP \nQ \nR \nKB \nFalso \nfalso \nFalso \nFalso \nFalso \nfalso \nverdadero \nFalso \nFalso \nverdadero \nFalso \nFalso \nFalso \nverdadero \nverdadero \nFalso \nverdadero \nfalso \nFalso \nVerdadero \nverdadero \nfalso \nverdadero \nVerdadero \nverdadero \nverdadero \nFalso \nVerdadero \nverdadero \nverdadero \nverdadero \nVerdadero \nElaborado por los Autores \nLuego, de manera similar, en nuestra KB, sabemos que Q es falsa. Así, podemos \ndecir que la KB es falsa en todos los modelos donde Q es verdadera. \nTabla 2-5 Base de conocimiento en base a Q \nP \nQ \nR \nKB \nFalso \nfalso \nFalso \nFalso \nFalso \nfalso \nverdadero \nFalso \nFalso \nverdadero \nFalso \nFalso \nFalso \nverdadero \nverdadero \nFalso",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n88 \nP \nQ \nR \nKB \nverdadero \nfalso \nFalso \n \nverdadero \nfalso \nverdadero \n \nverdadero \nverdadero \nFalso \nFalso \nverdadero \nverdadero \nverdadero \nFalso \nElaborado por los Autores \nFinalmente, nos quedamos con dos modelos. En ambos, P es verdadera y Q es \nfalsa. En un modelo R es verdadero y en el otro R es falso. Debido a que (P ∧ ¬Q) → R \nestá en nuestra KB, sabemos que en el caso de que P sea verdadera y Q sea falsa, R debe \nser verdadera. Por lo tanto, decimos que nuestro KB es falso para el modelo donde R es \nfalso y verdadero para el modelo donde R es verdadero. \nTabla 2-6 Base de conocimiento en base a R \nP \nQ \nR \nKB \nFalso \nfalso \nFalso \nFalso \nFalso \nfalso \nverdadero \nFalso \nFalso \nverdadero \nFalso \nFalso \nFalso \nverdadero \nverdadero \nFalso \nverdadero \nfalso \nFalso \nFalso \nverdadero \nfalso \nverdadero \nVerdadero \nverdadero \nverdadero \nFalso \nFalso \nverdadero \nverdadero \nverdadero \nFalso \nElaborado por los Autores \nMirando esta tabla, solo hay un modelo donde nuestra base de conocimiento es \nverdadera. En este modelo, se ve que R también es verdadero. Según nuestra definición \nde vinculación, si r es verdadera en todos los modelos donde KB es verdadera, entonces \nKB ⊨ R. \n2.1.2 Lógica de primer orden \nLa lógica de primer orden o lógica proposicional, aunque eficaz para representar \nconocimientos simples y manejar proposiciones aisladas, enfrenta limitaciones \nsignificativas en escenarios más complejos. Su estructura binaria y la falta de conexiones \nentre proposiciones restringen su capacidad para capturar relaciones y matices detallados \nen el conocimiento.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n89 \nAnte estas limitaciones se desarrolló la lógica de primer orden, una evolución de \nla lógica proposicional. Esta forma lógica más general permite representar todos los \ndetalles expresados en las sentencias de manera más rica y precisa. La lógica de primer \norden es capaz de expresar relaciones, cuantificadores, y reglas más complejas, lo que la \nhace adecuada para representar conocimiento en entornos donde la información es más \nelaborada y las interacciones entre objetos son más sofisticadas. \nEn el ámbito de la inteligencia artificial, la lógica de primer orden juega un rol \nfundamental, proporcionando una base sólida para el desarrollo de sistemas inteligentes. \nSu capacidad para representar conocimientos de manera detallada y estructurada la \nconvierte en una herramienta indispensable para abordar los desafíos de representación \ndel conocimiento en IA. \nLa lógica de primer orden se destaca especialmente en entornos de incertidumbre, \ndonde los agentes inteligentes deben operar con información fragmentada o incompleta \n(Gelfond & Kahl, 2014). Esta lógica ofrece un marco robusto para la interpretación y el \nmanejo de estas situaciones, respaldado por un conjunto de axiomas y reglas bien \ndefinidas. \nLa lógica de primer orden se convierte en un pilar esencial para la inteligencia \nartificial, proporcionando una estructura para la representación del conocimiento que es \nfundamental para el desarrollo de comportamientos inteligentes. \nEn la lógica de primer orden, la construcción del conocimiento se basa en tres \nelementos fundamentales: \nConstantes: Representan los objetos del conocimiento, que pueden ser personas, \nobjetos físicos o conceptos abstractos. Son los elementos básicos sobre los que se \nconstruye el conocimiento. \nPredicados: Son relaciones, cualidades o atributos que se aplican a los objetos del \nconocimiento. Permiten expresar cómo se relacionan entre sí o qué características poseen. \nFunciones: Las funciones en la lógica de primer orden son referencias indirectas \na otros elementos del conocimiento. Pueden utilizarse para representar transformaciones \no cálculos sobre los objetos y predicados. \nEstos tres componentes trabajan en conjunto para representar de manera precisa y \nestructurada el conocimiento en la lógica de primer orden, convirtiéndose en una \nherramienta poderosa para la representación y el razonamiento en la inteligencia artificial.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n90 \nEn la lógica de primer orden, las constantes se utilizan para representar objetos \nindividuales en un dominio, estos objetos deben ser relevantes en el contexto del \nconocimiento que estamos representando. \nEjemplos de constantes podrían ser: \n• Juan \n• Guillermina \n• Bicicleta \n• Automóvil \nCada una de estas constantes se refiere a un objeto específico en el dominio de \nconocimiento y puede utilizarse en sentencias lógicas para expresar relaciones, \npropiedades o hechos que involucran a estos objetos (Brachman & Levesque, 2004). Las \nconstantes son una parte fundamental de la representación del conocimiento en la lógica \nde primer orden. \nEn la lógica de primer orden, los predicados se utilizan para expresar relaciones \nentre objetos o para definir propiedades de esos objetos. Los predicados representan \nafirmaciones sobre el mundo y se combinan con las constantes para formar frases \natómicas que describen hechos o relaciones específicas en un dominio de conocimiento. \nComo ejemplo, se tiene el predicado \"persona\" que se utiliza para definir la \npropiedad de ser una persona. Luego, se aplican este predicado a las constantes \n\"Guillermina\" y \"Juan\" para afirmar que Guillermina y Juan son personas. Estas \nafirmaciones se expresan como frases atómicas en la lógica de primer orden: \nPersona (Guillermina) \nPersona (Juan) \nEstas frases atómicas representan hechos concretos sobre el dominio de \nconocimiento y pueden utilizarse en inferencias y razonamientos lógicos dentro de un \nsistema de lógica de primer orden. \nDe las expresiones anteriores la función es Persona, y el argumento Guillermina \ny Juan. Se puede indicar que ellos se conocen \nConoce(Juan, Guillermina)              expresa: Juan conoce a Guillermina \nConoce(Guillermina, Juan)              expresa: Guillermina conoce a Juan \nTambién se puede expresar: \nPasea_en(Juan, bicicleta)                 expresa: Juan pasea en la bicicleta",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n91 \nConduce(Guillermina, Automóvil) expresa: Guillermina conduce el automóvil \nSi se aplica de la lógica proposicional los operadores booleanos se pueden \nconstruir oraciones más complejas. De esta manera, se toman dos o más frases atómicas \ny con los conectivos se construye una oración compuesta. \nConoce(Juan, Guillermina)  ˄  Conoce(Guillermina, Juan) \n           expresa: Juan conoce a Guillermina y Guillermina conoce a Juan \nPasea_en(Juan, Bicicleta)  ˅ Pasea_en(Juan, Automóvil) \n          expresa: Juan pasea en bicicleta o Juan pasea en automóvil  \nConoce(Juan, Guillermina)  ˄  ¬ Conoce(Guillermina, Juan) \n           expresa: Juan conoce a Guillermina o Guillermina no conoce a Juan \nConoce(Juan, Guillermina)   →  Conoce(Guillermina, Juan)       \n           expresa: Si Juan conoce a Guillermina entonces Guillermina conoce a Juan \nConoce(Juan, Guillermina)   ↔  Conoce(Guillermina, Juan)                  \n              expresa: Juan conoce a Guillermina si Guillermina conoce a Juan \nEn la lógica de primer orden, las variables son herramientas poderosas que \npermiten representar información de manera abstracta y general, lo que facilita la \nformulación de reglas y relaciones que son válidas para una amplia gama de objetos sin \nespecificar los objetos en sí. Esto es especialmente útil en la inteligencia artificial y la \nrepresentación del conocimiento, donde no siempre se conoce de antemano la identidad \nexacta de los objetos involucrados. \nConoce(x, Guillermina)   →  Conoce(Guillermina, x) \nHermano(x, y)  → Padre(z, x) ˄ Padre(z, y) \nLos predicados en la lógica de primer orden tienen un valor de veracidad que \ndepende de los términos específicos que se les asignen. Esto significa que un predicado \npuede ser verdadero para ciertos términos y falso para otros, lo que le brinda una \ncapacidad de expresión muy flexible.  \nEsta característica es fundamental para la representación precisa y abstracta del \nconocimiento en la inteligencia artificial y otros campos. \nLos predicados permiten asignar cualidades abstractas o relaciones entre objetos \no conceptos. Por ejemplo, el predicado \"Conoce (x, y)\" podría representar la relación de \nconocer entre dos personas, donde \"x\" y \"y\" son variables que pueden tomar cualquier \nvalor de individuos. Esto permite representar declaraciones como \"Juan conoce a María\"",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n92 \n(donde \"x\" toma el valor de Juan y \"y\" toma el valor de María) o \"Xavier conoce a \nSilvana\" (donde \"x\" toma el valor de Xavier y \"y\" toma el valor de Silvana). \nLa lógica de primer orden se basa en reglas de inferencia sólidas para el \nrazonamiento lógico. Esta lógica se utiliza para deducir consecuencias verdaderas a partir \nde un conjunto de predicados que se asumen como lógicamente verdaderos, generalmente \ndenominados axiomas o hechos iniciales. \nLas reglas de inferencia son principios lógicos que determinan cómo se pueden \nderivar nuevas afirmaciones o conclusiones de las afirmaciones o premisas existentes. \nEstas reglas aseguran que las inferencias realizadas sean válidas y que las conclusiones \nsean verdaderas si las premisas lo son. Algunos ejemplos de reglas de inferencia en la \nlógica de primer orden incluyen el modus ponens, modus tollens, la introducción de \ncuantificadores y otras. \n2.1.3 Cuantificadores \nLos cuantificadores son herramientas esenciales en la lógica de primer orden para \nexpresar afirmaciones que involucran variables y establecer si son verdaderas para todos \nlos elementos del dominio o al menos para algún elemento. \nEl cuantificador universal (∀) se utiliza para expresar una propiedad que es \nverdadera para todos los elementos del dominio (Van Harmelen et al., 2008). Por \nejemplo, ∀x P(x) puede leerse como \"Para todo x, P(x) es verdadero\". Indica que la \npropiedad P(x) es verdadera para cada elemento x en el dominio. \nEl cuantificador existencial (∃) se utiliza para expresar una propiedad que es \nverdadera para al menos un elemento del dominio (Van Harmelen et al., 2008). Por \nejemplo, ∃x P(x) puede leerse como \"Existe al menos un x para el cual P(x) es verdadero\". \nIndica que la propiedad P(x) es verdadera para al menos un elemento x en el dominio. \nEstos cuantificadores se combinan con predicados para formar expresiones \nlógicas más complejas y precisas. Por ejemplo, se pueden usar en afirmaciones como ∀x \n(P(x) → Q(x)) que se lee como \"Para todo x, si P(x) es verdadero, entonces Q(x) también \nes verdadero\". O ∃x (P(x) ∧ Q(x)) que se lee como \"Existe al menos un x para el cual \nP(x) y Q(x) son verdaderos\". \nLa cuantificación es fundamental en la representación del conocimiento y el \nrazonamiento en la inteligencia artificial y otras áreas de la informática. Permite expresar \npropiedades generales sobre objetos y relaciones entre ellos, lo que es importante para",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n93 \nmodelar situaciones del mundo real de manera precisa y eficiente.  \nEjemplos del uso de cuantificadores: \nA todos los niños les agrada los dulces.     \n∀x  Niño(x) → Agrada(x, Dulces)       \nAlgunos estudiantes se matriculan en inteligencia artificial. \n∃x Estudiante(x) ˄  Matricula(x, IA)    \nHay un cocinero que cocina para todas las personas del barrio que no pueden \ncocinar ellos mismos.  \n ∃x Cocinero(x) ˄  ∀y Persona(y) ˄  ¬ Cocina(y,y)  →  Cocina(x,y) \nPara que dos personas sean hermanos. \n∀x,y Hermano(x,y) →  ∃z  Padre(z,x)  ˄   Padre(z,y) \n2.1.4 Razonamiento \nEl razonamiento es un proceso esencial en la toma de decisiones y la resolución \nde problemas tanto en humanos como en sistemas de inteligencia artificial. El \nrazonamiento lógico y las teorías de razonamiento automatizado son esenciales en \ncampos como la inteligencia artificial, la programación, la verificación de la corrección \nde programas y muchos otros. \nEn el contexto de la lógica de predicados, las inferencias son el proceso de derivar \nnuevas sentencias lógicas o conclusiones a partir de un conjunto dado de sentencias \nconocidas o premisas. Estas inferencias se realizan mediante reglas de inferencia que \ngarantizan la validez y la coherencia de las conclusiones. \nAlgunas de las reglas de inferencia más importantes en lógica de predicados \nincluyen: \nModus Ponens: Si tenemos una afirmación condicional (p → q) y sabemos que la \nafirmación antecedente (p) es verdadera, entonces podemos concluir que la afirmación \nconsecuente (q) también es verdadera. \nModus Tollens: Si tenemos una afirmación condicional (p → q) y sabemos que la \nafirmación consecuente (q) es falsa, entonces podemos concluir que la afirmación \nantecedente (p) también es falsa. \nSilogismo Hipotético: Si tenemos dos afirmaciones condicionales (p → q) y (q → \nr), entonces podemos inferir una nueva afirmación condicional (p → r). \nSilogismo Disyuntivo: Si tenemos una afirmación que es una disyunción (p ∨ q)",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n94 \ny sabemos que una de las disyunciones (p) es falsa, entonces podemos concluir que la \notra disyunción (q) es verdadera. \nCuantificación Universal y Existencial: Utilizando los cuantificadores (∀ y ∃), \npodemos realizar inferencias basadas en propiedades que se aplican a todos los elementos \ndel dominio o al menos a algunos de ellos. \nEstas reglas de inferencia son fundamentales en la lógica de predicados y se \nutilizan para derivar conclusiones válidas a partir de premisas dadas. La aplicación precisa \nde estas reglas es esencial para el razonamiento lógico y la toma de decisiones en sistemas \ninteligentes. \na) Modus ponens.- Es utilizada, en los sistemas basados en conocimiento; si \nsabemos que una implicación y su antecedente son verdaderos, entonces el \nconsecuente también es verdadero, entonces se establece que: \nSi se tiene una afirmación condicional (p → q) y se sabe que la afirmación \nantecedente (p) es verdadera, entonces se puede concluir que la afirmación \nconsecuente (q) también es verdadera. \nEjemplo 1 \n“Hay luz en la lámpara” representa a la sentencia p si esta es verdadera. Si el condicional \nsiguiente es verdadero: “Si hay luz en la lámpara entonces el interruptor está encendido”. \nLa sentencia q “el interruptor esta encendido” es verdadero. En otras palabras, el uso de \nesta regla, permite obtener sintácticamente nuevo conocimiento del viejo conocimiento. \nEn este ejemplo se puede pensar en p como el antecedente y en q como el consecuente. \nEjemplo 2 \nPremisa 1: Si llueve, entonces la calle estará mojada. \nPremisa 2: Está lloviendo. \nConclusión: Por lo tanto, la calle estará mojada. \nEn este caso, se sabe que si está lloviendo (p es verdadero), entonces la afirmación \ncondicional \"Si llueve, entonces la acera estará mojada\" nos dice que la acera estará \nmojada (q es verdadero). \nEjemplo 3 \nPremisa 1: Si estudias para el examen (p), entonces obtendrás una buena calificación (q). \nPremisa 2: Estás estudiando para el examen (p es verdadero). \nConclusión: Por lo tanto, obtendrás una buena calificación (q es verdadero).",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n95 \nEn este caso, la afirmación condicional establece que si estudias para el examen \n(p), entonces obtendrás una buena calificación (q). La premisa 2 nos dice que estás \nestudiando para el examen, lo que significa que p es verdadero. Según el Modus Ponens, \npodemos concluir que obtendrás una buena calificación (q es verdadero) debido a que se \ncumple la condición establecida en la premisa 1. \nb) Modus tollens.- Es una regla de inferencia lógica que opera de manera contraria \nal Modus Ponens. En el Modus Tollens, se parte de una afirmación condicional (p \n→ q), se sabe que la afirmación consecuente (q) es falsa, entonces se puede \nconcluir que la afirmación antecedente (p) también debe ser falsa. \nEl Modus Tollens es una herramienta importante en la lógica y el razonamiento \ndeductivo para evaluar las consecuencias de afirmaciones condicionales y su negación. \nEjemplo1 \nRetomando el ejemplo anterior en el cual se dice que hay luz en la lámpara y el \ninterruptor está encendido. Si se expresa el condicional la lámpara está apagada por lo \ntanto el interruptor está apagado, esto es verdadero, para nuestra forma lógica de pensar, \npero para el caso que estamos tratando q “el interruptor está apagado” es falso, por lo \ntanto, la premisa p “la lámpara está apagada” también es falsa. Se puede observar que es \nel enfoque contradictorio del Modus Ponens. \nEjemplo 2 \nPremisa 1: Si llueve, la calle estará mojada (p → q). \nPremisa 2: La calle no está mojada (¬q). \nConclusión: Por lo tanto, no está lloviendo (¬p). \nEn este caso, se sabe que la calle no está mojada (¬q), se concluye que no está \nlloviendo (¬p) utilizando el Modus Tollens, debido a que la premisa inicial establece que \nsi llueve (p), la calle estará mojada (q). Dado que la calle no está mojada (¬q), podemos \ninferir que no está lloviendo (¬p). \nEjemplo 3 \nPremisa 1: Si el estudiante estudia para el examen, aprobará (p → q). \nPremisa 2: El estudiante no aprobó el examen (¬q). \nConclusión: Por lo tanto, el estudiante no estudió para el examen (¬p). \nEn este caso, si se sabe que el estudiante no aprobó el examen (¬q), se puede \nconcluir que el estudiante no estudió para el examen (¬p) utilizando el Modus Tollens.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n96 \nLa premisa inicial establece que si el estudiante estudia para el examen (p), aprobará (q). \nDado que el estudiante no aprobó (¬q), puede inferir que no estudió para el examen (¬p). \nc) Resolución.- Esta regla permite la creación de una contradicción a través de la \nnegación de la sentencia original, que permite demostrar que la sentencia original \nes verdadera. La resolución es un método de inferencia utilizado en lógica para \ndeterminar la verdad o falsedad de una afirmación basándose en un conjunto de \ncláusulas de conocimiento y una consulta \nEjemplo 1 \nSi (A v B) es verdadero y (¬B v C) es verdadero, entonces (A v C) también es \nverdadero. \nLas sentencias expresan lo siguiente: A = “la lámpara está apagada”, B = “el \ninterruptor está apagado”, C = “el enchufe está desconectado”. Si se niega B = “el \ninterruptor no está apagado”. Entonces A es verdadero, y B es falso, entonces C es \nverdadero. \nEjemplo 2  \nPremisa 1: Si llueve, entonces la calle estará mojada (p → q). \nPremisa 2: La calle no está mojada (¬q). \nConsulta: ¿Está lloviendo? (¬p) \nPara resolver esto, primero convertimos las premisas a cláusulas: \nPremisa 1 (Cláusula 1): ¬p ∨ q \nPremisa 2 (Cláusula 2): ¬q \nAhora, aplicamos la resolución: \n(¬p ∨ q) ∧ (¬q)             [Conjuntamos las cláusulas] \n(¬p ∧ ¬q) ∨ (q ∧ ¬q)    [Distribución] \n(¬p ∧ ¬q) ∨ F               [q ∧ ¬q es F (falso)] \n(¬p ∧ ¬q)                     [Identidad ((¬p ∧ ¬q) ∨ F = (¬p ∧ ¬q))] \nLa resolución nos lleva a la conclusión de que ¬p es verdadero, lo que significa \nque no está lloviendo. \nEjemplo 3 \nPremisa 1: Si el estudiante estudia para el examen, aprobará (p → q). \nPremisa 2: El estudiante no aprobó el examen (¬q). \nConsulta: ¿El estudiante estudió para el examen? (¬p)",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n97 \nConvertimos las premisas a cláusulas: \nPremisa 1 (Cláusula 1): ¬p ∨ q \nPremisa 2 (Cláusula 2): ¬q \nAplicamos la resolución: \n(¬p ∨ q) ∧ (¬q)                 [Conjuntamos las cláusulas] \n(¬p ∧ ¬q) ∨ (q ∧ ¬q)        [Distribución] \n(¬p ∧ ¬q) ∨ F                   [q ∧ ¬q es F (falso)] \n(¬p ∧ ¬q)                          [Identidad ((¬p ∧ ¬q)  ∨ F = (¬p ∧ ¬q))] \nLa resolución nos lleva a la conclusión de que ¬p es verdadero, lo que significa \nque el estudiante no estudió para el examen. \nEn estos ejemplos, la resolución nos permite llegar a la misma conclusión que \nobtuvimos utilizando el Modus Tollens. \nd) Deducción.- Es un tipo de razonamiento que procede lógicamente de lo universal \na lo particular, a partir de premisas verdaderas garantiza conclusiones verdaderas. \nEs la base de la lógica proposicional y de predicados.  \n \nFigura 2.1: Tamaño de recipientes \n        Elaborado por los Autores \nEjemplo 1:  \nSe tienen tres recipientes (figura 1.17) de diferente tamaño x, y, z.   \n Si x es mayor que y y y es mayor que z  \n   entonces se puede deducir que x es mayor que z \nUtilizando los cuantificadores esto se puede expresar como. \n∀𝑥, ∀𝑦, ∀𝑧,[Mayor (x, y)^Mayor (y, z)→ Mayor (x, z)] \nEjemplo 2 \nPremisa 1: Todos los hombres son mortales. (Premisa general) \n∀x(Hombre(x)→Mortal(x)) \nPremisa 2: Platón es un hombre. (Premisa específica) \nHombre(Platón)",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n98 \nConclusión: Por lo tanto, Sócrates es mortal. (Deducción basada en las dos \npremisas anteriores y la regla lógica de que si todos los hombres son mortales y \nSócrates es un hombre, entonces Sócrates también es mortal). \nHombre(Platón) )→Mortal(Platón) \nEjemplo 3 \nPremisa 1: a=b (Premisa) \nPremisa 2: b=c (Premisa) \nConclusión: Por lo tanto, a=c (Deducción basada en las dos premisas anteriores y \nla propiedad transitiva de la igualdad en las matemáticas, que establece que si a=b \ny b=c, entonces a=c). \n(a=b ∧ b=c)→(a=c) \nEn estos ejemplos, la deducción implica llegar a una conclusión lógica o \nmatemática basada en premisas o información previamente establecida. La \ndeducción es un proceso importante en la lógica, donde se utilizan reglas y \nprincipios para derivar conclusiones válidas a partir de información conocida. \n \ne) Abducción.- Es un método de razonamiento utilizado en la generación de  \nexplicaciones, el cual no garantiza que se puedan lograr conclusiones verdaderas, \npor lo tanto no constituye un método sólido de inferencia (Kowalski, 2011). \nEn términos generales se puede expresar:    \n                 Si la sentencia (A→B) es verdadera y B es verdadera,  \n                     entonces A es posiblemente verdadera. \nEn la abducción, se parte de una conclusión y se busca identificar las \ncircunstancias que la justificarían. Es decir, se intenta hallar una razón o causa que \nexplique por qué la conclusión es correcta. Es comúnmente utilizado en \ninteligencia artificial y razonamiento basado en casos, así como en diagnóstico \nmédico y resolución de problemas. \nEjemplo 1 \nSi se tiene una funda con esferográficos de color azul, y junto a la funda \nestán unos esferográficos de color azul, se deduce que proceden estos \nesferográficos de la funda, esto último posiblemente puede ser verdadero. \nEjemplo 2",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n99 \nSupóngase que existe una persona llamada Luis que siempre llega tarde a \nlas reuniones. Un día, Luis llega tarde a una reunión nuevamente. Se puede utilizar \nla abducción para generar una explicación probable de por qué Luis llega tarde. \nLas observaciones son: \nObservación1: Luis llegó tarde a la reunión. \nObservación 2: Luis tiene un largo trayecto en automóvil para llegar al lugar de la \nreunión. \nObservación 3: Hubo un accidente en la carretera principal. \nHipótesis 1: Luis llegó tarde a la reunión por el accidente en la carretera \nprincipal. \nHipótesis 2: Luis llegó tarde a la reunión porque se levanta muy tarde. \nHipótesis 3: Luis llegó tarde a la reunión por ir a dejar a sus hijos al colegio. \nAhora, se puede realizar un razonamiento abductivo para generar una \nexplicación, dada esta información, se podría abducir la siguiente explicación \nprobable: \nLuis llegó tarde a la reunión (O1) porque (H1) hubo un accidente en la \ncarretera principal (O3), lo que causó retrasos en el tráfico y afectó su largo \ntrayecto en automóvil (O2). \nEn este ejemplo, la abducción permite generar una explicación probable \n(el accidente en la carretera) para la hipótesis (porque, Luis llegó tarde a la \nreunión) basada en las circunstancias conocidas (largo trayecto de Juan y el \naccidente en la carretera). \nEjemplo 3 \nImagine que usted es un detective y llega a una casa, donde encuentra una \nventana rota, una puerta forzada y un escritorio revuelto. Tiene las siguientes \nobservaciones: \nObservación 1: La ventana está rota. \nObservación 2: La puerta ha sido forzada. \nObservación 3: El escritorio del cuarto de estudio está revuelto. \nObservación 4: El propietario de la casa informa que algunas joyas han \ndesaparecido. \nAhora, quieres abducir una explicación probable de lo que sucedió. Las",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n100 \nhipótesis posibles incluyen: \nHipótesis 1: Un ladrón entró por la ventana rota. \nHipótesis 2: El propietario perdió las joyas y forzó la puerta y revolvió el escritorio \npara hacer que pareciera un robo. \nHipótesis 3: Hubo un terremoto que causó la ventana rota, la puerta forzada y el \nescritorio revuelto. \nDado que está buscando una explicación como detective podría usar la \nhipótesis más probable, para abducir lo siguiente: \nEs probable que un ladrón (H1) haya entrado a la casa por la ventana rota \n(O1), forzado la puerta (O2) y revuelto el escritorio (O3) en busca de las joyas \n(O4) que luego se llevó. \nEn este caso, la abducción le ayuda a generar la hipótesis más probable \nbasada en las observaciones en la escena del crimen. Sin embargo, es importante \nrecordar que la abducción no garantiza la verdad absoluta, solo identifica una \nexplicación probable dadas las observaciones disponibles. \nf) Inducción.- La inducción representa un proceso de razonamiento que parte de \nobservaciones específicas para alcanzar conclusiones de carácter más general. En \nel vasto y complejo campo de la inteligencia artificial, este enfoque se emplea de \nmanera estratégica para elaborar modelos, patrones y reglas, todos ellos \nfundamentados en datos concretos y observaciones detalladas.  \nEsta metodología no solo facilita la creación de sistemas predictivos \nrobustos, sino que también dota a las máquinas de la capacidad de tomar \ndecisiones informadas y precisas en escenarios futuros que presenten similitudes \ncon las situaciones observadas. Así, la inducción se convierte en una herramienta \nesencial para la extracción de conocimiento y aprendizaje automático, \npermitiendo a los sistemas de IA adaptarse y responder de manera efectiva ante \nuna variedad de situaciones y contextos. \n             La forma del método inductivo es la siguiente: \n             Si se conoce que P(a), P(b),....... P(n) son verdaderos, \n                  entonces se puede concluir que ∀x, P(x) es también verdadero. \nSe emplea para los estudios experimentales, por ejemplo, cuando se \nprueban las medicinas se hace en un grupo que tiene ciertas características y luego",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n101 \ncuando ha dado resultado se generaliza a la población, pero cuando ya está en el \nmercado la medicina, hay ciertos pacientes a los cuales les es contraproducente.  \nEn el contexto de los estudios experimentales, como la prueba de \nmedicamentos, se utiliza un enfoque inductivo. Este proceso comienza con la \nselección de un grupo específico de pacientes que comparten ciertas \ncaracterísticas, sobre los cuales se realizan pruebas. Los resultados positivos \nobtenidos en este grupo limitado se extrapolan luego para aplicarlos a la población \ngeneral. Sin embargo, es importante reconocer que, incluso después de la \naprobación y distribución de un medicamento, pueden surgir casos individuales \nde efectos adversos. Este fenómeno destaca la importancia de la vigilancia \ncontinua y del análisis de datos post-lanzamiento, un área donde la inteligencia \nartificial puede jugar un rol significativo, procesando y analizando grandes \nvolúmenes de datos para identificar patrones ocultos y predecir posibles \ncontraindicaciones en subgrupos específicos de pacientes. \nLa inducción en el ámbito de la inteligencia artificial abarca un espectro \namplio de técnicas y métodos, cada uno con sus aplicaciones y ventajas \nespecíficas. Entre estas técnicas se incluyen: \nAprendizaje Supervisado: Donde los modelos de IA aprenden a partir de \nconjuntos de datos etiquetados, mejorando su capacidad para hacer predicciones \no clasificaciones precisas. \nAprendizaje No Supervisado: Utilizado para analizar datos sin etiquetar, \ndescubriendo estructuras ocultas o patrones sin intervención humana previa (Xiao, \n2022). \nMinería de Datos: Esencial para descubrir correlaciones y tendencias en \ngrandes bases de datos, lo que permite una toma de decisiones más informada. \nRazonamiento Inductivo: Se aplica para formular hipótesis y modelos a \npartir de observaciones específicas. \nRedes Neuronales: Sistemas que imitan la estructura y función del cerebro \nhumano para procesar información de manera eficiente. \nAprendizaje Profundo: Una forma avanzada de aprendizaje automático \nque utiliza redes neuronales profundas para modelar y resolver problemas \ncomplejos.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n102 \nCada uno de estos enfoques aporta una dimensión única al campo de la IA, \npermitiendo a los sistemas aprender y adaptarse de manera efectiva en una \nvariedad de contextos y aplicaciones. \nA continuación, tenemos algunos ejemplos: \nEjemplo 1  \nClasificación de correos electrónicos como spam o no spam \nEl proceso empieza con la recopilación de un conjunto de datos que \ncontiene una colección de correos electrónicos que se etiquetan previamente como \n\"spam\" o \"no spam\". Cada correo electrónico en el conjunto de datos se representa \ncomo un conjunto de características, como las palabras que contiene y otros \natributos relevantes. \nLuego el conjunto de datos de entrenamiento se utilizzan para enseñar a \nnuestro algoritmo de aprendizaje supervisado a reconocer patrones que distingan \nentre correos electrónicos de spam y no spam. El algoritmo ajusta un modelo \nmatemático que relaciona las características de entrada (contenido del correo \nelectrónico) con las etiquetas de salida (spam o no spam). \nDurante el proceso de entrenamiento, el algoritmo de aprendizaje inducirá \nreglas o relaciones a partir de los ejemplos de entrenamiento. Por ejemplo, podría \naprender que, si un correo electrónico contiene ciertas palabras clave como \n\"oferta\", \"ganador\" y \"gratis\", es más probable que sea spam. \nDespués de entrenar el modelo, se valida utilizando un conjunto de datos \nde prueba independiente para verificar su capacidad para clasificar correctamente \ncorreos electrónicos desconocidos. Si el modelo no tiene un rendimiento \nsatisfactorio, se puede ajustar los parámetros del algoritmo o recopilar más datos \nde entrenamiento para mejorar su precisión. \nUna vez que el modelo está entrenado y validado, se puede usarlo para \nclasificar automáticamente nuevos correos electrónicos. Cuando llega un nuevo \ncorreo electrónico, el modelo evalúa sus características y predice si es spam o no \nspam en función de las reglas y patrones que ha aprendido. \nEste es un ejemplo simplificado, debido a que en la práctica, los algoritmos \nde aprendizaje supervisado pueden ser mucho más complejos y manejar una \nvariedad de características y técnicas de procesamiento de datos. La clave de la",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n103 \ninducción en este caso es que el modelo aprende a partir de ejemplos previos para \ngeneralizar y hacer predicciones precisas sobre nuevos datos sin etiquetar. \nEjemplo 2  \nClasificación de dígitos escritos a mano \nSe desea construir un sistema de reconocimiento de dígitos del 0 al 9 \nescrito a mano, de forma que el sistema pueda identificar automáticamente el \ndígito contenido en una imagen. \nSe reúne un conjunto de datos de entrenamiento que incluye miles de \nimágenes de dígitos manuscritos, donde cada imagen está marcada con la \nidentificación del dígito que representa, como \"0\", \"1\", \"2\", \"3\", ..., \"9\". \nCada imagen se transforma en un conjunto de características numéricas \nque capturan distintas propiedades de la imagen, como la intensidad de los píxeles \ny la forma de los trazos. Estas características se utilizan como la entrada de nuestro \nmodelo. \nEste conjunto de datos de entrenamiento, junto con las etiquetas \ncorrespondientes, se emplea para entrenar un modelo de aprendizaje supervisado, \ncomo una red neuronal o un clasificador basado en máquinas de soporte vectorial \n(SVM). El modelo aprenderá a identificar patrones en las características que \npermitan distinguir entre los diversos dígitos. \nEn el proceso de entrenamiento, el modelo inducirá reglas o pesos óptimos \na cada característica, lo que le permitirá realizar una clasificación precisa de los \ndígitos. \nEl modelo se somete a una validación utilizando un conjunto de datos de \nprueba que no fue empleado durante el proceso de entrenamiento. En caso de que \nel modelo no presente un desempeño satisfactorio, se procede a ajustar sus \nparámetros o a considerar estrategias adicionales, como aumentar el tamaño del \nconjunto de datos de entrenamiento o realizar modificaciones en las características \nextraídas (McCarthy, 1981). \nUna vez que el modelo ha sido entrenado y validado, está listo para realizar \npredicciones en imágenes nuevas y desconocidas de manera automática. El \nmodelo examina las características de la imagen y emite una predicción sobre el \ndígito que esta representa.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n104 \nEjemplo 3  \nProcesamiento del lenguaje natural (PNL) \nSuponga que se desea construir un sistema que pueda identificar el idioma \nen el que está escrito un texto.  \nSe comienza recopilando un conjunto de textos en varios idiomas \ndiferentes, y cada texto está etiquetado con el idioma en el que está escrito. \nSe Utiliza este conjunto de datos para entrenar un modelo de aprendizaje \nautomático, como un clasificador basado en palabras o caracteres, para identificar \npatrones que distingan entre los diferentes idiomas. \nDurante el proceso de entrenamiento, el algoritmo de aprendizaje induce \nreglas basadas en las palabras, caracteres u otras características relevantes de cada \ntexto en diferentes idiomas. Por ejemplo, podría aprender que ciertas \ncombinaciones de caracteres son comunes en un idioma específico, pero raras en \notros. \nSe evalúa el rendimiento del modelo utilizando un conjunto de datos de \nprueba independiente y se ajusta la configuración si es necesario para mejorar su \nprecisión. \nUna vez que el modelo está entrenado y validado, se puede usar para \npredecir el idioma de un nuevo texto en función de las reglas y patrones que ha \naprendido. Por ejemplo, si un texto tiene muchas palabras que son típicas del \nespañol, el modelo lo clasificará como \"español\". \nLa inducción en este caso implica aprender reglas y patrones a partir de \ndatos de entrenamiento para tomar decisiones informadas sobre datos no vistos \nanteriormente. \n2.2 \nReglas de producción \nEn el ámbito de la inteligencia artificial, las bases de conocimiento se estructuran \nmediante cláusulas de Horn. Las cláusulas de Horn reciben su nombre del lógico Alfred \nHorn, quien las identificó como una forma especial de expresión lógica. Estas cláusulas \nse articulan |a través de una estructura de implicación, en la cual la premisa se compone \nde una conjunción de literales positivos (que pueden ser hechos o condiciones), y la \nconclusión es un solo literal positivo. Para llevar a cabo procesos inferenciales, es común \nemplear algoritmos de encaminamiento, tanto en modalidades hacia adelante como hacia",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n105 \natrás. \nSon particularmente significativas en la inteligencia artificial debido a su \neficiencia en el procesamiento computacional. Esta estructura facilita enormemente el \ndiseño de algoritmos de inferencia, debido a que permite simplificar los procesos de \nbúsqueda y de resolución de problemas. Además, las cláusulas de Horn son la base para \nmuchos lenguajes de programación lógica, como Prolog, que son ampliamente utilizados \nen la construcción de sistemas basados en conocimientos y en la resolución de problemas \nen IA. Su simplicidad y potencia hacen que las cláusulas de Horn sean ideales para \nrepresentar reglas y hechos en sistemas expertos, permitiendo a estos sistemas realizar \ninferencias lógicas de manera eficiente y efectiva. \nLos sistemas basados en reglas representan un destacado paradigma en la \nrepresentación del conocimiento debido a su simplicidad y similitud con el razonamiento \nhumano. Estos sistemas utilizan el formato IF-THEN (SI-ENTONCES), que es una \nrepresentación de la cláusula de Horn. En este formato, el \"IF\" actúa como el antecedente \no premisa, mientras que el \"THEN\" sirve como el consecuente o conclusión. Un ejemplo \npráctico sería: SI el lugar está sucio, ENTONCES proceda a limpiar. \nLos sistemas basados en reglas emplean el modus ponens para gestionar los \nhechos conocidos. Estos hechos, que son declaraciones aceptadas como verdaderas, \nforman la memoria de trabajo del sistema. Durante el proceso de inferencia, estas \ndeclaraciones y reglas se utilizan conjuntamente para derivar conclusiones. \nLa unificación es un proceso importante en los sistemas de reglas de producción, \nrepresentando un mecanismo fundamental para lograr la correspondencia entre diferentes \nelementos de conocimiento. En esencia, la unificación implica la comparación y \ncombinación de términos, variables o patrones dentro de las reglas y hechos para \nencontrar un ajuste o coincidencia común. Este proceso no solo permite verificar si dos \nexpresiones son equivalentes o compatibles, sino que también facilita la generación de \nconclusiones lógicas. \nPor ejemplo, en un sistema de diagnóstico médico, la unificación podría utilizarse \npara combinar síntomas reportados por un paciente (como fiebre o tos) con patrones \nconocidos de enfermedades, permitiendo al sistema inferir posibles diagnósticos. \nAdemás, la unificación es fundamental en la generalización y especialización de las \nreglas, permitiendo a los sistemas de IA adaptar su conocimiento a nuevos casos o",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n106 \nsituaciones específicas, lo que es necesario para la flexibilidad y la capacidad de \naprendizaje de estos sistemas. \nEn el ámbito del razonamiento computacional, se destacan principalmente dos \nenfoques estratégicos: el encaminamiento hacia adelante y el encaminamiento hacia atrás. \nEl encaminamiento hacia adelante comienza con un conjunto exhaustivo de datos \nconocidos, desde los cuales se desarrolla progresivamente hacia una solución. Este \nmétodo es especialmente eficaz en situaciones donde los datos fluyen de manera \nsecuencial y sistemática, permitiendo al sistema formular hipótesis y llegar a conclusiones \npaso a paso. Se emplea comúnmente en sistemas expertos para realizar diagnósticos o en \nprocesos de toma de decisiones donde la información se acumula y se elabora \ngradualmente. \nPor otro lado, el encaminamiento hacia atrás adopta una aproximación inversa. \nAquí, se inicia con una hipotética solución o conclusión y luego se busca retroactivamente \nevidencia o datos que la sustenten. Esta técnica es particularmente útil en contextos donde \nel objetivo final es claro, pero el camino para alcanzarlo no lo es. Se utiliza en la solución \nde problemas complejos, como en la programación lógica, donde se definen los objetivos \ndeseados y el sistema trabaja hacia atrás para encontrar las condiciones que deben \ncumplirse para alcanzar esos objetivos. Esta estrategia es eficaz para reducir el espacio \nde búsqueda y para centrarse en los aspectos relevantes de un problema, lo que resulta en \nuna solución más eficiente y dirigida. \n2.2.1 Encaminamiento hacia adelante \nDentro del marco de los sistemas basados en conocimiento, se opera con un \nconjunto de datos previamente conocidos. Estos datos se analizan en relación con cada \nuna de las reglas estructuradas en formato IF-THEN. El objetivo es determinar si los datos \ncumplen con las premisas (IF) de alguna de estas reglas. Para este propósito, se emplea \nla técnica de unificación. En situaciones donde múltiples reglas resultan ser compatibles, \nse opta por aquella con la mayor prioridad asignada. Una vez seleccionada, la regla se \nejecuta, derivando nuevos hechos (THEN) (Feigenbaum & others, 1977). Estos hechos \nrecién derivados pueden, a su vez, ser empleados por otras reglas, generando así una \ncascada de derivaciones adicionales. El motor de inferencia es el componente encargado \nde interpretar y evaluar estos hechos dentro de la base de conocimiento, conduciendo al \nsistema hacia una respuesta coherente.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n107 \nPara ilustrar la forma en que trabaja se presenta el siguiente ejemplo con un \nconjunto de reglas que trata sobre animales: \nREGLA 1 IF  mamífero = si AND \n                      carnívoro = si AND \n            \ncolor = leonado  AND \n            \nmanchas_oscuras = si  \n                THEN animal = onza \nREGLA 2 IF  posee_pelo = si AND \n            \npuede_dar_leche = si \n              THEN mamífero= si \nREGLA 3 IF  come_carne = si AND \n            \ndientes_puntiagudos = si AND \n            \ngarras = si   AND \n            \nojos_adelante = si \n                THEN  carnívoro = si \nREGLA 4 IF  posee_pelo = no AND \n            \ntiene_plumas = si  AND \n            \npuede_volar = si  OR \n \n   \npuede_volar = no  AND \n            \npuede_nadar = si OR \n            \npuede_nadar = no AND \n            \npone_huevos = si \n            THEN pájaro = si \nREGLA 5 IF  mamífero = si AND \n            \npezuñas = si AND \n            \nrumear = si \n             THEN ungulado = si \nREGLA 6 IF  mamífero = si AND \n            \ncarnívoro = si AND \n            \ncolor=leonado  AND \n            \nrayas_negras = si \n             THEN    animal = tigre \nREGLA 7 IF ungulado = si AND \n            \ncuello_largo = si AND \n            \npatas_largas = si AND \n            \nmanchas_oscuras = si  \n             THEN animal = jirafa \nREGLA 8 IF pájaro = si AND \n            \npuede_volar = no AND \n            \ncuello_largo = si AND \n            \npatas_largas = si AND",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n108 \n            \ncolor = blanco_negro \n              THEN animal = avestruz \nREGLA 9 IF  ungulado = si AND \n            \nrayas_negras = si AND \n            \ncolor = blanco \n               THEN animal = cebra \nREGLA 10 IF pájaro = si AND \n            \n  puede_volar = si AND \n            \n  color = blanco_negro \n               THEN animal = albatros \nREGLA 11 IF pájaro = si AND \n            \n  puede_volar = no AND \n            \n  puede_nadar = si AND \n            \n  color = blanco_negro \n                THEN animal = pingüino                    \n           \nSe va a probar si se puede determinar el animal al que se refiere dado el conjunto \nde datos: \nposee_pelo = si  \npuede_dar_leche = si \ncolor=leonado   \nrayas_negras = si \ncome_carne = si  \ndientes_puntiagudos = si  \ngarras =si    \nojos_adelante = si \nA continuación, se puede observar las ejecuciones necesarias, las reglas que se \najustan a los datos y cuál es la que se aplica y los hechos encontrados. \nTabla 2-7 Fases del proceso de encaminamiento hacia adelante \nNúmero de \nejecuciones \nReglas que se \najustan a los \ndatos \nRegla \nAplicable \nDatos aplicables \nHechos \nencontrados \n1 \n2,3 \n2 \nposee_pelo = si \npuede_dar_leche = si \nmamífero = si \n2 \n2,3 \n3 \ncome_carne = si \ndientes_puntiagudos = si \ngarras = si \nojos_adelante = si \ncarnívoro = si \n3 \n2,3,6 \n6 \nmamífero = si \ncarnívoro = si \ncolor = leonado \nanimal = tigre",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n109 \nrayas_negras = si \n4 \n2,3,6 \nNinguna \n \n \n        Elaborado por los Autores \n1era Ejecución: Con los datos que se tienen se va a ver cuáles premisas de las \nreglas se cumplen, encontrando que la regla 2 y 3 se ajustan a los datos dados. La regla \naplicable es la 2 por prioridad. Encontrándose el hecho de que se trata de un mamífero. \nEl nuevo hecho pasa a constituirse en un nuevo dato para la búsqueda de las reglas \naplicables.  \n2da Ejecución:   Las reglas 2 y 3 se ajustan de nuevo a los datos que se tienen, \npero como la regla 2 ya se ejecutó se procede a utilizar la regla 3; derivándose el nuevo \nhecho que constituye un nuevo dato de que se trata de un animal carnívoro.  \n3era Ejecución: Las reglas aplicables son la 2,3,6 como las dos primeras ya se \nutilizaron entonces queda por ejecutarse la regla 6 llegando a determinarse el hecho de \nque el animal al que se refieren los datos dados es el tigre. \n4ta Ejecución: Se vuelve a probar para ver si existe alguna otra regla que se pueda \nejecutar, pero como se observa en el cuadro no existe ninguna otra regla; además si \nhubiese constituiría un error en las premisas de las reglas, pues no existen 2 animales en \nel mundo con las mismas características.  \n2.2.2 Encaminamiento hacia atrás \nEn el enfoque del encaminamiento hacia atrás, el razonamiento se inicia desde la \nconclusión (THEN) que se busca alcanzar. Inicialmente, no se dispone de datos \nconocidos. Por ello, basándose en los objetivos presentes en las conclusiones (THEN), se \nintenta deducir valores a través de cuestionamientos vinculados a las premisas (IF), \nutilizando las reglas establecidas en la base de conocimientos. Es esencial priorizar estos \nobjetivos para determinar cuál de ellos puede ser satisfecho con las premisas que se van \nidentificando como pertinentes al objetivo en cuestión.  \nSi todas las premisas de una regla resultan ser verdaderas, se ejecuta dicha regla, \nderivando así su conclusión y logrando el objetivo propuesto. Este objetivo satisfecho se \ntransforma en un hecho conocido. Sin embargo, si alguna premisa no se cumple, es \nnecesario identificar una regla cuya conclusión (THEN) tenga dicha premisa y, a partir \nde ahí, trabajar en satisfacer sus premisas (IF) asociadas. \nComo aplicación para un mejor entendimiento, con las mismas reglas utilizadas \npara el encaminamiento hacia adelante se va a proceder a realizar el encaminamiento",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n110 \nhacia atrás, siendo el objetivo determinar el animal del que se trata.  \n1era Ejecución: Se busca todas las reglas que en su conclusión (THEN) mencionen \nal objetivo animal. Se parte sin datos conocidos. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \nAnimal \nNinguno \n1,6,7,8,9,10,11 \n1 \n2da Ejecución: Las reglas que hacen referencia al objetivo animal en las \nconclusiones son: 1,6,7,8,9,10,11; se procede a probar la primera premisa de la regla 1 \nmamífero = si, como no existe valor alguno para mamífero en los datos conocidos, se \nbusca una regla que nos permita derivar dicho valor; se encuentra que la regla 2 en su \nconclusión(THEN) hace referencia a mamífero = si; entonces esta regla se vuelve en la \nprioridad, y el objetivo cambia a mamífero. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \nmamífero \nanimal \nNinguno \n2,1,6,7,8,9,10,11 \n2 \n3ra Ejecución: Se busca determinar si la primera premisa posee_pelo = si de la \nregla 2 se encuentra entre los datos conocidos, como no existe se busca determinar si \nalguna conclusión de las reglas hace referencia, al no encontrarse tampoco el mecanismo \nde inferencia procede a hacer la pregunta “¿Posee pelo?” al usuario. Ante una respuesta \nafirmativa, se considera que la premisa es válida y se añade a los datos conocidos. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \nmamífero \nanimal \nposee_pelo = si \n2,1,6,7,8,9,10,11 \n2 \n4ta Ejecución: Se busca determinar si la segunda premisa puede_dar_leche = si de \nla regla 2 se encuentra entre los datos conocidos, como no existe se busca determinar si \nalguna conclusión (THEN) de las reglas hace referencia, al no encontrarse el mecanismo \nde inferencia procede a hacer la pregunta “¿Puede dar leche?” al usuario del sistema. La \nrespuesta afirmativa del usuario confirma la premisa, que posteriormente se incorpora a \nlos datos conocidos. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \nmamífero \nanimal \nposee_pelo = si \npuede_dar_leche = si \n2,1,6,7,8,9,10,11 \n2 \n5ta Ejecución: Como las dos premisas de la regla 2 se cumplen entonces se llega a",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n111 \nla conclusión de que se trata de un mamífero, por lo tanto el objetivo mamífero pasa a ser \nparte de los datos conocidos y el objetivo prioritario vuelve a ser animal, siendo la regla \n1 la que se debe probar si sus premisas se cumplen. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \nanimal \nposee_pelo = si \npuede_dar_leche = si \nmamífero= si \n1,6,7,8,9,10,11 \n1 \n6ta Ejecución: Se regresa a las reglas aplicables, se procede a probar la primera \npremisa de la regla 1 mamífero = si, como es parte de los datos conocidos, se procede a \ndeterminar si la segunda premisa carnívoro = si se encuentra en los datos conocidos, al \nno existir valor alguno se busca una regla que nos permita derivar dicho valor; se \nencuentra que la regla 3 en su conclusión (THEN) hace referencia a carnívoro = si; \nentonces esta regla se convierte en prioridad, y el objetivo cambia de animal a carnívoro. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \ncarnívoro \nanimal \nposee_pelo = si \npuede_dar_leche = si \nmamífero= si \n3,1,6,7,8,9,10,11 \n3 \n7ma Ejecución: Se busca determinar si la primera premisa come_carne = si de la \nregla 3 se encuentra entre los datos conocidos como no existe, se busca determinar si  \nalguna conclusión de las reglas hace referencia, al no encontrarse tampoco  el mecanismo \nde inferencia procede a hacer la pregunta “¿Come carne?” al usuario del sistema. La \nrespuesta afirmativa del usuario confirma la premisa, que posteriormente se incorpora a \nlos datos conocidos. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \ncarnívoro \nanimal \nposee_pelo = si \npuede_dar_leche = si \nmamífero= si \ncome_carne = si \n3,1,6,7,8,9,10,11 \n3 \n8va Ejecución: Se busca determinar si la segunda premisa dientes_puntiagudos = \nsi de la regla 3 se encuentra entre los datos conocidos, como no existe se busca determinar \nsi alguna conclusión de las reglas hace referencia a esta premisa, al no encontrarse \ntampoco el mecanismo de inferencia procede a hacer la pregunta “¿Tiene dientes",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n112 \npuntiagudos?” El usuario del sistema responde afirmativamente, validando así la premisa, \nque se incorpora a la columna de datos conocidos. \nObjetivos \nDatos conocidos \nReglas aplicables Regla a utilizar \ncarnívoro \nanimal \nposee_pelo = si \npuede_dar_leche = si \nmamífero= si \ncome_carne = si \ndientes_puntiagudos = \nsi \n3,1,6,7,8,9,10,11 \n3 \n9na Ejecución: Se busca determinar si la tercera premisa garras = si  de la regla 3 \nse encuentra entre los datos conocidos, como no existe se busca determinar si  alguna \nconclusión de las reglas hace referencia a esta premisa, al no encontrarse tampoco  el \nmecanismo de inferencia procede a hacer la pregunta “¿Tiene garras?” al usuario del \nsistema. La respuesta afirmativa del usuario confirma la premisa, que posteriormente se \nincorpora a los datos conocidos. \nObjetivos \nDatos conocidos \nReglas aplicables Regla a utilizar \ncarnívoro \nanimal \nposee_pelo = si \npuede_dar_leche = si \nmamífero= si \ncome_carne = si \ndientes_puntiagudos = \nsi \ngarras =si \n3,1,6,7,8,9,10,11 \n3 \n10ma Ejecución: Se busca determinar si la cuarta premisa ojos_adelante = si de la \nregla 3 se encuentra entre los datos conocidos, como no existe se busca determinar si \nalguna conclusión de las reglas hace referencia a esta premisa, al no encontrarse tampoco \nel mecanismo de inferencia procede a hacer la pregunta “¿Tiene ojos adelante?” al \nusuario. La respuesta afirmativa del usuario confirma la premisa, que posteriormente se \nincorpora a los datos conocidos. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \ncarnívoro \nanimal \nposee_pelo = si \npuede_dar_leche = si \n3,1,6,7,8,9,10,11 \n3",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n113 \nmamífero= si \ncome_carne = si \ndientes_puntiagudos = \nsi \ngarras =si \nojos_adelante = si \n11ma Ejecución: Como las cuatro premisas de la regla 3 se cumplen, entonces se \nllega a la conclusión de que se trata de un carnívoro, por lo tanto el objetivo carnívoro \npasa a ser parte de los datos conocidos y el objetivo prioritario vuelve a ser animal, siendo \nla regla 1 la que se debe probar para ver si sus premisas se cumplen. \nObjetivos \nDatos conocidos \nReglas aplicables \nRegla a utilizar \nanimal \nposee_pelo = si \npuede_dar_leche = si \nmamífero= si \ncome_carne = si \ndientes_puntiagudos = \nsi \ngarras =si \nojos_adelante = si \ncarnívoro= si \n1,6,7,8,9,10,11 \n1 \n12ma Ejecución: Se procede a probar la primera premisa de la regla 1 mamífero = \nsi, como es parte de los datos conocidos, se procede a determinar si la segunda premisa  \ncarnívoro = si se encuentra en los datos conocidos, como si existe entonces se procede \ncon la tercera premisa color = leonado  se encuentra en los datos conocidos, al no existir \nvalor alguno se busca una regla que nos permita derivar dicho valor; como no  existe \nninguna regla que en su conclusión haga referencia a esta premisa el mecanismo de \ninferencia procede a preguntar al usuario del sistema ¿Cuál es el color del animal? al \nusuario. La respuesta afirmativa del usuario confirma la premisa, que posteriormente se \nincorpora a los datos conocidos. \nObjetivos \nDatos conocidos \nReglas aplicables Regla a utilizar \nanimal \nposee_pelo = si \npuede_dar_leche = si \n1,6,7,8,9,10,11 \n1",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n114 \nmamífero= si \ncome_carne = si \ndientes_puntiagudos = \nsi \ngarras =si \nojos_adelante = si \ncarnívoro= si \ncolor=leonado \n13ma Ejecución: Se procede a probar la cuarta premisa de la regla 1 \nmanchas_oscuras = si, primero se busca en los datos conocidos, al no existir valor alguno \nse busca una regla que nos permita derivar dicho valor; como no  existe ninguna regla \nque en su conclusión haga referencia a esta premisa el mecanismo de inferencia procede \na preguntar al usuario del sistema ¿Tiene manchas oscuras? En este caso la respuesta es \nno, por lo que la premisa no se cumple y falla la regla 1, tomando prioridad la regla 6 que \nestá en la secuencia de las reglas aplicables. \nObjetivos \nDatos conocidos \nReglas aplicables Regla a utilizar \nanimal \nposee_pelo = si \npuede_dar_leche = si \nmamífero= si \ncome_carne = si \ndientes_puntiagudos = \nsi \ngarras =si \nojos_adelante = si \ncarnívoro= si \ncolor=leonado \n6,7,8,9,10,11 \n6 \n14ta Ejecución: Se procede a probar la primera premisa de la regla 6 mamífero = \nsi, como es parte de los datos conocidos, se procede con la segunda premisa  carnívoro = \nsi se encuentra en los datos conocidos como si existe entonces se procede con la tercera \npremisa color=leonado  se encuentra en los datos conocidos como si existe entonces se \nprocede con la cuarta premisa rayas_negras = si al no estar presente en los datos \nconocidos, se busca una regla que nos permita derivar dicho valor; como no  existe",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n115 \nninguna regla que en su conclusión haga referencia a esta premisa el mecanismo de \ninferencia procede a preguntar al usuario del sistema ¿Tiene rayas negras el animal? En \neste caso la respuesta es si por lo que la premisa se cumple y pasa a ser parte de los datos \nconocidos. Todas las premisas de la regla 6 se cumplen y por lo tanto el objetivo que era \nencontrar un animal con ciertas características se cumple, siendo este el tigre. \nObjetivos \nDatos conocidos \nReglas aplicables Regla a utilizar \n \nposee_pelo = si \npuede_dar_leche = si \nmamífero= si \ncome_carne = si \ndientes_puntiagudos = \nsi \ngarras =si \nojos_adelante = si \ncarnívoro= si \ncolor=leonado \nrayas_negras = si \nanimal = tigre \n7,8,9,10,11 \n \n15ta Ejecución:  Las reglas 7,8,9,10,11 son desechadas debido a que ya se encontró \ncon los datos conocidos un animal, que en este caso es el tigre y ya no existe ningún \nobjetivo.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n116 \nCAPITULO 3 \n3 METODOS Y ESTRATEGIAS DE BUSQUEDA \nLas estrategias de búsqueda están fundamentadas en la actuación de los agentes que \ntienen un propósito definido. Estos agentes, ejecutan una serie de acciones que les facilita \nla transición entre diferentes estados, en la búsqueda de alcanzar el estado objetivo, que \nrepresenta su meta final. Estas búsquedas se realizan en contextos donde el entorno de \ntrabajo es observable, discreto, estático y determinista. Es importante destacar que la \nelección de la acción a implementar, con el fin de transitar hacia un nuevo estado, conlleva \nun costo asociado. \nEn el proceso de búsqueda se siguen comúnmente 3 pasos que son: \n✓ Formulación del objetivo: Esta fase implica definir el estado deseado al que el agente \naspira llegar al concluir el proceso. \n✓ Realización de la búsqueda: En este paso, se identifica la secuencia de estados \nintermedios, considerando la medida de rendimiento del agente, que guiará la \ntransición desde el estado inicial hasta el estado objetivo. \n✓ Ejecución de la búsqueda: Una vez determinada la ruta óptima, se llevan a cabo las \nacciones sugeridas durante la fase de realización de la búsqueda para alcanzar el estado \nfinal deseado. \n3.1 \nBúsqueda no informada \nEsta estrategia de búsqueda opera exclusivamente con la información contenida en \nel problema propuesto, sin recurrir a datos adicionales. Su objetivo es identificar los \nestados sucesores y, a través de este proceso, localizar el estado meta. En el contexto de \nlas búsquedas, lo que generalmente se visualiza es un árbol bidimensional. Esto permite \nrealizar búsquedas desplazándose tanto en el eje X como en el eje Y, navegando a través \nde los nodos del árbol y sus respectivas conexiones. \nLas búsquedas no informadas hacer a ser tratadas se indica a continuación: \nBúsqueda Preferentemente por Amplitud: Esta técnica explora todos los nodos de un \nnivel antes de pasar al siguiente. \nBúsqueda Primero en Profundidad: Se centra en explorar tan profundo como sea \nposible a lo largo de una rama antes de retroceder. \nBúsqueda de Profundidad Limitada: Similar a la búsqueda en profundidad, pero con \nuna restricción en cuántos niveles se exploran.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n117 \nBúsqueda por Profundización Iterativa: Combina las ventajas de la búsqueda en \nprofundidad y la búsqueda por amplitud, incrementando gradualmente la profundidad \nexplorada. \nBúsqueda de Costo Uniforme: Se enfoca en expandir el nodo con el menor costo \nacumulado desde el estado inicial. \n3.1.1 Búsqueda preferentemente por amplitud \nLa estrategia de búsqueda preferentemente por amplitud es un método sistemático \nque comienza desde el nodo raíz y se extiende horizontalmente a través de los nodos \nadyacentes, abarcando cada nivel de manera exhaustiva antes de descender al siguiente. \nEsta exploración horizontal garantiza que todos los nodos en un nivel sean visitados y \nexaminados antes de pasar al nivel inferior. Operando bajo el principio FIFO (First In, \nFirst Out), esta estrategia asegura que los nodos se expandan en el orden en que fueron \ndescubiertos, lo que facilita un proceso de búsqueda organizado y predecible (Chopra, \n2012). \nCada conexión entre los nodos se considera con un costo uniforme, el algoritmo \navanza equitativamente en todas las direcciones posibles, un paso a la vez en cada ruta \nviable. Esta búsqueda es particularmente eficaz en escenarios en los cuales  todas las rutas \ndeben ser evaluadas por igual o cuando la estructura del problema no proporciona pistas \nclaras sobre cuál podría ser la ruta más prometedora. \nAunque esta estrategia garantiza encontrar la solución óptima si existe dentro del \nespacio de búsqueda, su exhaustividad puede resultar en un consumo de tiempo y recursos \nmayor al mínimo necesario. Es especialmente efectiva en árboles de búsqueda con una \nprofundidad y número de ramas moderados, pero puede volverse menos práctica en \nárboles con una gran cantidad de nodos o niveles, debido a que requiere almacenar y \nprocesar todos los nodos de un nivel antes de avanzar al siguiente. \nLa búsqueda por amplitud se aplica en diversos contextos de la inteligencia \nartificial y la informática, como en la solución de puzzles, navegación en mapas, y en la \nplanificación de rutas. Su capacidad para dar una solución óptima y su naturaleza \nsistemática la hacen una herramienta valiosa en problemas donde la precisión y la \nexhaustividad son más críticas que la eficiencia en términos de tiempo o memoria (Russell \n& Norvig, 2012). \nComo ejemplo; se tiene un árbol binario (figura 3.1) donde el estado inicial es el",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n118 \nnodo A y el objetivo es poder llegar al nodo I utilizando la búsqueda preferentemente \npor amplitud y pasando a través de los estados intermedios que son los nodos que forman \nel camino hacia la meta. \n \nFigura 3.1 Árbol binario \nElaborado por los Autores \nSe empieza en el nivel 0 donde se encuentra el nodo raíz que para este caso es \nel nodo A, como no coincide este nodo con el objetivo que es el nodo I se pasa \nal siguiente nivel (nivel 1). \n \nSe pasa al nodo que está a la izquierda del árbol binario que en este \ncaso es el nodo B, pero al no coincidir con el nodo objetivo, se \nprocede a pasar al nodo siguiente en horizontal. \n \nEl siguiente nodo en ser visitado es el nodo C, que tampoco \nconstituye el objetivo (nodo I), por lo cual se desciende al \nsiguiente nivel (nivel 2). \n \n \nEn el segundo nivel el primer nodo en ser visitado es el nodo D \nal no ser el nodo objetivo es desechado.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n119 \nA continuación, se debe trasladar al nodo E que se encuentra \nen el segundo nivel, que no constituye el nodo objetivo. Por lo \ncual se deben visitar los nodos hijos del nodo C que están en el \nsegundo nivel. \n \n \nEl nodo F es el siguiente en ser visitado en el proceso, \npero sucede lo mismo que en los casos anteriores, no \ncoincide con el nodo objetivo. \n \n \n \n \nEl nodo G es el último en ser visitado en el nivel 2 \ny tampoco concuerda con el nodo objetivo que es \nel nodo I, por lo cual se debe descender al nivel 3 \nen búsqueda del objetivo. \n \n \n \n \n \n \nEl primer nodo a ser visitado en el nivel 3 es \nel nodo H al no ser el objetivo, continua la \nbúsqueda hacia el nodo vecino en el eje de las \nX, cuyo padre es el nodo D.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n120 \n \nEn el nivel 3 se encuentra el nodo I que \nera el objetivo, por lo cual se ha llegado \nal estado final.  \n \n \n \n \n \n \nLa solución obtenida utilizando la \nbúsqueda por amplitud para ir del \nnodo A al nodo I constituye el \ncamino a través de los nodos  A-B-\nD-I. \n3.1.2 Búsqueda primero en profundidad \nLa estrategia de búsqueda primero en profundidad se caracteriza por su enfoque \nvertical, procediendo a lo largo del eje Y. Inicia desde el nodo raíz y se dirige hacia el \nnodo sucesor más a la izquierda en el siguiente nivel, y continúa descendiendo por el \nárbol siguiendo siempre la rama más a la izquierda. Este proceso se repite hasta alcanzar \nun punto donde no existen más nodos sucesores. Si no se encuentra el nodo objetivo, el \nalgoritmo retrocede al nodo anterior para explorar otros sucesores posibles, siguiendo el \nprincipio LIFO (Last In, First Out) (Russell & Norvig, 2012). Esta metodología permite \nque la búsqueda se sumerja profundamente en una dirección antes de considerar otras \nalternativas, lo que puede ser especialmente eficiente en situaciones donde la solución se \nencuentra en niveles más profundos del árbol. \nEn el mejor de los escenarios, si el algoritmo 'tiene suerte' y elige consistentemente \nel camino correcto hacia el nodo objetivo, la búsqueda en profundidad puede ser \nextremadamente rápida y directa. Sin embargo, a diferencia de la búsqueda por amplitud, \nno garantiza encontrar la solución óptima si existe más de una, ya que el primer camino \nexitoso que encuentra será el seleccionado. \nPor otro lado, en el peor de los casos, este algoritmo podría explorar cada posible",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n121 \ncamino en el árbol de búsqueda antes de encontrar la solución, lo que resultaría en un \ntiempo de ejecución significativamente más largo, especialmente en árboles con muchas \nramificaciones y profundidades. Aunque este enfoque es menos eficiente en términos de \nmemoria comparado con la búsqueda por amplitud, su simplicidad lo hace valioso en \nciertos contextos, como en la solución de laberintos o problemas que requieren explorar \ntodas las posibilidades hasta encontrar una solución viable. \nEs importante destacar que, debido a su naturaleza, la búsqueda en profundidad \nes más susceptible a quedar atrapada en ciclos o caminos sin salida, por lo que a menudo \nse implementan mecanismos como la limitación de profundidad o la verificación de \nestados repetidos para mejorar su eficacia y evitar la exploración innecesaria de caminos \nya evaluados.  \nUtilizando el mismo árbol empleado en la búsqueda preferentemente por amplitud \ny siendo el nodo objetivo el nodo I se tiene: \n        \nEl primer nodo en ser visitado es el nodo A, al no ser el nodo objetivo se \ndesciende al siguiente nivel (nivel 1) \n \nEn el nivel 1 se encuentra el nodo B que no es el objetivo y se \nprocede a bajar al nivel 2. \n \n \nEl nodo D que se encuentra en el nivel 2 tampoco es el \nobjetivo por lo cual se procede a bajar al nivel 3.  \n \n \nAl no ser el nodo H el nodo objetivo y no existir más \nsucesores se retrocede al nodo D para ver si este tiene \notros sucesores, en este caso si tiene otros sucesores.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n122 \n \nEl nodo D tiene un sucesor que es el nodo I, que \nconstituye el objetivo. Por lo que se llega a la solución \nque es ir desde el nodo A pasando por los nodos B y D \nhasta llegar al nodo objetivo que es el nodo I  (A-B-D-I). \n \n \n3.1.3 Búsqueda de profundidad limitada \nEn el contexto de las estrategias de búsqueda aplicadas a estructuras de árbol, la \ntécnica de búsqueda primero en profundidad es una de las más utilizadas, caracterizada \npor explorar lo más profundo posible a lo largo de una rama antes de considerar otras \nalternativas. Sin embargo, en árboles con una gran cantidad de niveles, esta técnica puede \nser ineficiente, debido a que podría implicar recorrer un número extenso de nodos antes \nde encontrar la solución. \nPara optimizar este tipo de búsqueda en árboles de gran profundidad y mitigar la \nposibilidad de exploraciones excesivamente largas, se introduce el concepto de \n“Búsqueda de Profundidad Limitada”. Esta variante de la búsqueda impone un límite de \nprofundidad, estableciendo un nivel máximo al cual se realizará la exploración. Este \nlímite es particularmente importante cuando se tiene información o estimaciones previas \nlas cuales sugieren que el nodo objetivo está ubicado dentro de un rango de profundidad \nespecífico (Russell & Norvig, 2012). \nAl alcanzar el límite de profundidad preestablecido, la búsqueda trabaja bajo la \npremisa de que no existen sucesores adicionales en ese nivel, aunque esto puede ser que \nno sea cierto en la estructura original del árbol. Esta suposición permite delimitar la \nexploración, enfocando los recursos y esfuerzos en una sección más manejable del árbol, \nlo que resulta en una mayor eficiencia y rapidez en encontrar una solución. \nEsta técnica acelera significativamente la búsqueda en ciertos casos, pero también \npresenta el riesgo de omitir la solución si el nodo objetivo se encuentra más allá del límite \nde profundidad impuesto. La elección de un límite de profundidad adecuado es un factor \ncrítico, que se debe balancear entre la eficiencia deseada y la probabilidad de encontrar \nel nodo objetivo. \nLa búsqueda de profundidad limitada se utiliza en problemas donde la meta se",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n123 \nespera que se encuentre a una profundidad moderada, o en situaciones en las cuales es \npreferible obtener una respuesta rápida, aunque sea parcial, en lugar de realizar una \nexploración completa. Esta técnica es un ejemplo de cómo las estrategias de búsqueda se \nadaptadan y ajustadan para satisfacer las necesidades específicas de diferentes problemas \ny contextos. \n \nFigura 3.2 Árbol de búsqueda \nElaborado por los Autores \nPara el ejemplo que estamos utilizando si el objetivo es llegar al nodo F (figura \n3.2) si se utiliza la búsqueda primero en profundidad se necesita pasar por diez nodos para \nllegar a la solución. Pero se va a ver lo que sucede si se utiliza un límite = 2 (figura 3.3), \nen el cual se tiene una especie de árbol truncado. \n  \nFigura 3.3 Árbol con límite de 2 \nElaborado por los Autores \nEl primer nodo en ser visitado es el nodo A al no ser el nodo objetivo se \ndesciende al siguiente nivel (nivel 1) \n \nEn el nivel 1 se encuentra el nodo B que  no es el nodo objetivo \ny se procede a bajar al nivel 2.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n124 \n  \n \nEl nodo D que se encuentra en el nivel 2 tampoco es el \nobjetivo por lo cual se procede a retroceder al nodo B en \nvista de que se ha llegado al límite = 2 y por tanto se \nconsidera que el nodo D ya no tiene más sucesores. \nSe retrocede al nodo B y se tiene otro \nsucesor que es el nodo E, este nodo es \nvisitado, pero al no ser la solución esto es \nel objetivo nodo F, se procede a \nretroceder al nodo del que desciende esto \nes al nodo B, para observar si tiene otros \nhijos, pero al no ser el caso se retrocede \naún más hasta llegar al nodo A. \nEl nodo A tiene además del nodo \nB otro hijo que es el nodo C, el \ncual no es la solución por lo cual \nse procede a descender hacia el \nnodo sucesor. \n  \n \n \nEl nodo F que constituye el \nsucesor del nodo C es el nodo \nobjetivo, por lo cual se detiene la \nbúsqueda y se encuentra la \nsolución, que es ir del nodo A al \nnodo C y de ahí al nodo objetivo \nque es el nodo F  (A-C-B).  Como \nse puede observar nunca se utilizó el límite=3 para encontrar el nodo objetivo. \n3.1.4 Búsqueda por profundización iterativa \nLa búsqueda por profundización iterativa es una estrategia innovadora que integra",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n125 \nlos aspectos más eficientes de la búsqueda primero en profundidad y la búsqueda de \nprofundidad limitada. Esta técnica se basa en la realización de una serie de búsquedas en \nprofundidad, cada una con un límite de profundidad que se incrementa de manera iterativa \nen cada ciclo. \nEl proceso comienza con un límite de profundidad inicial fijado en 0, explorando \nsolo el nodo raíz. Si el nodo objetivo no se encuentra en este nivel superficial, el límite se \naumenta en una unidad y se procede con una nueva búsqueda en profundidad, esta vez \nextendiéndose hasta el siguiente nivel. Este enfoque iterativo se repite, incrementando el \nlímite en cada ciclo, hasta encontrar el nodo objetivo o haber recorrido completamente la \nestructura del árbol. \nUna ventaja significativa de la búsqueda por profundización iterativa es su \neficiencia al explorar árboles de búsqueda extensos. Esta metodología es especialmente \nútil cuando se desconoce la profundidad exacta del nodo objetivo. En lugar de \ncomprometerse a una búsqueda de toda la profundidad del árbol desde el comienzo, que \npuede ser costosa en términos de tiempo y memoria, esta estrategia adopta un enfoque \nmás controlado y escalonado, examinando cada nivel de manera secuencial. \nEste método combina la eficiencia de la búsqueda primero en profundidad con \nrespecto al uso de memoria, con la garantía de la búsqueda por amplitud de encontrar la \nsolución óptima sin incurrir en altos costos asociados con la memoria. Es efectivo en \nsituaciones donde el árbol de búsqueda es muy amplio o en situaciones en las cuales la \nubicación del nodo objetivo es incierta; garantiza una exploración sistemática y \nminuciosa, sin la sobrecarga de revisar innecesariamente nodos profundos desde el inicio. \nPor lo tanto, la búsqueda por profundización iterativa se posiciona como una \nherramienta poderosa en la resolución de problemas de inteligencia artificial, ofreciendo \nun equilibrio óptimo entre eficiencia y exhaustividad, adecuado para una amplia gama de \naplicaciones donde la estructura del problema es compleja y la ubicación del objetivo no \nes predecible. \n Para ejemplo que se utiliza el proceso sería el siguiente: \n \nEn el límite = 0 se tiene un solo nodo sin sucesores. El objetivo es \nel nodo F, como el nodo raíz es el nodo A y no constituye el nodo \nobjetivo se procede a aumentar el límite en 1 (0 +1).",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n126 \n \nEl nuevo árbol de búsqueda tiene 3 \nnodos y empieza en el nodo A que al \nno ser el nodo objetivo se procede a \nbajar al siguiente nivel, por el enlace \nque está más a la izquierda.  \n \nEn el nivel 1 se encuentra el nodo B que \nno es el nodo objetivo por lo que se \nregresa al nodo padre que es el nodo A. \n  \nEl nodo siguiente a visitar es el nodo C, \nque es el sucesor del nodo A pero no \nconstituye el nodo objetivo, por lo tanto \nse regresa al nodo padre que es el nodo \nA y al no tener más sucesores, se \nprocede a aumentar el límite = 2  (1+1). \n \nEl nuevo árbol de búsqueda \nmuestra \nlos \nniveles \ncorrespondientes, \nen \nel \nnivel = 0 el nodo A raíz no \nes el nodo objetivo por lo \ncual se procede a descender \nhacia uno de sus sucesores.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n127 \nEl nodo B no constituye el \nnodo objetivo por lo que \nse procede a descender en \nbúsqueda del nodo hijo. \n \n \n \n \nEl nodo D no es el nodo \nobjetivo por lo que se \nregresa al padre que es el \nnodo B para ir al siguiente \nsucesor. \n \n \nEl nodo E es el otro hijo del \nnodo B pero no constituye \nel nodo objetivo, al no tener \nsucesores el nodo E se \nregresa al nodo padre. El \nnodo B no tiene más hijos \npor lo cual se retrocede \nhacia el padre del nodo B \nregresando al nodo raíz nodo A. \nEl nodo A tiene además de \nB otro sucesor que es el \nnodo C pero este nodo \ntampoco coincide con el \nnodo objetivo; por lo cual se \nprocede a descender hacia \nuno de sus sucesores, en \neste caso siempre el que está",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n128 \nmás a la izquierda. \n \nEl nodo F es el nodo sucesor del \nnodo C y constituye el nodo \nobjetivo por lo cual la búsqueda \ntermina y se tiene la solución \nque constituye ir del nodo A al \nnodo C y de ahí al nodo F. \n \n \n3.1.5 Búsqueda de costo uniforme \nEsta estrategia de búsqueda se diferencia de otras técnicas tradicionales en que no \nse basa únicamente en la cantidad de pasos o nodos que se deben atravesar para llegar al \nobjetivo, sino en el costo acumulado asociado a esos pasos. Es especialmente relevante \nen escenarios donde los enlaces entre nodos tienen costos variables y no unitarios. \nEn la búsqueda de costo uniforme, la prioridad no es la proximidad superficial al \nobjetivo (como podría ser el caso en una búsqueda primero en anchura), sino el camino \nque representa el menor costo acumulado (Russell & Norvig, 2012).  \nEn cada etapa de la búsqueda, se expande el nodo que, hasta ese momento, tiene \nel camino de menor costo desde el nodo inicial. \nAunque a simple vista podría parecer similar a la búsqueda primero en anchura, \nla búsqueda de costo uniforme mejora y refina este enfoque al considerar el costo de los \nenlaces en su proceso de decisión.  \nNo se trata simplemente de contar los pasos o nodos atravesados, sino de evaluar \ny sumar los costos asociados a esos pasos. De esta manera, la estrategia garantiza que, al \nalcanzar el nodo objetivo, se haya seguido el camino con el costo total más bajo, \nindependientemente del número de nodos que se haya tenido que atravesar.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n129 \n \nFigura 3.4 Grafo de búsqueda \nElaborado por los Autores \nEsta técnica es esencial en problemas donde las decisiones no solo dependen de \nla distancia o cantidad de pasos, sino también de factores como tiempo, recursos o \ncualquier otra métrica que pueda ser cuantificada en términos de costo.  \nSe va a utilizar el siguiente grafo (figura 3.4) para realizar la búsqueda desde el \nnodo origen que en este caso será el nodo A hasta el nodo destino que será el nodo G. Las \ndistancias entre los nodos se obtendrán mediante el trazo de líneas rectas entre los centros \nde los nodos y se respetarán las direcciones señaladas mediante las flechas \nEl costo del nodo A es cero, y no constituye el nodo destino, por lo cual se procede \na determinar el costo para llegar hacia sus sucesores. \n \nEl costo de ir del nodo A hacia el nodo B se obtiene \naplicando el teorema de Pitágoras√42 + 12 = 4,12 \nlo mismo se aplica para ir al nodo C  √22 + 22 =\n2,83",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n130 \nEl costo de ir del nodo C al nodo D \nes √52 + 22 = 5,39. Como se \nsuman los costos de ir del nodo A \nhasta el nodo D el valor es 2,83 \n+5,39 =8,22. Como C no tiene más \ndescendientes \nse \nprocede \na \ncomparar en el árbol que se ha \nformado los costos entre el nodo B y nodo D que son los extremos del árbol y no tienen \nmás sucesores, por lo que el nodo de menor costo es B 4,12. \n \nLos dos sucesores del nodo B son el \nnodo E y el nodo C. El costo para ir \ndel nodo B al nodo E  es √22 + 22 =\n2,83 y el costo para ir del nodo B al \nnodo C es √62 + 12 = 6,08. Se \ncomparan los totales entre los nodos que no tienen sucesores en este nuevo árbol que son \nel E, C y D; siendo el de menor valor el E, por lo cual se procede a expandir este nodo. \n  \nEl nodo E tiene un solo \nsucesor que es el nodo H y el \ncosto de ir del nodo E al nodo \nH es √42 + 22 = 4,47.  El \ntotal de la suma de ir del \nnodo A al nodo H es 11,42 \ncomparando con los valores \npara llegar al nodo C y al nodo D;  el nodo D tiene un menor costo por lo cual se procede \na expandir.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n131 \nEl nodo D tiene dos \nsucesores que son el \nnodo F y el nodo G, el \ncosto de ir del nodo D al \nnodo F es √52 + 12 =\n5,10 y el costo de ir del \nnodo D al nodo G es \n√72 + 52 = 8,60 . El \ntotal para ir del nodo A \nhasta el nodo F es 13,32 y el total para ir del nodo A al nodo G es 16,82. En este caso \nhemos llegado al nodo objetivo que es el nodo G pero el total es superior a otros nodos \ncomo H, C y F que pueden ser expandidos y también llegan al nodo G. Si el objetivo es \nsimplemente llegar al nodo G se habría cumplido con el propósito y el camino sería ir del \nnodo A a través de los nodos intermedios C y D para llegar al nodo objetivo que es el \nnodo G. Pero si el propósito es encontrar el camino de menor costo se debería continuar \ncon la búsqueda porque aún existen otros nodos que le lleva al objetivo que es el nodo G. \nEn el caso del ejemplo se debería continuar la búsqueda por los otros caminos que faltan \nprobar que son: A-B-E-H-I-G; A-B-C-D-F-G; A-B-C-D-G, para ver cuál es el camino \nque tiene el menor costo total comparado con el camino encontrado que es A-C-D-G para \ndeterminar si este camino constituye el de menor costo.  \n3.2 \nBúsqueda informada \nLa búsqueda informada, a diferencia de las técnicas de búsqueda no informada, \nincorpora información adicional que va más allá de la mera descripción del problema. \nEsta información adicional, denominada heurística, se basa en el conocimiento previo o \nexperiencia relacionada con el problema en cuestión. La heurística no garantiza una \nsolución correcta, pero proporciona una guía o dirección que puede hacer que la búsqueda \nsea más eficiente (Edelkamp & Schrödl, 2011). \nEl conocimiento heurístico actúa como una especie de \"intuición\" que permite \nestimar la proximidad o calidad de un estado particular respecto al objetivo deseado. Por \nejemplo, en un problema de ruta más corta, una heurística podría ser la distancia en línea \nrecta desde un punto a otro, que, aunque no considera obstáculos o caminos específicos, \nproporciona una estimación rápida de la cercanía al objetivo.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n132 \nEn la búsqueda informada, se utilizan diversas métricas para evaluar y priorizar \nlos nodos en el espacio de búsqueda. Estas métricas, basadas en heurísticas, permiten \nordenar o clasificar los nodos según su potencial o probabilidad de acercarse a la solución \nóptima. De esta manera, la búsqueda se orienta hacia las opciones más prometedoras, \nreduciendo el tiempo y los recursos necesarios para encontrar una solución. \nSe tratarán dos formas de búsqueda informada: \n✓ Búsqueda avara primero el mejor \n✓ Búsqueda A* \n3.2.1 Búsqueda avara (primero el mejor) \nLa estrategia de búsqueda avara, también conocida como \"Primero el Mejor\", se \ncentra en la exploración prioritaria de aquellos nodos que, según una función heurística, \nparecen ser los más prometedores para alcanzar el objetivo de manera eficiente. Esta \nfunción heurística, representada por ℎ(n), estima el costo desde el nodo actual n hasta el \nnodo objetivo, basándose en conocimientos previos o heurísticos del problema en \ncuestión (Kumar, 2013). \nEn cada paso de la búsqueda, se selecciona y expande el nodo cuyo valor de ℎ(n) \nes el menor, es decir, aquel que se estima está más cerca del objetivo. Esta elección se \nrealiza con la esperanza y la premisa de que dirigirse hacia el nodo más prometedor \nacelerará el proceso de encontrar la solución. \nEs importante señalar que, una vez que se alcanza el nodo objetivo, el valor de \nh(n) se convierte en cero, indicando que no hay más costo estimado pendiente desde ese \npunto. \nLa efectividad de la búsqueda avara está intrínsecamente ligada a la precisión y \ncalidad de la función heurística empleada. Una función heurística bien diseñada puede \nguiar al algoritmo directamente hacia la solución, mientras que una función imprecisa \npodría desviar la búsqueda, aumentando el tiempo y los recursos necesarios para \nencontrar la solución. \nSe va a utilizar para ejemplificar esta búsqueda el grafo de búsqueda de costo \nuniforme, con la métrica de que la distancia más corta entre dos puntos es la línea recta.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n133 \nEl estado inicial es A y la distancia en línea recta al objetivo G es h(A) = 9 , \nobserve que el nodo A esta en la posición (8,1) y el nodo G en la posición (8,10) \nentonces la distancia en línea recta es (10 – 1) = 9 por tanto f(A) = 9, para llegar \nal nodo objetivo se requiere que la heurística sea cero, por lo que no ha llegado al objetivo \ny se debe expandir el nodo A. \nSe procede a expandir el nodo A y se calcula la \ndistancia en línea recta desde los nodos B y C al nodo \nobjetivo \nG, \nlos \nvalores \nson: \nh(B) \n=  \n√(8 −4)2 + (10 −2)2 = 8,94 \ny \nh(C) \n= \n√(10 −8)2 + (10 −3)2 = 7,28, \nsiendo \nlas \nfunciones f(B)= 8,94 y f(C)=7,28. \n \nSe expande el nodo C que tiene \nmenor valor el cual posee solo un \nnodo \nsucesor \nh(D) \n=  \n√(15 −8)2 + (10 −5)2 = 8,6 \nel valor de la función f(D) = 8,6. \n \nSe comparan los valores de \nlos nodos B y D que no \ntienen sucesores en el gráfico \nanterior para ver cuál de los \ndos se expande, se procede \ncon el nodo D que tiene el \nmenor valor, siendo sus \nsucesores los nodos F y G \n(Sipser, 1996). Los valores son h(F) =  √(10 −8)2 + (10 −6)2 = 4,47 y h(G) =  \n√(0)2 + (0)2 = 0, por tanto los valores de f(F) = 4,47 y de f(G)= 0 siendo el final de la \nbúsqueda debido a que se ha alcanzado el nodo objetivo. El camino para ir del nodo A al \nnodo G es entonces: A - C - D - G.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n134 \n \n3.2.2 Búsqueda A* \nEsta búsqueda es conocida como A estrella la cual evalúa los nodos bajo la \nfórmula f(n) = g(n) + h(n), donde g(n) se utiliza para evaluar el costo de ir por el camino \nde un nodo hacia su sucesor y h(n) para ir del sucesor hacia el nodo objetivo utilizando la \nheurística, la suma da el valor de la función f(n) que constituye el costo más barato de ir \nhacia el objetivo. Al combinar estos dos valores, el algoritmo tiene una forma más precisa \nde determinar el costo de la solución y optimizar sus opciones sobre la marcha. El \nalgoritmo realiza un seguimiento de costo (costo de la ruta hasta ahora + costo estimado \nhasta el objetivo), y una vez que excede el costo estimado de alguna opción anterior, el \nalgoritmo abandonará la ruta actual y volverá a la opción anterior, evitando así ir por un \ncamino largo e ineficiente que h(n) marcó erróneamente como el mejor. Este algoritmo \nal basarse en una heurística, es tan bueno como la heurística que emplea, para que la \nbúsqueda A* sea óptima, la función heurística, h(n) para cada nodo n y nodo sucesor n’ \ncon costo de paso c, h(n) ≤ h(n’) + c (Russell & Norvig, 2012). \nEl algoritmo de búsqueda A* es una de las estrategias más reconocidas y efectivas \nen el ámbito de la inteligencia artificial para encontrar el camino más corto en un espacio \nde búsqueda. Su eficacia radica en su capacidad para combinar información sobre los \ncostos ya conocidos y las estimaciones heurísticas de los costos futuros. \nLa fórmula que guía esta búsqueda es f(n)=g(n)+h(n): \ng(n) representa el costo real desde el nodo de inicio hasta el nodo actual n. \nh(n) es una función heurística que estima el costo desde el nodo n hasta el nodo \nobjetivo. \nLa suma de estos dos valores, f(n), proporciona una estimación del costo total \ndesde el nodo de inicio hasta el objetivo pasando por el nodo. \nLa magia del algoritmo A* radica en cómo utiliza esta información. En cada paso, \nel algoritmo expande el nodo con el valor f(n) más bajo, asegurando que siempre esté \nexplorando el camino más prometedor hacia el objetivo. Si, en algún momento, el costo \nacumulado de un camino supera una estimación previa, A* descarta ese camino, evitando \nasí exploraciones innecesarias y optimizando el proceso de búsqueda. \nPara que A* garantice encontrar la solución más óptima, es importante que la \nfunción heurística h(n) no sobreestime el costo real para llegar al objetivo.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n135 \nMatemáticamente, esto se expresa como: para cada nodo n y su sucesor n’ con un costo \nde paso c, debe cumplirse que h(n)≤h(n’)+c. \nEn esencia, A* es un algoritmo que combina lo mejor de las búsquedas informadas \ny no informadas, proporcionando soluciones eficientes y precisas, siempre y cuando se \ncuente con una heurística adecuada. \nPara la demostración se utilizará el grafo de la búsqueda de costo \nuniforme, el estado inicial es el nodo A y el nodo objetivo es el nodo G. \nel valor de g(A) es 0 porque no existe ningún desplazamiento, mientras \nque el valor de h(A) es (10 -1), por las posiciones que mantiene los nodos igual que en la \nbúsqueda avara primero el mejor. Entonces f(A) = g(A) +h(A)=0 + 9 = 9. \n \nSe procede a expandir los nodos hijos del nodo A que son los nodos B y C, se \ncalcula el valor de f(B)= g(B)  + h(B) = √(8 −4)2 + (2 −1)2 + √(8 −4)2 + (10 −2)2 \n= 4,12 + 8,94 = 13,06, así mismo se procede a calcular el valor de f(C) = \n√(10 −8)2 + (3 −1)2 + √(10 −8)2 + (10 −3)2 = 2,45 + 7,28 = 9,73. El nodo que \ntiene el menor valor es C el cual se procede a expandir. \n \nEl nodo C tiene un solo sucesor que es el nodo D, se procede a calcula el valor de \ng(D) que es la distancia de ir del nodo A al nodo C más la distancia de ir del nodo C al \nnodo D, entonces g(D) = 2,45 + √(15 −10)2 + (5 −3)2 = 2,45 + 5,39 = 7,84 ; el valor \nde h(D) = √(15 −8)2 + (10 −5)2 = 8,60. El valor de f(D) = 7,84 + 8,60 = 16,44. El \nnodo que se procede a expandir es el que tiene el menor valor que en este caso es el nodo",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n136 \nB. \n \nEl nodo B tiene 2 sucesores que son el nodo E y el nodo C, se procede a realizar \nlos cálculos para cada uno de estos nodos. El valor de g(E ) = 4,12 + \n√(6 −4)2 + (4 −2)2 = 4,12 + 2,83 = 6,95  ; el cálculo de la heurística es  h(E) = \n√(8 −6)2 + (10 −4)2 = 6,32 ; el valor de f(E) = 6,95 + 6,32 = 13,27 . El valor de g(C)= \n4,12 +  √(10 −4)2 + (3 −2)2 = 4,12 + 6,08 = 10,2 ; se procede a calcular el valor de \nh(C) = √(10 −8)2 + (10 −3)2 = 7,28 ; el valor de f(C) = 10,2 + 7,28 = 17,48  \n \nEl nodo E es el de menor valor por lo que se despliega su sucesor que es el nodo \nH; se calcula el valor de g(H) = 4,12 + 2,83 + √(6 −2)2 + (6 −4)2 = 4,12 + 2,83 + 4,47 \n= 11,42 ; el valor  h(H) = √(8 −2)2 + (10 −6)2= 7,21 ; el valor de f(H) = 11,42 + 7,21 \n= 18,63.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n137 \n \nEl nodo D es el que tiene el menor valor por lo tanto se abren los sucesores que \nson F y G. El cálculo de g(F) = 7,84 +  √(15 −10)2 + (6 −5)2 = 7,84 + 5,10 = 12,94 y \nel valor de h(F) = √(10 −8)2 + (10 −6)2 = 4,47 ; el cálculo de f(F) = 12,94 + 4,47 = \n17,41. El valor de g(G) = 7,84 + √(15 −8)2 + (10 −5)2 = 8,60; el valor de h(G) = 0  y \npor último el valor de f(G) = 8,60 + 0 = 8,60. En este caso como el menor valor es el del \nnodo G se ha llegado a la solución y el camino es A-C-D-G. Si hubiesen existido otros \nnodos que tenían menor valor y que se podía llegar a G se debía continuar con el cálculo \nhasta encontrar el de menor valor. En la búsqueda A* se puede retroceder del hijo hacia \nel padre cuando se buscan los sucesores, en el caso que se ha analizado esto no sucede \nporque existe dirección en los enlaces. \n3.3 \nOptimización \nLa optimización es un proceso esencial en el ámbito de la inteligencia artificial \n(IA). Se refiere a la tarea de seleccionar la solución más adecuada de entre un conjunto \nde alternativas posibles. Esta elección se basa en criterios específicos, que pueden variar \nsegún el problema en cuestión. Por ejemplo, en un problema de planificación, la \noptimización podría buscar la ruta más corta o eficiente; mientras que, en un problema de \naprendizaje automático, podría tratarse de minimizar el error en las predicciones. \nLa optimización no solo se limita a encontrar la \"mejor\" solución, sino que \ntambién puede involucrar la búsqueda de soluciones que sean \"suficientemente buenas\" \nen un tiempo razonable, especialmente cuando se trata de problemas complejos o de gran \nescala. \nEn el contexto de la IA, la optimización es fundamental, debido a que permite a \nlos sistemas tomar decisiones informadas, mejorar su rendimiento y adaptarse a",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n138 \nsituaciones cambiantes. A través de técnicas y algoritmos especializados, la IA puede \nexplorar y evaluar diferentes soluciones, identificando aquellas que maximizan o \nminimizan un objetivo determinado.  \n3.3.1 Búsqueda local \nLa búsqueda local es una técnica de optimización que opera en el espacio de \nsoluciones de un problema, manteniendo un único nodo o solución en cada iteración. A \ndiferencia de otros algoritmos de búsqueda que exploran ampliamente el espacio de \nestados, la búsqueda local se centra en explorar el entorno inmediato de la solución actual, \nmoviéndose iterativamente hacia soluciones vecinas que mejoren el criterio de \noptimización (Michiels et al., 2007). \nEsta estrategia es especialmente útil para problemas con espacios de estados muy \ngrandes o incluso infinitos, donde una búsqueda exhaustiva sería inviable. En lugar de \nbuscar un camino específico, como en la resolución de laberintos, la búsqueda local se \norienta a encontrar respuestas óptimas o subóptimas a preguntas complejas. Ejemplos de \nestas preguntas podrían ser: \"¿Cuál es la configuración más eficiente en la conducción de \nun automóvil autónomo?\" o \"¿Cómo se optimiza la topología de una red de datos?\". \nEs importante destacar que, debido a su naturaleza, la búsqueda local no garantiza \nencontrar la solución óptima global. Sin embargo, tiene la ventaja de ser \ncomputacionalmente \neficiente \ny, \nen \nmuchos \ncasos, \nproporciona \nsoluciones \n\"suficientemente buenas\" en un tiempo razonable. Esta característica la hace valiosa en \naplicaciones prácticas donde el tiempo y los recursos computacionales son limitados. \nSe define los siguientes términos en la búsqueda local: \nFunción Objetivo: Es la función que determina la calidad o el valor de una \nsolución en el espacio de búsqueda. El objetivo principal es maximizar esta función para \nobtener la solución más óptima, es decir, encontrar un máximo global. \nFunción de Costo: A diferencia de la función objetivo, la función de costo se \ncentra en minimizar el valor asociado a una solución. El propósito es reducir al mínimo \nel costo asociado a una solución, buscando así un mínimo global. \nEstado Actual: Representa la solución o nodo que el algoritmo está evaluando en \nun momento dado. Es el punto de referencia desde el cual se exploran las soluciones \nvecinas. \nEstado Vecino: Son aquellos estados o soluciones que están inmediatamente",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n139 \ncercanos o relacionados con el estado actual. En términos prácticos, un estado vecino se \nobtiene realizando pequeñas modificaciones al estado actual. Estos estados ofrecen \nalternativas ligeramente diferentes y son esenciales para la exploración y optimización en \nla búsqueda local. \nEl mecanismo fundamental de los algoritmos de búsqueda local radica en iniciar \ncon un estado actual y evaluar sus vecinos para determinar cuál de ellos ofrece una mejor \nsolución, ya sea maximizando la función objetivo o minimizando la función de costo. El \nalgoritmo se desplaza iterativamente hacia el mejor estado vecino y repite el proceso hasta \nque se cumpla un criterio de parada, como encontrar una solución que no pueda ser \nmejorada o alcanzar un número máximo de iteraciones. \nEsta metodología permite explorar de manera eficiente el espacio de soluciones, \nespecialmente en problemas complejos donde una búsqueda exhaustiva sería \ncomputacionalmente costosa. \nUn ejemplo clásico de búsqueda local en inteligencia artificial es el problema del \nViajante de Comercio (TSP, por sus siglas en inglés). En este problema, un viajante debe \nvisitar una serie de ciudades exactamente una vez y regresar al punto de partida, \nminimizando la distancia total recorrida. \nSupóngase que se tienen 4 ciudades (A, B, C, D) y las distancias entre ellas son \nlas siguientes: \nA-B: 10 km \nA-C: 15 km \nA-D: 20 km \nB-C: 35 km \nB-D: 20 km \nC-D: 30 km \nPasos: \n1) Inicialización: Se elige una ruta inicial aleatoria, por ejemplo, A -> B -> C -> D \n-> A. \n2) Función de Costo: La suma de las distancias entre las ciudades en la ruta. \nEstado Actual: A -> B -> C -> D -> A con un costo de 10 (A-B) + 35 (B-\nC) + 30 (C-D) + 20 (D-A) = 95 km. \n3) Estados Vecinos: Se genera rutas vecinas intercambiando dos ciudades en la ruta",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n140 \nactual. Por ejemplo, intercambiando B y C se obtiene A -> C -> B -> D -> A. \n4) Evaluación de Vecinos: Calculamos el costo de la nueva ruta: 15 (A-C) + 35 (C-\nB) + 20 (B-D) + 20 (D-A) = 90 km. \n5) Selección del Mejor Vecino: Comparamos el costo de la nueva ruta con el costo \ndel estado actual. Si es menor, actualizamos el estado actual con el nuevo estado. \n6) Iteración: Repetimos los pasos 4-6 hasta que no encontremos una mejora o hasta \nque alcancemos un número máximo de iteraciones. \nResultado: \nAl final del proceso, se tendría una ruta que es una solución aproximada al \nproblema del Viajante de Comercio. Es importante tener en cuenta que la búsqueda local \npodría no encontrar la solución óptima, pero generalmente encontrará una solución que \nes lo suficientemente buena en un tiempo razonable. \n3.3.2 Búsqueda de escalada de colinas \nLa escalada de colinas (Hill Climbing) es una variante especializada de los \nalgoritmos de búsqueda local, diseñada para encontrar soluciones óptimas en un espacio \nde estados (Minsky, 1961). En este enfoque, se parte de un estado inicial y se evalúan los \nestados vecinos utilizando una función específica, que puede ser una función objetivo \npara maximizar o una función de costo para minimizar. Si se encuentra un estado vecino \nque es mejor que el estado actual según la función de evaluación, se realiza un cambio, y \nese estado vecino se convierte en el nuevo estado actual. Este proceso se repite \niterativamente hasta que se alcanza un estado en el que ningún vecino ofrece una mejora, \nlo que se conoce como un máximo local en el caso de maximización o un mínimo local \nen el caso de minimización. \nUn algoritmo de escalada de colinas se verá de la siguiente manera en \npseudocódigo: \nFunción escaladaDeColinas(problema): \n    actual = estadoInicialDelProblema() \n    repetir: \n        vecino = mejorVecino(actual) \n        si valor(vecino) <= valor(actual): \n            retornar actual \n        actual = vecino \n \nEn este algoritmo, se inicia con un estado actual, en algunos problemas se verá",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n141 \ncuál es el estado actual, mientras que en otros se tiene que comenzar seleccionando uno \naleatoriamente. Luego, se repite las siguientes acciones: se evalúa a los vecinos, \nseleccionando el de mejor valor. Luego, se compara el valor de este vecino con el valor \ndel estado actual, si el vecino es mejor, se cambia el estado actual al estado vecino y luego \nse repite el proceso. El proceso finaliza cuando se compara el mejor vecino con el estado \nactual y el estado actual es mejor que el estado vecino. Luego, se devuelve el estado \nactual. \n \n3.3.2.1 Mínimos y máximos locales y globales \n \nFigura 3.5 Máximo global y Máximo local \nElaborado por los Autores \nUn algoritmo de escalada puede quedarse atascado en máximos o mínimos \nlocales. Un máximo global (figura 3.5) es un estado que tiene el valor más alto de todos \nlos estados en el espacio de estado. Un máximo local (figura 3.5) es un estado que tiene \nun valor más alto que sus estados vecinos, pero más bajo que el máximo global.   \n \nFigura 3.6 Mínimo global y Mínimo local \nElaborado por los Autores \nUn mínimo global (figura 3.6) es un estado que tiene el valor más bajo de todos \nlos estados en el espacio de estado. Un mínimo local (figura 3.6) es un estado que tiene \nun valor más bajo que sus estados vecinos.  \nEl problema con los algoritmos de escalada de colinas es que pueden terminar en \nmínimos y máximos locales. Una vez que el algoritmo alcanza un punto cuyos vecinos \nson peores, para el propósito de la función, que el estado actual, el algoritmo se detiene.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n142 \nLos tipos especiales de máximos y mínimos locales incluyen el máximo local plano \n(figura 3.7) y el mínimo local plano, donde varios estados de igual valor son adyacentes, \nformando una meseta cuyos vecinos tienen un valor peor debido a que la función de \nevaluación es plana constituyendo un máximo local plano, y el hombro (figura 3.7), \ndonde varios estados de igual valor son adyacentes y los vecinos de la meseta puede ser \ntanto mejor como peor. A partir de la mitad de la meseta, el algoritmo no podrá avanzar \nen ninguna dirección. \n \nFigura 3.7 Máximo local plano y hombro \nElaborado por los Autores \nUn ejemplo muy conocido de la utilización de la búsqueda de escalada de colinas \nen inteligencia artificial es el problema de las N-Reinas. El objetivo es colocar N reinas \nen un tablero de ajedrez de N x N de tal manera que ninguna reina pueda atacar a otra. En \notras palabras, no debe haber dos reinas en la misma fila, columna o diagonal.  \n \nFigura 3.8 N-Reinas \nFuente: Mi diario Python. Luis Salcedo \nEl algoritmo de escalada de colinas para el Problema de las N-Reinas es el \nsiguiente: \n1. Inicialización: Coloca las N reinas en posiciones aleatorias en el tablero. \n2. Evaluación del Estado Actual: Calcula el número de pares de reinas que se \natacan mutuamente. Este será la función objetivo que se intentará minimizar. \n3. Bucle Principal: \nGenerar Vecinos: Para cada reina, mueve su posición en su columna actual para",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n143 \ngenerar nuevos tableros vecinos. \nEvaluar Vecinos: Utiliza la función objetivo para evaluar qué tan bueno es cada \ntablero vecino. \nSeleccionar el Mejor Vecino: Escoge el tablero vecino con el menor número de \npares de reinas en conflicto. \nComparar con el Estado Actual: \n▪ Si el mejor vecino es mejor que el estado actual, mueve a ese estado. \n▪ Si no hay mejora, el algoritmo se detiene. \n4. Resultado: El estado final es una solución al problema, aunque no necesariamente \nla mejor solución posible. \nEste algoritmo es bastante simple y rápido, su problema es que puede quedarse \ndetenido en óptimos locales, es decir, soluciones que son mejores que sus vecinos \ninmediatos, pero no son las mejores soluciones posibles. \nLa Búsqueda de Escalada de Colinas es utiliza amplaimente en problemas de \noptimización y búsqueda heurística, como el diseño de redes neuronales, la planificación \nde rutas y la asignación de tareas (Haykin, 2009). \n3.3.3 Variantes de escalada de colinas \nDebido a las limitaciones de la búsqueda de escalada de colinas, se han pensado \nmúltiples variantes para superar el problema de quedarse atascado en mínimos y máximos \nlocales. Lo que todas las variaciones del algoritmo tienen en común es que, sin importar \nla estrategia, cada uno todavía tiene el potencial de terminar en mínimos y máximos \nlocales y no hay medios para continuar optimizando. Los algoritmos a continuación están \nredactados de tal manera que un valor más alto es mejor, pero también se aplican a las \nfunciones de costo, donde el objetivo es minimizar el costo. \n• Ascenso más pronunciado: Enfatiza la selección del vecino con la mayor \nmejora en el valor de aptitud (encontrar el máximo de una función) entre todos los vecinos \ngenerados en cada paso. Esta variante se centra en realizar el movimiento cuesta arriba \nmás significativo en el paisaje de aptitud. Si bien puede ser efectiva para encontrar \nrápidamente un máximo local, también puede quedar atrapada en regiones estrechas y \nempinadas del paisaje. \nFuncionamiento: \n1) Comenzar con un estado inicial.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n144 \n2) Evaluar la función de evaluación (o función de costo) del estado actual. \n3) Generar y evaluar todos los vecinos del estado actual. \n4) Seleccionar el vecino que tiene el mayor incremento en la función de evaluación \nen comparación con el estado actual. \n5) Si este vecino mejor tiene una evaluación más alta que el estado actual, moverse \na ese estado y repetir desde el paso 2. \n6) Si ningún vecino tiene una evaluación más alta que el estado actual, se ha \nencontrado un máximo local y el algoritmo termina. \nPseudocódigo: \nFunción AscensoMásPronunciado(estadoInicial): \n    estadoActual = estadoInicial \n    mientras no se alcance un máximo local o se alcance el número máximo \n    de iteraciones: \n        vecinos = generarVecinos(estadoActual) \n        mejorVecino = seleccionarMejorVecino(vecinos) \n        si el mejorVecino tiene un valor de función objetivo mayor que el \n        estadoActual: \n            estadoActual = mejorVecino \n        sino: \n               detenerse  #Alcanzamos un máximo local o una meseta \n   devolver estadoActual \nEl pseudocódigo presentado ilustra el núcleo del proceso de Ascenso más \npronunciado. Empieza con un estado inicial y, en cada ciclo, examina los estados \ncircundantes para determinar si alguno supera la función objetivo. Si identifica un vecino \nmás óptimo, el algoritmo se desplaza hacia ese estado y continua el proceso. Esta \ndinámica persiste hasta que se llega a un máximo local (donde no existe vecinos mejores) \no se cumple un límite preestablecido de iteraciones. \n• Estocástico: Se elije aleatoriamente entre los vecinos de mayor valor. Al hacer \nesto, se prefiere ir a cualquier dirección que mejore nuestro valor. Esto tiene sentido si, \npor ejemplo, el vecino de mayor valor conduce a un máximo local mientras que otro \nvecino conduce a un máximo global. Esto introduce un elemento de aleatoriedad que \npuede ayudar a escapar de óptimos locales. La escalada de colinas estocástica puede ser \nespecialmente útil en búsquedas que tienen muchos máximos locales. \nFuncionamiento: \n1) Comenzar con un estado inicial.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n145 \n2) Evaluar la aptitud (o función de costo) del estado actual. \n3) Generar una lista de todos los vecinos que tienen una mejor aptitud que el \nestado actual. \n4) Seleccionar aleatoriamente uno de estos vecinos y moverse a ese estado. \n5) Repetir los pasos 2-4 hasta que se cumpla un criterio de parada, como un \nnúmero máximo de iteraciones sin mejora o si no se encuentran vecinos \nmejores. \nPseudocódigo: \nFunción Estocástico(estadoInicial, iteraciones): \n    estadoActual = estadoInicial \n    para i en rango(iteraciones): \n        vecinoAleatorio = seleccionarVecinoAleatorio(estadoActual) \n        si evaluar(vecinoAleatorio) > evaluar(estadoActual): \n            estadoActual = vecinoAleatorio \n    devolver estadoActual \nEste pseudocódigo detalla un algoritmo estocástico básico. Inicia con un estado \ninicial y ejecuta un número preestablecido de iteraciones. Durante cada iteración, \nselecciona aleatoriamente un vecino del estado actual y evalúa si este vecino aleatorio es \nsuperior al estado actual de acuerdo con la función objetivo. En caso de ser más óptimo, \nel estado actual se reemplaza por el vecino aleatorio. Este procedimiento continúa durante \nun número determinado de iteraciones. \n• Primera elección: elige el primer vecino de mayor valor, sin necesidad de \nevaluar a todos los vecinos, comparado con el estado actual que se generó aleatoriamente. \nTan pronto como se encuentra un vecino que es mejor que el estado actual, se realiza el \ncambio. Los vecinos se suelen explorar en un orden aleatorio para evitar sesgos y para \ndarle al algoritmo una mayor capacidad de exploración. Este algoritmo es útil cuando el \nnúmero de vecinos es muy grande y evaluarlos todos sería computacionalmente costoso. \nFuncionamiento:  \n1) Partir de un estado inicial. \n2) Seleccionar aleatoriamente un vecino del estado actual. \n3) Si este vecino mejora el estado actual según la función de evaluación, se adopta \ncomo nuevo estado actual. \n4) Si no mejora, se selecciona otro vecino aleatoriamente y se repite el proceso. \n5) El algoritmo termina cuando se ha explorado un número determinado de vecinos",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n146 \nsin encontrar mejora o cuando se cumple otro criterio de parada. \nPseudocódigo: \nFunción PrimeraElección(estadoInicial, iteraciones): \n    estadoActual = estadoInicial \n    para i en rango(iteraciones): \n        vecinoAleatorio = seleccionarVecinoAleatorio(estadoActual) \n        si evaluar(vecinoAleatorio) > evaluar(estadoActual): \n            estadoActual = vecinoAleatorio \n            si evaluación(estadoActual) >= valorMeta: \n                devolver estadoActual  # Se alcanzó una solución aceptable \n    devolver estadoActual  # Se alcanzó el número máximo de iteraciones \nEste pseudocódigo ilustra el funcionamiento del algoritmo de Primera Elección, \nque es una variante de la búsqueda local. Comienza desde un estado inicial y realiza un \nnúmero especificado de iteraciones. En cada iteración, selecciona un vecino aleatorio del \nestado actual y evalúa si el vecino aleatorio es mejor que el estado actual según la función \nobjetivo. En caso de ser superior, el estado actual se actualiza al vecino aleatorio. El \nproceso se repite hasta que se alcanza una solución aceptable (según un criterio de parada) \no hasta que se alcanza el número máximo de iteraciones permitidas. \n• Algoritmos Genéticos: Estos algoritmos están inspirados en el proceso natural \nde la evolución biológica, utilizan una población de soluciones y aplican operaciones \ninspiradas en la genética, como la mutación y el cruce, para explorar el espacio de estados \n(Pham & Karaboga, 2012). Tienen la capacidad de explorar un amplio espacio de \nsoluciones y encontrar soluciones óptimas o subóptimas en problemas complejos. \nFuncionamiento: \n1) Inicializar una población de individuos de manera aleatoria. \n2) Evaluar la aptitud de cada individuo en la población. \n3) Seleccionar individuos para la reproducción basados en su aptitud. \n4) Aplicar operadores genéticos como el cruzamiento y la mutación para generar una \nnueva población. \n5) Repetir los pasos 2-4 hasta que se cumpla un criterio de parada, como un número \nmáximo de generaciones o una aptitud objetivo. \nPseudocódigo: \nAlgoritmoGenético(tamañoPoblación, tasaMutación, generaciones): \n    población = inicializarPoblaciónAleatoria(tamañoPoblación) \n    para generación en rango(generaciones):",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n147 \n        evaluación = evaluarPoblación(población) \n        nuevaPoblación = [] \n    mientras tamaño(nuevaPoblación) < tamañoPoblación: \n            padre1 = seleccionarPadre(población, evaluación) \n            padre2 = seleccionarPadre(población, evaluación) \n            hijo = cruzar(padre1, padre2) \n            si aleatorio() < tasaMutación: \n                mutar(hijo) \n            agregar hijo a nuevaPoblación \n        población = nuevaPoblación \n    devolver el mejor individuo de la población \nEl pseudocódigo describe un algoritmo genético. A continuación, se describen las \nfunciones principales del mismo: \n▪ inicializarPoblaciónAleatoria(tamañoPoblación): Crea una población inicial de \nindividuos de manera aleatoria. \n▪ evaluarPoblación(población): Evalúa cada individuo en la población utilizando una \nfunción de aptitud y devuelve sus valores de aptitud. \n▪ seleccionarPadre(población, evaluación): Selecciona un individuo para ser padre \nbasado en su aptitud relativa. \n▪ cruzar(padre1, padre2): Realiza la cruza (reproducción) entre dos padres para \ngenerar un hijo. \n▪ mutar(hijo): Aplica una mutación al hijo, posiblemente cambiando uno o más genes. \n▪ aleatorio(): Genera un valor aleatorio entre 0 y 1. \nEl algoritmo genético se ejecuta durante un número especificado de generaciones. \nEn cada generación, los individuos se evalúan en función de su aptitud, se seleccionan \npadres para reproducción, se realiza la cruza y, en algunos casos, se aplica una mutación. \nEl proceso se repite hasta alcanzar un número fijo de generaciones. \n• Reinicio aleatorio: Esta técnica ejecuta la escalada de colinas múltiples veces \ndesde distintos estados iniciales aleatorios. Su objetivo principal es superar la limitación \nde la escalada de colinas tradicional que tiende a estancarse en máximos (o mínimos) \nlocales. En vez de confinarse a una sola búsqueda desde un punto inicial, se exploran \ndiversas soluciones partiendo de diferentes estados. Tras repetir este proceso en \nnumerosas ocasiones, se opta por la solución más óptima encontrada entre todas las \niteraciones. \nFuncionamiento:",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n148 \n1) Establecer un número máximo de reinicios. \n2) Para cada reinicio: \na. Seleccionar un estado inicial al azar. \nb. Realizar la escalada de colinas desde ese estado inicial hasta que se encuentre \nun máximo local. \nc. Guardar la solución si es mejor que las soluciones anteriores. \n3) Al final de todos los reinicios, devolver la mejor solución encontrada. \nPseudocódigo: \nReinicioAleatorio(iteraciones, tasaReinicio): \n    mejorSolucion = SolucionAleatoria()  # Inicializar con una solución aleatoria \n    para i en rango(iteraciones): \n        solucionActual = MejorVecino(mejorSolucion)  # Encuentra el mejor vecino \n       si solucionActual es mejor que mejorSolucion: \n            mejorSolucion = solucionActual  # Actualiza la mejor solución \n       si aleatorio() < tasaReinicio: \n            mejorSolucion = SolucionAleatoria()  # Reinicia aleatoriamente \n    devolver mejorSolucion \nA continuación, se describen las funciones y componentes clave del pseudocódigo \nde un algoritmo de Reinicio Aleatorio. \niteraciones: Es el número máximo de iteraciones que se ejecutarán. \ntasaReinicio: La probabilidad de realizar un reinicio aleatorio en cada iteración. \nSolucionAleatoria(): Se genera una solución inicial aleatoria. \nMejorVecino(solucion): Encuentra el mejor vecino de la solución actual. Esto implica \nexplorar soluciones cercanas a la actual y seleccionar la mejor. \naleatorio(): Genera un valor aleatorio entre 0 y 1. \nEl algoritmo empieza con una solución inicial aleatoria. Luego, realiza un bucle \ndurante un número determinado de iteraciones. En cada iteración, busca el mejor vecino \nde la solución actual y compara si es mejor que la mejor solución conocida hasta ese \ninstante. De ser el caso de que sea superior, actualiza la mejor solución. Además, en cada \niteración, hay una probabilidad (tasaReinicio) de realizar un reinicio aleatorio, esto \nimplica que la búsqueda se reinicia desde una solución aleatoria en lugar de continuar \ndesde la solución actual. \n• Búsqueda de haz local: A diferencia de los algoritmos de búsqueda local \nconvencionales que trabajan con un único nodo, este enfoque mantiene y evalúa múltiples",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n149 \nestados simultáneamente. En cada iteración, selecciona los k vecinos más prometedores. \nAl operar con varias soluciones en paralelo, este método incrementa las probabilidades \nde hallar un óptimo global, evitando quedar atrapado en óptimos locales, un problema \ncomún en la escalada de colinas. No obstante, este beneficio viene acompañado de un \nmayor costo computacional, ya que se requiere evaluar varias soluciones en cada iteración \n(Russell & Norvig, 2021). \nFuncionamiento: \n1) Comienza con k estados iniciales generados aleatoriamente. \n2) En cada iteración, se exploran todos los vecinos de todos los k estados en el haz. \n3) De todos estos vecinos, se seleccionan los k mejores para formar el nuevo haz \npara la siguiente iteración. \nEl proceso se repite hasta que no se encuentren mejoras en el haz o hasta que se \ncumpla algún otro criterio de parada. \nPseudocódigo: \nBúsquedaHazLocal(k, iteraciones): \n    soluciones = GenerarKSolucionesIniciales(k)  # Genera k soluciones iniciales \naleatorias \n    para i en rango(iteraciones): \n        nuevasSoluciones = Vacío()  # Inicializa una lista vacía para almacenar las nuevas \nsoluciones \n     para solucion en soluciones: \n            vecinos = GenerarVecinos(solucion)  # Genera vecinos de la solución actual \n            mejorVecino = MejorVecino(vecinos)  # Encuentra el mejor vecino \n            agregar mejorVecino a nuevasSoluciones  # Agrega el mejor vecino a la lista de \nnuevas soluciones \n            soluciones = SeleccionarKSolucionesTop(nuevasSoluciones, k)  # Selecciona las \nmejores k soluciones \n     mejorSolucion = MejorSolucion(soluciones)  # Encuentra la mejor solución de todas \n     devolver mejorSolucion \nA continuación, se encuentra las funciones y componentes del pseudocódigo del \nalgoritmo de Búsqueda de Haz Local. \nk: El número de soluciones en el conjunto de haces. \niteraciones: El número máximo de iteraciones que se ejecutarán. \nGenerarKSolucionesIniciales(k): Genera k soluciones iniciales aleatorias. \nGenerarVecinos(solucion): Genera los vecinos de una solución dada. \nMejorVecino(vecinos): Encuentra el mejor vecino entre un conjunto de vecinos.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n150 \nSeleccionarKSolucionesTop(soluciones, k): Selecciona las mejores k soluciones entre \ntodas las soluciones generadas. \nMejorSolucion(soluciones): Encuentra la mejor solución entre todas las soluciones \nfinales. \nEmpieza el algoritmo generando k soluciones iniciales aleatorias. A continuación, \nse ejecuta un bucle durante un número determinado de iteraciones. En cada iteración, se \ngenera vecinos para cada solución en el conjunto de haces, encuentra el mejor vecino y \nprocede a agregarle a la lista de nuevas soluciones. \nAl concluir cada iteración, se escogen las mejores k soluciones de la lista de \nnuevas soluciones y se actualiza el conjunto de haces con esas soluciones. Finalmente, \ndespués de todas las iteraciones, el algoritmo encuentra la mejor solución entre todas las \nsoluciones finales y la devuelve como resultado. \n• Optimización por Enjambre de Partículas: Esta técnica, inspirada en el \ncomportamiento colectivo de aves y peces, utiliza \"partículas\" que representan soluciones \nen un espacio de búsqueda. A diferencia de la búsqueda de haz local, en la optimización \npor ejambre de particulas, las partículas ajustan su posición no solo en función de su \npropia experiencia, sino también de la de sus vecinos. Cada partícula posee una posición, \nque simboliza una solución potencial; una velocidad, que indica su movimiento; y una \nmemoria, que almacena su mejor posición hallada. Una particularidad distintiva es la \ncolaboración entre partículas, compartiendo información y orientando al enjambre hacia \nzonas del espacio de búsqueda que muestran ser prometedoras, todo ello fundamentado \nen las vivencias acumuladas por el conjunto de partículas (Benítez et al., 2014). \nFuncionamiento: \n1) Inicialización: Se crea un enjambre de partículas con posiciones y velocidades \naleatorias. \n2) Evaluación: Cada partícula evalúa su posición actual utilizando una función \nobjetivo. \n3) Actualización de la memoria: Si la posición actual de una partícula es mejor \n(según la función objetivo) que su mejor posición conocida, se actualiza su \nmemoria. \n4) Actualización de la velocidad y posición: La velocidad de cada partícula se ajusta \nen función de su memoria y de la mejor posición encontrada por todo el enjambre.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n151 \nLuego, se actualiza la posición de la partícula basándose en su velocidad. \n5) Iteración: Los pasos 2 a 4 se repiten hasta que se cumpla un criterio de parada, \ncomo un número máximo de iteraciones o una mejora mínima en la función \nobjetivo. \nPseudocódigo: \nOptimizaciónEjambrePartículas(iteraciones, tamañoEnjambre, c1, c2): \n    enjambre = InicializarEnjambreAleatoriamente(tamañoEnjambre)  # Inicializa el \nenjambre con partículas aleatorias \n    para i en rango(iteraciones): \n        para cada partícula en enjambre: \n            calcular la aptitud de la partícula  # Evalúa la calidad de la solución \n            si la aptitud es mejor que la mejor aptitud personal de la partícula: \n                actualizar la mejor aptitud personal de la partícula \n                actualizar la mejor posición personal de la partícula \n            encontrar la partícula con la mejor aptitud personal en todo el enjambre \n            para cada partícula en enjambre: \n                actualizar la velocidad y posición de la partícula: \n                    velocidad = velocidad + c1 * rand() * (mejor posición personal - posición \nactual) \n                    velocidad = velocidad + c2 * rand() * (mejor posición global - posición \nactual) \n                    posición = posición + velocidad \n   encontrar la partícula con la mejor aptitud global en todo el enjambre \n    devolver la mejor posición global encontrada \nEl pseudocódigo describe el algoritmo Optimización por Enjambre de Partículas, \na continuación, se indican las variables y componentes importantes involucrados: \niteraciones: El número máximo de iteraciones que se ejecutarán. \ntamañoEnjambre: El número de partículas en el enjambre. \nc1 y c2: Coeficientes de aceleración que controlan la influencia de la mejor posición \npersonal y la mejor posición global en el movimiento de las partículas. \nInicializarEnjambreAleatoriamente(tamañoEnjambre): Inicializa el enjambre con \nposiciones y velocidades aleatorias.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n152 \ncalcular la aptitud de la partícula: Evalúa la calidad de la solución representada por \nla partícula. \nmejor posición personal: La mejor posición alcanzada por una partícula individual. \nmejor posición global: La mejor posición alcanzada por cualquier partícula en el \nenjambre. \nEl algoritmo Optimización por Enjambre de Partículas inicia con un enjambre de \npartículas con posiciones y velocidades aleatorias. Durante un número determinado de \niteraciones, cada partícula evalúa su aptitud y, si es superior a su mejor registro personal, \nactualiza su posición. Se identifica la partícula con la aptitud más destacada del enjambre. \nPosteriormente, se ajustan la velocidad y posición de cada partícula basándose en las \nmejores posiciones personales y globales, influenciadas por los coeficientes c1 y c2. Al \nconcluir las iteraciones, el algoritmo determina la partícula con la mejor aptitud global, \npresentando su posición como la solución óptima o aproximada al problema de \noptimización. \n• Búsqueda tabú: Esta técnica metaheurística de optimización se caracteriza por \nmantener una lista de los estados recientemente explorados, denominada \"lista tabú\", para \nprevenir su reexploración inmediata. Su objetivo es optimizar soluciones evitando quedar \natrapado en óptimos locales. Para ello, no solo se apoya en su memoria a corto plazo, sino \nque también implementa estrategias de diversificación, que permiten abordar distintas \nregiones del espacio de soluciones, y estrategias de intensificación, que se centran en \ninvestigar detalladamente áreas con potencial prometedor (Benítez et al., 2014). \nFuncionamiento: \n1) Iniciar con una solución inicial y se evalúa su calidad. \n2) En cada iteración, se generan soluciones vecinas y se selecciona la mejor, incluso \nsi es peor que la solución actual. \n3) La solución seleccionada se añade a la lista tabú. \nPseudocódigo: \nBúsquedaTabú(iteraciones, tamañoListaTabú): \n    soluciónActual = GenerarSoluciónInicial()  # Genera una solución inicial aleatoria \n    mejorSolución = soluciónActual \n    listaTabú = ListaVacia() \n   para i en rango(iteraciones): \n        vecindario = GenerarVecindario(soluciónActual)  # Genera un vecindario de \nsoluciones vecinas",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n153 \n        mejorVecino = NULL \n        for cada vecino en vecindario: \n            si vecino no está en listaTabú y aptitud(vecino) < aptitud(mejorVecino): \n                mejorVecino = vecino \n        si mejorVecino es NULL: \n            detener  # No se encontró un mejor vecino válido \n       soluciónActual = mejorVecino \n       si aptitud(mejorVecino) < aptitud(mejorSolución): \n            mejorSolución = mejorVecino \n       agregar mejorVecino a listaTabú \n        si tamaño de listaTabú > tamañoListaTabú: \n            eliminar el elemento más antiguo de listaTabú \n devolver mejorSolución \nA continuación, se describe el pseudocódigo del algoritmo de Búsqueda Tabú, sus \nvariables y componentes importantes: \niteraciones: El número máximo de iteraciones que se ejecutarán. \ntamañoListaTabú: El tamaño máximo de la lista tabú que almacena soluciones prohibidas \nrecientes. \nGenerarSoluciónInicial(): Genera una solución inicial aleatoria. \nGenerarVecindario(soluciónActual): Genera un vecindario de soluciones vecinas a partir \nde la solución actual. \naptitud(solución): Evalúa la calidad de una solución dada (menos es mejor). \nListaVacia(): Inicializa una lista tabú vacía. \nEl algoritmo inicia con una solución aleatoria, considerándola como la mejor hasta \nese momento. En cada iteración, genera soluciones vecinas y selecciona el mejor vecino \nque no este en la lista tabú con aptitud superior. Si este vecino supera la mejor solución \nactual, se actualiza. Este vecino se añade a la lista tabú, eliminando el elemento más \nantiguo si se excede el tamaño máximo de la lista. Tras un número determinado de \niteraciones, el algoritmo presenta la mejor solución hallada como la respuesta óptima o \naproximada al problema de optimización. \n3.3.4 Recocido simulado \nEl algoritmo de Recocido Simulado, también conocido como Simulated \nAnnealing en inglés, se destaca como una estrategia robusta para abordar el problema de \nquedar atrapado en óptimos locales en la búsqueda de escalada de colinas. Su concepto \nse inspira en la metalurgia, donde se calienta un metal y luego se permite que se enfríe",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n154 \ngradualmente para mejorar sus propiedades mecánicas. De manera análoga, el algoritmo \nde Recocido Simulado opera en la búsqueda de soluciones óptimas. \nEl proceso comienza con el algoritmo funcionando a una \"temperatura\" alta, lo \nque implica que tiene una alta probabilidad de tomar decisiones aleatorias. A medida que \nesta \"temperatura\" disminuye durante el proceso, el algoritmo se vuelve más \"selectivo\", \nes decir, reduce la probabilidad de tomar decisiones aleatorias. Este mecanismo de \nenfriamiento controlado es fundamental, ya que permite al algoritmo explorar estados \nvecinos que podrían ser peores que el estado actual, lo que evita quedar atrapado en \nmáximos locales. \nA continuación, se presenta un pseudocódigo para el algoritmo de Recocido \nSimulado: \nfunción RecocidoSimulado(problema, máx): \n    actual = estadoInicial del problema \n    para t de 1 a máx: \n        T = Temperatura(t) \n        vecino = vecinoAleatorio del actual \n        ΔE = diferencia de aptitud entre el vecino y el estado actual \n        si ΔE > 0: \n            actual = vecino \n        sino, con probabilidad e(ΔE/T) conjunto actual = vecino \n    retornar actual \nEste algoritmo toma como entrada un problema y el número máximo de \niteraciones a realizar. En cada iteración, se establece la temperatura T mediante una \nfunción de temperatura. Esta función devuelve un valor más alto en las primeras \niteraciones (cuando t es bajo) y un valor más bajo en las iteraciones posteriores (cuando \nt es alto). Luego, se selecciona un vecino aleatorio y se calcula ΔE, que mide cuánto mejor \nes el vecino en comparación con el estado actual. \nSi ΔE es positivo, lo que significa que el vecino es mejor que el estado actual, se \nestablece el estado actual como el vecino. Sin embargo, cuando ΔE es negativo, lo que \nindica que el vecino es peor, aún existe la posibilidad de que el estado actual se establezca \ncomo el vecino. Esta probabilidad se calcula mediante la fórmula e(ΔE/T). Cuanto más \nnegativo sea ΔE, menor será la probabilidad de seleccionar el vecino, y cuanto mayor sea \nla temperatura T, mayor será la probabilidad de aceptar un vecino peor. \nEl Recocido Simulado es una estrategia eficaz para explorar soluciones en \nproblemas de optimización, permitiendo movimientos hacia estados peores en busca de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n155 \nuna solución global óptima (Russell & Norvig, 2021). A medida que disminuye la \ntemperatura, se vuelve más selectivo y tiende a converger hacia la mejor solución \nencontrada hasta el momento. Esta propiedad lo hace valioso en la resolución de \nproblemas complejos donde se desea evitar quedar atrapado en óptimos locales.  \nUn ejemplo interesante de la aplicación del algoritmo de Recocido Simulado en \nInteligencia Artificial es el problema de la Mochila. En este problema, se tiene una \nmochila con una capacidad de peso máxima y un conjunto de objetos, cada uno con un \npeso y un valor. El objetivo es seleccionar un subconjunto de objetos de tal manera que \nel peso total no exceda la capacidad de la mochila y el valor total sea máximo. \nPseudocódigo de Recocido Simulado para el Problema de la Mochila. \n1. Inicializar solución_actual con una selección aleatoria de objetos \n2. Inicializar mejor_solución con solución_actual \n3. Inicializar temperatura = 1000 (valor alto) \n4. Inicializar factor_enfriamiento = 0.99 \nMientras temperatura > 1: \n    1. Generar solución_vecina cambiando un objeto aleatorio en solucion_actual \n    2. Calcular delta_valor = valor(solución_vecina) - valor(solución_actual) \n    3. Si delta_valor > 0: \n        - Actualizar solución_actual = solución_vecina \n        - Si valor(solución_actual) > valor(mejor_solución): \n            - Actualizar mejor_solución = solución_actual \n    4. Si no: \n        - Generar un número aleatorio r entre 0 y 1 \n        - Si r < exp(delta_valor / temperatura): \n            - Actualizar solución_actual = solución_vecina \n    5. Reducir la temperatura: temperatura *= factor_enfriamiento \nExplicación: \nInicialización: Se comienza con una solución inicial aleatoria y una temperatura alta. \nBucle Principal: El algoritmo entra en un bucle donde se generan soluciones vecinas y se \nevalúan. \nGeneración de Vecinos: Se crea una solución vecina cambiando un objeto aleatorio en la \nsolución actual.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n156 \nEvaluación de Valor: Se calcula la diferencia de \"valor\" entre la solución vecina y la \nsolución actual. \nActualización de Solución: Si la solución vecina es mejor (mayor valor), se acepta como \nla nueva solución actual. Si es peor, podría aceptarla con una probabilidad que disminuye \ncon la temperatura. \nEnfriamiento: Se reduce la temperatura según un factor de enfriamiento y repite el \nproceso. \nAl final del algoritmo, mejor_solución contendrá la mejor solución encontrada \npara el problema de la mochila. \nEste algoritmo es especialmente útil en problemas de optimización combinatoria \ny ha demostrado su eficacia en una variedad de aplicaciones prácticas en inteligencia \nartificial. \nEl algoritmo de Recocido Simulado tiene diversas aplicaciones en el campo de la \nInteligencia Artificial y la optimización. A continuación, estas son algunas de las áreas \ndonde este algoritmo es especialmente útil: \n1. Optimización Combinatoria \n    Problema del Viajante de Comercio (TSP) \n    Problema de la Mochila \n    Problema de Asignación de Tareas \n2. Aprendizaje Automático \nSelección de Características: Para mejorar la eficiencia de los modelos de aprendizaje \nautomático. \nOptimización de Hiperparámetros: Para encontrar la mejor configuración de un \nmodelo de aprendizaje automático. \n3. Robótica \nPlanificación de Rutas para Robots: Optimización de la trayectoria que debe seguir un \nrobot para completar una tarea. \n4. Redes de Computadoras \nBalanceo de Carga: Para distribuir eficientemente las tareas entre diferentes \nservidores. \nOptimización de Redes: Para encontrar la ruta más eficiente para el envío de paquetes \nde datos.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n157 \n5. Logística y Cadena de Suministro \nOptimización de Rutas de Entrega: Para encontrar la ruta más eficiente para la entrega \nde productos. \n6. Diseño VLSI (Very Large Scale Integration) \nUbicación de Componentes: Para optimizar la disposición de componentes en un chip. \n7. Bioinformática \nAlineación de Secuencias: Para encontrar la mejor alineación entre dos secuencias de \nADN, ARN o proteínas. \n8. Juegos y Estrategias \nResolución de Puzzles y Juegos de Tablero: Como el Sudoku o el problema de las N-\nreinas. \n9. Energía y Medio Ambiente \nOptimización de Sistemas de Energía: Para encontrar la configuración más eficiente en \nsistemas de energía renovable. \n10. Finanzas \nOptimización de Portafolios: Para encontrar la combinación óptima de activos \nfinancieros. \nEl Recocido Simulado es un algoritmo versátil que se adapta bien a problemas que \ntienen un gran espacio de soluciones y donde se busca una solución óptima o cercana a la \nóptima en un tiempo razonable. \n3.3.5 Programación lineal \nLa programación lineal es una familia de problemas que optimizan una ecuación \nlineal (una ecuación de la forma y = ax₁ + bx₂ + …). \nLa programación lineal tendrá los siguientes componentes: \n• Una función de costo que se quiere minimizar: c₁x₁ + c₂x₂ + … + cₙxₙ. Aquí, cada x₋ es \nuna variable y está asociada con algún costo c₋. \n• Una restricción que se representa como una suma de variables que es menor o igual a \nun valor (a₁x₁ + a₂x₂ + … + aₙxₙ ≤ b) o exactamente igual a este valor (a₁x₁ + a₂x₂ + … + \naₙxₙ = b). En este caso, x₋ es una variable, y a₋ es algún recurso asociado a ella, y b es \ncuántos recursos se puede dedicar a este problema. \n• Límites individuales en las variables (por ejemplo, que una variable no puede ser \nnegativa) de la forma lᵢ ≤ xᵢ ≤ uᵢ.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n158 \nConsidere el siguiente ejemplo: \n• Dos máquinas, X₁ y X₂. X₁ cuesta $40/hora para funcionar, X₂ cuesta $70/hora para \nfuncionar. El objetivo es minimizar el costo. Esto se puede formalizar como una función \nde costo: 40x₁ + 70x₂. \n• X₁ requiere 6 unidades de trabajo por hora. X₂ requiere 3 unidades de trabajo por hora. \nTotal de 22 unidades de mano de obra a gastar. Esto se puede formalizar como una \nrestricción: 6x₁ + 3x₂ ≤ 22. \n• X₁ produce 10 unidades de salida por hora. X₂ produce 14 unidades de salida por hora. \nLa empresa necesita 95 unidades de producción. Esta es otra restricción. Literalmente, se \npuede reescribir como 10x₁ + 14x₂ ≥ 95. Sin embargo, las restricciones deben tener la \nforma (a₁x₁ + a₂x₂ + … + aₙxₙ ≤ b) o (a₁x₁ + a₂x₂ + … + aₙxₙ = b). Por lo tanto, \nmultiplicamos por (-1) para obtener una ecuación equivalente de la forma deseada: (-\n10x₁) + (-14x₂) ≤ -95. \nUn algoritmo de optimización para programación lineal requiere conocimientos \nprevios en geometría y álgebra lineal que no queremos asumir, en su lugar, se puede usar \nalgoritmos que ya existen en diferentes lenguajes. \n3.3.6 Satisfacción de restricciones \nLos problemas de satisfacción de restricciones tienen un conjunto de variables, un \nconjunto de dominios (cada uno asociado a una variable) y un conjunto de restricciones. \nSon una clase de problemas en los que es necesario asignar valores a las variables \nmientras se satisfacen algunas series de restricciones o condiciones.  \n \nFigura 3.9 Cursos que toman los estudiantes \nElaborado por los Autores",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n159 \nLos problemas de satisfacción de restricciones tienen las siguientes propiedades: \n• Conjunto de variables (x₁, x₂, …, xₙ) \n• Conjunto de dominios para cada variable {D₁, D₂, …, Dₙ} \n• Conjunto de restricciones C \n \nConsidere el siguiente ejemplo (figura 3.9) en que cada uno de los estudiantes \n1,2,3,4 está tomando tres cursos de los siguientes A, B, C, D, E, F, G. Cada curso debe \ntener un examen, y los días posibles para los exámenes son los lunes, martes y miércoles. \nSin embargo, el mismo estudiante no puede tener dos exámenes el mismo día. En este \ncaso, las variables son los cursos, el dominio son los días y las restricciones son qué cursos \nno se pueden programar para tener un examen el mismo día porque los está tomando el \nmismo estudiante.  \n \nFigura 3.10 Grafo de los cursos \nElaborado por los Autores \nEste problema se puede resolver empleando restricciones que se representan como \nun gráfico. Cada nodo del gráfico (figura 3.10) es un curso distinto, y se pone la \nrestricción entre dos cursos que es de que no se pueden programar para el mismo día.  \nAlgunos términos que vale la pena conocer sobre los problemas de satisfacción de \nrestricciones son: \n• Una Restricción Fuerte es una restricción que debe ser satisfecha en una \nsolución correcta. \n• Una Restricción Suave es una restricción que expresa qué solución se prefiere \nsobre otras. \n• Una Restricción Unaria es una restricción que involucra solo una variable. En \nnuestro ejemplo, una restricción unaria sería decir que el curso A no puede tener un \nexamen el lunes {A ≠ lunes}.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n160 \n• Una Restricción Binaria es una restricción que involucra dos variables. Este es \nel tipo de restricción que usamos en el ejemplo, se dice que dos cursos no pueden tener el \nmismo valor {A ≠ B} con respecto al día del examen. \n3.3.6.1 Consistencia de nodo \nEn el ámbito de la programación de restricciones, la \"consistencia del nodo\" se \nrefiere a la condición en la que todos los valores en el dominio de una variable particular \ncumplen con las restricciones unarias asociadas a esa variable (Russell & Norvig, 2021). \nEn otras palabras, cada valor que la variable puede tomar es viable según las restricciones \nimpuestas sobre ella. \nPara que un nodo (variable) sea consistente: \n1. Todos los valores dentro de su dominio deben cumplir cualquier restricción unaria \nque se aplique a esa variable. \n2. Si un valor en el dominio de una variable no cumple con la restricción unaria, ese \nvalor se excluye del dominio. \nContinuando con el ejemplo anterior, se tiene dos cursos, A y B. El dominio de \ncada curso es {lunes, martes, miércoles} y las restricciones son {A ≠ lunes, B ≠ martes, \nB ≠ lunes, A ≠ B}. Ahora, ni A ni B son consistentes, porque las restricciones existentes \nles impiden tomar todos los valores que están en su dominio. Sin embargo, si eliminamos \nel lunes del dominio de A, tendrá consistencia de nodo. Para lograr la consistencia del \nnodo en B, se tendrá que eliminar tanto el lunes como el martes de su dominio. \nLa verificación de la consistencia del nodo es un paso importante en algoritmos \nde programación de restricciones como el backtracking, debido a que ayuda a reducir el \nespacio de búsqueda y a eliminar asignaciones que no conducirán a una solución válida, \noptimizando así el proceso de resolución del problema (Shi, 2019). \n3.3.6.2 Consistencia del arco \nLa consistencia de arco es cuando todos los valores en el dominio de una variable \nsatisfacen las restricciones binarias de la variable. Por lo que se debe verificar y asegurar \nde que, para cada valor en el dominio de una variable, exista algún valor en el dominio \nde otra variable que satisface la restricción binaria entre ambas variables. En otras \npalabras, para hacer que X sea coherente con el arco con respecto a Y, elimine elementos \ndel dominio de X hasta que cada opción para X tenga una opción posible para Y. \nPara que un arco (una restricción binaria entre dos variables) sea consistente:",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n161 \n1. Para cada valor en el dominio de la primera variable, debe existir al menos un valor en \nel dominio de la segunda variable que satisface la restricción binaria entre ambas. \n2. Si no existe tal valor para algún valor de la primera variable, ese valor se elimina del \ndominio de la primera variable. \nConsidérese el ejemplo de los estudiantes con los dominios revisados: A :{martes, \nmiércoles} y B:{miércoles}. Para que A tenga coherencia del arco con B, sin importar el \ndía en que se programe el examen de A (desde su dominio), B aún podrá programar un \nexamen. ¿Es A arco-consistente con B? Si A toma el valor martes, entonces B puede \ntomar el valor miércoles. Sin embargo, si A toma el valor miércoles, entonces no hay \nvalor que B pueda tomar (recuerde que una de las restricciones es A ≠ B). Por lo tanto, A \nno es arco-consistente con B. Para cambiar esto, se puede eliminar miércoles del dominio \nde A. Entonces, cualquier valor que tome A (el martes es la única opción) deja un valor \npara que lo tome B (miércoles). Ahora, A es consistente del arco con B. Veamos un \nalgoritmo en pseudocódigo que hace que una variable sea consistente con el arco con \nrespecto a alguna otra variable. En estos problemas, generalmente se tienen variables que \npueden tomar ciertos valores y restricciones que limitan las combinaciones posibles de \nestos valores. El objetivo es encontrar una asignación de valores a las variables de manera \nque se satisfagan todas las restricciones. \nfunción Revisar(restrición, X, Y):    \n    revisado = falso \n    # Iterar sobre cada valor en el dominio de X \n    para cada x en X.dominio: \n        # Verificar si existe algún valor y en el dominio de Y que satisface la restricción \n       si no existe y en Y.dominio tal que restricción(x, y) sea verdadero: \n               eliminar x de X.dominio \n               revisado = verdadero \n    # Retornar si se hizo alguna modificación en el dominio de X \n    retorne revisado \nEste algoritmo comienza rastreando si se realizó algún cambio en el dominio de \nX, utilizando la variable revisado. Esto será útil en el próximo algoritmo que se examine. \nLuego, el código se repite para cada valor en el dominio de X y ve si Y tiene un valor que \nsatisface las restricciones. Si es así, entonces no haga nada, si no, elimine este valor del \ndominio de X. \nA menudo se está interesado en hacer que todo el problema sea consistente y no \nsolo una variable con respecto a otra. En este caso, se utiliza un algoritmo llamado PM,",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n162 \nque usa Revisar: \nfunción PM(restricción): \n    cola = todos los arcos con la restricción \n    mientras cola no esté vacía: \n        (X, Y) = Quitar de la cola (cola) \n        si Revisar(restricción, X, Y): \n            si tamaño del dominio de X == 0: \n                retorne falso \n            para cada Z en X.vecinos - {Y}: \n                Poner en cola (Z, X) \n    retorne verdadero \nEste algoritmo agrega todos los arcos del problema a una cola. Cada vez que \nconsidera un arco, lo elimina de la cola. Luego, ejecuta en el algoritmo Revisar para ver \nsi este arco es consistente. Si se hicieron cambios para hacerlo consistente, se necesitan \nmás acciones. Si el dominio resultante de X está vacío, significa que este problema de \nsatisfacción de restricciones no tiene solución (debido a que no hay valores que X pueda \ntomar que permitan que Y tome cualquier valor dadas las restricciones). Si el problema \nno se considera irresoluble en el paso anterior, entonces, dado que se cambió el dominio \nde X, debemos ver si todos los arcos asociados con X aún son consistentes. Es decir, \ntomamos todos los vecinos de X excepto Y, y agregamos los arcos entre ellos y X a la \ncola. Sin embargo, si en el algoritmo Revisar devuelve falso, lo que significa que el \ndominio no cambió, simplemente continuamos considerando los otros arcos. \nSi bien el algoritmo para la consistencia del arco puede simplificar el problema, \nno necesariamente lo resolverá, debido a que solo considera las restricciones binarias y \nno cómo se pueden interconectar varios nodos. Nuestro ejemplo anterior, donde cada uno \nde los 4 estudiantes está tomando 3 cursos, permanece sin cambios al ejecutar PM en él. \nUn problema de satisfacción de restricciones puede verse como un problema de \nbúsqueda: \n• Estado inicial: asignación vacía (todas las variables no tienen ningún valor \nasignado). \n• Acciones: agregue una {variable = valor} a la asignación; es decir, dar un valor \na alguna variable. \n• Modelo de transición: muestra cómo al agregar la tarea cambia la tarea. No hay \nmucha profundidad en esto: el modelo de transición devuelve el estado que incluye la \nasignación después de la última acción.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n163 \n• Prueba de objetivo: comprobar si a todas las variables se les asigna un valor y \nse cumplen todas las restricciones. \n• Función de coste del trayecto: todos los trayectos tienen el mismo coste. Como \nse mencionó anteriormente, a diferencia de los típicos problemas de búsqueda, los \nproblemas de optimización se preocupan por la solución y no por la ruta a la solución. \nSin embargo, resolver ingenuamente un problema de satisfacción de \nrestricciones, como un problema de búsqueda regular, es enormemente ineficiente. En \ncambio, se puede hacer uso de la estructura de un problema de satisfacción de \nrestricciones para resolverlo de manera más eficiente. \n3.3.7 Búsqueda de retroceso \nLa búsqueda de retroceso es un algoritmo de búsqueda utilizado en problemas de \nsatisfacción de restricciones. Este algoritmo se basa en una función recursiva que asigna \nvalores a las variables del problema, respetando las restricciones establecidas. En caso de \nque una asignación viole alguna restricción, el algoritmo intenta una asignación diferente. \nA continuación, se presenta el pseudocódigo: \nfunción Retroceder (asignación, psr): \n1. Si la asignación está completa: \n• Retornar asignación. \n2. var = SeleccionarVariableSinAsignar(asignación, psr). \n3. Para cada valor en DominioDeValores(var, asignación, psr): \n• Si el valor es consistente con la asignación actual: \no Agregar {var = valor} a la asignación. \no resultado = Retroceder(asignación, psr). \no Si resultado ≠ falla: \n▪ Retornar resultado. \no Eliminar {var = valor} de la asignación. \n4. Retornar falla. \nEl algoritmo comienza verificando si la asignación actual está completa. Si es así, \nretorna la asignación debido a que todas las variables han sido asignadas de forma \nsatisfactoria. Si la asignación no está completa, selecciona una variable sin asignar y \nprueba cada valor posible en su dominio. Si un valor es consistente con las restricciones \nactuales, lo agrega a la asignación y llama recursivamente a la función Retroceder con la \nnueva asignación. Si esta llamada recursiva no resulta en un error, el algoritmo ha \nencontrado una asignación válida y la retorna. En caso de que todas las asignaciones \nposibles para una variable fallen, se elimina la asignación de esa variable y se retorna un",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n164 \nerror, lo que induce el \"retroceso\" a una asignación anterior y la reconsideración de otras \nalternativas. \nConsidere el siguiente proceso de acción: \nSe comienza con asignaciones vacías. Luego a la variable A (figura 3.11) se le \nasigna un valor, por ejemplo, Lunes. A continuación, usando esta asignación, se ejecuta \nel algoritmo nuevamente. Ahora que A ya tiene una asignación, el algoritmo considerará \nB y le asignará el Lunes. Esta asignación devuelve falso, por lo que, en lugar de asignar \nun valor a C dada la asignación anterior, el algoritmo intentará asignar un nuevo valor a \nB, por ejemplo, Martes. Esta nueva asignación satisface las restricciones y, a \ncontinuación, se considerará una nueva variable dada esta asignación.  \nSi, por ejemplo, asignar también Martes o Miércoles a B falla, entonces el \nalgoritmo retrocederá y volverá a considerar A, asignándole otro valor, por ejemplo \nMartes. Si el martes y el miércoles también fallan, significa que se ha intentado todas las \nasignaciones posibles y el problema no tiene solución. El algoritmo de retroceso se usa \nampliamente y, como tal, varias bibliotecas ya contienen una implementación del mismo. \n \nFigura 3.11 Asignación de días a las variables \nElaborado por los Autores \n3.3.8 Inferencia \nAunque la búsqueda de retroceso es más eficiente que la búsqueda simple, aún \nrequiere mucha potencia computacional. Hacer cumplir la consistencia del arco, por otro \nlado, requiere menos recursos. Al intercalar la búsqueda de retroceso con la inferencia",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n165 \n(reforzando la consistencia del arco), se puede tener un algoritmo más eficiente. Este \nalgoritmo se denomina algoritmo de mantenimiento de la consistencia del arco. Este \nalgoritmo hará cumplir la consistencia de arco después de cada nueva asignación de la \nbúsqueda de retroceso. Específicamente, después de realizar una nueva asignación a X, \nllamaremos al algoritmo PM y lo iniciaremos con una cola de todos los arcos (Y,X) donde \nY es un vecino de X (y no una cola de todos los arcos en el problema). A continuación, \nse muestra un algoritmo de retroceso revisado que mantiene la consistencia del arco, con \nlas nuevas incorporaciones en negrita. \nfunción Retroceder (asignación, psr): \n• si la asignación está completa: \no retorne la asignacción \n• var = Seleccionar-Sin asignar-Var(asignación, psr) \n• para valor en Dominio-Valores (var, asignación, psr): \no si el valor es consistente con la asignación: \n▪ agregar {var = valor} a la asignación \n▪ inferencias = Inferencia (asignación, psr) \n▪ si inferencias ≠ falla: \n                      adicionar inferencias a la asignación \n▪ resultado = Retroceder (asignación, psr) \n▪ si resultado ≠ falla: \n                        retornar resultado  \n▪ eliminar {var = valor} y inferencias de la asignación \n• retornar error \nLa función de inferencia ejecuta el algoritmo PM como se describe. Su salida son \ntodas las inferencias que se pueden hacer mediante la aplicación de la consistencia de \narco. Literalmente, estas son las nuevas asignaciones que se pueden deducir de las \nasignaciones anteriores y la estructura del problema de satisfacción de restricciones. \nHay formas adicionales de hacer que el algoritmo sea más eficiente. Hasta ahora, \nse selecciona aleatoriamente una variable no asignada. Sin embargo, es más probable que \nalgunas opciones lleven a una solución más rápida que otras. Esto requiere el uso de \nheurísticas. Una heurística es una regla empírica, lo que significa que, la mayoría de las \nveces, dará un mejor resultado que seguir un enfoque ingenuo, pero no se garantiza que \nasí sea. \nLos valores mínimos restantes (VMR) son una de esas heurísticas. La idea aquí \nes que, si el dominio de una variable se restringió por inferencia, y ahora solo le queda un \nvalor (o incluso si son dos valores), al hacer esta asignación se reduce la cantidad de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n166 \nretrocesos que se podría necesitar hacer más adelante. \n Es decir, se tendrá que hacer esta asignación tarde o temprano, debido a que se \ndeduce de la aplicación de la consistencia de arco. Si esta tarea fracasa, es mejor averiguar \nlo antes posible y no retroceder más tarde.  \n \nFigura 3.12 Uso de la heurística VMR \nElaborado por los Autores \n \nPor ejemplo, después de haber acotado los dominios de las variables dada la \nasignación actual, utilizando la heurística VMR, elegiremos la variable C a continuación \ny le asignaremos el valor Miércoles (figura 3.12). \n \nFigura 3.13 Heurística de grado \nElaborado por los Autores \n \nLa heurística de Grado (figura 3.13) se basa en los grados de las variables, donde \nun grado es cuántos arcos conectan una variable con otras variables. Al elegir la variable \ncon el grado más alto, con una asignación, se restringen muchas otras variables, lo que \nacelera el proceso del algoritmo. \nPor ejemplo, al analizar se debe escoger la variable E porque tiene el grado más \nalto de todas las variables. \nEstas heurísticas no siempre son aplicables. Por ejemplo, cuando varias variables \ntienen el mismo número mínimo de valores en su dominio, o cuando varias variables \ntienen el mismo grado más alto.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n167 \nOtra forma de hacer que el algoritmo sea más eficiente es emplear otra heurística \ncuando se selecciona un valor del dominio de una variable. Aquí, se puede usar la \nheurística de Valores de Restricción Mínima, donde seleccionamos el valor que \nrestringirá la menor cantidad de otras variables. La idea aquí es que, mientras que en el \ngrado heurístico se quería usar la variable que es más probable que restrinja otras \nvariables, aquí queremos que esta variable imponga las menores restricciones sobre otras \nvariables. Es decir, se quiere localizar cuál podría ser la mayor fuente potencial de \nproblemas (la variable con el grado más alto) y luego convertirla en la menos \nproblemática que se pueda (asignarle el valor menos restrictivo). \nPor ejemplo, considérese la variable C (figura 3.14). Si se le asigna el martes, se \npondrá una restricción en B, E y F. Sin embargo, si se elige el miércoles, se pondrá una \nrestricción solo en B y E. Por lo tanto, probablemente sea mejor ir con el miércoles. \n \n     Figura 3.14 Asignación de día a la variable C \n     Elaborado por los Autores \n3.4 \nArboles de decisión \nLos árboles de decisión son una de las estructuras de datos más populares y \nampliamente investigadas, y son particularmente accesibles tanto para su creación como \npara su comprensión. Estos árboles facilitan el desarrollo de algoritmos de aprendizaje \nautomático. Funcionan mediante la categorización de la información de entrada en \nfunción de una variable de clasificación que tiene un rango limitado de posibles valores, \ncomo \"sí\" o \"no\".  \nSe aplican en una variedad de áreas como en la predicción de accidentes, evaluación \nde la solidez crediticia, identificación de la deserción de clientes, introducción de nuevos \nproductos en el mercado, consecución de objetivos de producción, reducción de la \ndeserción escolar, evaluación de riesgos en proyectos, toma de decisiones legales, \nplanificación de inversiones, previsiones climáticas, planificación de la producción,",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n168 \ndiagnóstico médico, y muchos otros. \nLos árboles de decisión también son útiles en sectores como el financiero y el de \nseguros, donde se utilizan para tomar decisiones sobre la aprobación de créditos o la \ndeterminación de las tarifas de las pólizas. Estos modelos permiten identificar qué \ncaracterísticas de los usuarios están asociadas con niveles más altos o más bajos de riesgo, \nfacilitando la personalización en función de las necesidades y riesgos específicos de cada \ngrupo de clientes. \nEstos árboles son muy utilizados en tareas de clasificación debido a su capacidad \nde predecir la categoría o clase de un dato nuevo de forma eficaz, la estructura que utiliza \nes semejante a una serie de preguntas y respuestas que conducen a una conclusión.   \nLos modelos de árboles de decisión ayudan a visualizar cómo se toman las \ndecisiones, a través de utilizar una representación que facilitan el análisis de las distintas \nvariables involucradas. Si un nodo en el árbol contiene datos de múltiples clases, se \nsubdivide en grupos más específicos y manejables, hasta que cada región (o nodo final) \nrepresente una sola categoría o clase.  \nLa creación de un modelo predictivo con árboles de decisión implica varias etapas \nque deben llevarse a cabo de manera ordenada, como el diseño del modelo (selección de \nlas características que se utilizarán en la toma de decisiones, y la construcción de la \nestructura del árbol), su evaluación (verificar qué tan bien el modelo predice o clasifica \nnuevos datos) y finalmente su implementación (integrarlo en un sistema de software \nexistente, usarlo para tomar decisiones en tiempo real, o aplicarlo en un proceso de \nnegocio). Para cada una de estas etapas se utiliza software o herramientas especializadas \nque son altamente beneficiosas, debido a que optimizan el proceso, evita errores y ahorran \ntiempo. \nLos árboles de decisión se dividen principalmente en dos categorías: árboles de \nclasificación y árboles de regresión. Los árboles de clasificación se utilizan para \ncategorizar datos en función de una variable clasificadora que es categórica, es decir, que \ntoma un número limitado de valores posibles, como “sí” o “no”, “amarillo” o “azul”. Este \ntipo de árboles es útil en situaciones donde la variable objetivo es discreta y se quiere \nclasificar en categorías específicas. Por otro lado, los árboles de regresión se emplean \ncuando la variable clasificadora es continua, por lo que puede tomar cualquier valor \ndentro de un rango, ejemplos: peso de una persona, precio de un terreno, la temperatura",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n169 \nambiente, ventas. \nLos árboles de decisión trabajan dividiendo el conjunto de datos de entrada en \ndiferentes regiones, con el fin de que cada una de estas regiones contenga elementos que \npertenezcan a una única clase. De esta forma, la clase predominante en cada región se \nconvierte en el representante de esa región específica. \nSi se encuentra una región que contiene elementos de más de una clase, el algoritmo \nprocede a subdividirla en regiones más pequeñas y más homogéneas, siguiendo el mismo \ncriterio de clasificación. Este proceso de subdivisión continúa hasta que todas las regiones \nsean lo más homogéneas posible en términos de la clase de los elementos que contienen. \nUn árbol de decisión opera mediante una serie de condiciones o preguntas que se \naplican a los datos de entrada. Cada condición dirige el flujo de datos hacia una rama \nespecífica del árbol, donde se realiza otra pregunta o se toma una decisión final. Este \nproceso se repite hasta llegar a una \"hoja\" del árbol, que es donde se toma la decisión \nfinal respecto a la clasificación o valor de la variable objetivo. \nLa \"profundidad máxima\" del árbol se refiere al número máximo de condiciones o \npreguntas que deben responderse para llegar a una hoja. Este es un parámetro importante \nporque puede afectar tanto la precisión como la complejidad del modelo. Un árbol muy \nprofundo podría capturar detalles muy específicos de los datos de entrenamiento, pero \ncorre el riesgo de sobre ajustar, lo que significa que podría no generalizar bien a nuevos \ndatos. Por otro lado, un árbol muy superficial podría no capturar suficiente información, \nresultando en un modelo poco preciso. \nAdemás de la consideración de la profundidad máxima del árbol, otro aspecto \nimportante en la construcción de árboles de decisión es la “poda del árbol”. La poda se \nrefiere al proceso de eliminar partes del árbol, como ramas o subárboles, que no \ncontribuyen significativamente a la capacidad de predicción del modelo. Este proceso es \nesencial para reducir la complejidad del modelo y evitar el sobreajuste. Mediante la poda, \nse pueden eliminar las ramas que se basan en variables o divisiones que no son \ninformativas, lo que simplifica el modelo y mejora su capacidad para hacer predicciones \nprecisas y relevantes en datos no vistos anteriormente. \nTras comprender la estructura general y la importancia de la poda en los árboles de \ndecisión, es importante examinar los algoritmos específicos que permiten la creación y \noptimización de estos modelos. Existen varios algoritmos destacados en el campo de los",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n170 \nárboles de decisión, cada uno con sus características y métodos particulares. Entre los \nmás conocidos y utilizados se encuentran el algoritmo ID3, C4.5 y CART.  \n \nEstos algoritmos difieren en cómo seleccionan las variables para dividir el árbol, \ncómo tratan los datos faltantes, cómo manejan variables continuas y categóricas, y en sus \nestrategias de poda. La elección del algoritmo adecuado depende del tipo específico de \nproblema, la naturaleza de los datos y los objetivos del análisis. \na) ID3 (Iterative Dichotomiser 3): Desarrollado por Ross Quinlan en la década de 1980, \nID3 es uno de los primeros algoritmos utilizados para construir árboles de decisión. \nUtiliza la Ganancia de Información como criterio para dividir los datos. ID3 se aplica \nprincipalmente a tareas de clasificación y funciona bien con atributos categóricos. Sin \nembargo, no es adecuado para atributos continuos y no maneja directamente los datos \nfaltantes ni la poda de árboles, que es decisivo para evitar el sobreajuste. \nb) C4.5: También desarrollado por Ross Quinlan como una extensión y mejora de ID3, \nC4.5 es capaz de manejar tanto datos categóricos como continuos. En lugar de la \nGanancia de Información, utiliza la Razón de Ganancia de Información, que normaliza \nla Ganancia de Información. C4.5 introduce el concepto de poda del árbol para reducir \nel tamaño del árbol y mejorar su capacidad de generalización. Además, maneja los \nvalores faltantes de los datos de manera más eficaz que ID3. \nc) CART (Classification and Regression Trees): Desarrollado por Breiman, Friedman, \nOlshen y Stone, CART es utilizado tanto para clasificación como para regresión. A \ndiferencia de ID3 y C4.5 que utilizan la entropía y la ganancia de información, CART \nutiliza el Índice Gini para clasificación y la Reducción de la Varianza para regresión. \nUna característica distintiva de CART es que produce árboles binarios (cada nodo tiene \nexactamente dos hijos), mientras que ID3 y C4.5 pueden crear árboles con más de dos \nhijos. CART también incluye procedimientos de poda más sofisticados para mejorar \nla generalización del modelo. \nUna vez que hemos explorado los algoritmos clave utilizados en la construcción \nde árboles de decisión, es fundamental entender las métricas de división que determinan \nla eficacia de cada nodo en el árbol. Estas métricas, como la Ganancia de Información, el \nÍndice Gini y la Reducción de la Varianza, son importantes en la evaluación de cómo cada \ncaracterística contribuye a la separación de los datos en categorías más homogéneas. La",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n171 \nelección de la métrica adecuada puede tener un impacto significativo en el rendimiento \ndel modelo, especialmente en la precisión con la que puede clasificar o predecir datos \nnuevos. Examinaremos estas métricas detalladamente para entender cómo optimizan la \neficiencia y la exactitud de los árboles de decisión. \na) Ganancia de Información (Information Gain): Esta métrica se basa en el concepto de \nentropía de la teoría de la información. La entropía mide el grado de incertidumbre o \nimpureza en un conjunto de datos (Poole & Mackworth, 2010). La Ganancia de \nInformación se calcula como la diferencia en entropía antes y después de la división \nde un conjunto de datos. Se prefiere una división que resulte en la máxima reducción \nde entropía, es decir, aquella que proporciona la mayor ganancia de información. Esto \nsignifica que la división ha logrado hacer los subconjuntos de datos más homogéneos \no puros respecto a la variable objetivo (Bishop & Nasrabadi, 2006). \nb) Índice Gini: El Índice Gini es otra medida de impureza o variabilidad y se usa \ncomúnmente en el algoritmo CART (Clasificación y Regresión de Árboles). Cuanto \nmenor es el valor de Gini, mayor es la pureza del nodo. El índice Gini para un nodo se \ncalcula sumando el cuadrado de la probabilidad de cada clase en el nodo y luego \nrestando el resultado de uno (Géron, 2022). Cuando se considera una división, se \nevalúa el índice Gini para cada subconjunto resultante y se pondera por el tamaño del \nsubconjunto. La división que resulta en el menor valor ponderado de Gini es la elegida. \nc) Reducción de la Varianza: Esta métrica se utiliza principalmente para problemas de \nregresión en árboles de decisión. Busca minimizar la varianza de los valores objetivo \nen cada nodo. La idea es elegir una división tal que los valores dentro de cada subgrupo \nsean lo más similares posible, lo que se traduce en una baja varianza. Para cada división \npotencial, se calcula la varianza en cada nodo hijo y se pondera por el número de \nobservaciones en el nodo. La división que resulta en la mayor reducción total de la \nvarianza es seleccionada. \nPor lo tanto, la profundidad máxima es un parámetro que a menudo se ajusta \ncuidadosamente para encontrar un equilibrio entre precisión y generalización. Este \nenfoque permite una clasificación efectiva y una fácil interpretación del modelo, lo que \nhace que los árboles de decisión sean una herramienta popular en el análisis de datos. A \ncontinuación, se tiene un ejemplo (figura 3.15).",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n172 \n \nFigura 3.15 Árbol de decisión binario \nElaborado por los Autores \n3.4.1 Estructura de los árboles de clasificación \nLos árboles de decisión son una herramienta poderosa para tareas de clasificación \ny regresión. Permiten modelar decisiones complejas de una manera que es fácilmente \ninterpretable. Existen los siguientes elementos: \nNodo Raíz: Es el punto de partida para cualquier nueva instancia de datos que se \nevalúa en el árbol. Este nodo contiene una condición basada en una característica o \natributo del conjunto de datos, que guía el flujo de la decisión hacia uno de los nodos \nhijos. \nEl Nodo Raíz se selecciona típicamente para maximizar la diferencia o pureza \nentre los subconjuntos de datos resultantes. Esto se hace utilizando criterios como la \nganancia de información, el índice de Gini, o la reducción de la entropía. Estos métodos \nbuscan identificar la característica que mejor divide el conjunto de datos en grupos \nhomogéneos en relación con la variable objetivo. Un Nodo Raíz bien elegido facilita la \ncreación de un árbol de decisión más eficiente y preciso, debido a que cada división \nposterior se construye sobre esta decisión inicial. \nNodos Internos o Splits: Cada uno de estos nodos contiene una condición o \npregunta basada en una característica específica del conjunto de datos. Esta condición se \ndiseña para dividir el conjunto de datos en dos o más subconjuntos, de acuerdo con los \nvalores que toma la característica en cuestión. \nLa selección de las condiciones en los Nodos Internos es un proceso estratégico, \ndonde se busca maximizar la claridad y la distinción entre los subconjuntos resultantes. \nEsto se logra mediante criterios como la ganancia de información, el índice de Gini, o la \nentropía, que determinan qué característica y qué valor de corte generan la división más \neficaz en términos de homogeneidad respecto a la variable objetivo.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n173 \nEstos nodos son fundamentales en el proceso de toma de decisiones, debido a que \npermiten que el árbol considere múltiples características y sus interacciones. Al evaluar \ndiferentes atributos en cada nivel del árbol, los Nodos Internos contribuyen a una mayor \nprecisión en la clasificación o predicción, permitiendo al modelo adaptarse y responder a \nla complejidad inherente en los datos. \nNodos Hoja o Terminales: A diferencia de los nodos raíz y nodos internos, los \nnodos hoja no contienen condiciones o preguntas. En lugar de ello, proporcionan la \nrespuesta final del árbol: asignan una etiqueta de clasificación o un valor predictivo a la \ninstancia de datos que ha seguido el camino desde el nodo raíz, pasando por varios nodos \ninternos, hasta llegar a este punto final. \nEn el contexto de la clasificación, cada nodo hoja corresponde a una categoría o \nclase específica. La asignación de la clase se basa en las características predominantes de \nlas instancias de datos que llegan a este nodo, a menudo utilizando la clase mayoritaria \nde estas instancias como la etiqueta asignada. En los problemas de regresión, el nodo hoja \ntípicamente representa el valor medio o mediano de las respuestas de las instancias de \ndatos que llegan a él. \nEstos nodos son fundamentales, porque encapsulan la conclusión del análisis \nrealizado por el árbol de decisión. Proporcionan una salida clara y concreta, que es el \nobjetivo final del proceso de modelado. La simplicidad y claridad de los nodos hoja hacen \nque los árboles de decisión sean herramientas altamente interpretables y transparentes en \nla toma de decisiones basada en datos. \nAdemás, los nodos hoja son indicativos de la capacidad del árbol para segmentar \ny entender el conjunto de datos. Un equilibrio adecuado en el número y la distribución de \nestos nodos es importante para evitar problemas como el sobreajuste o el subajuste, \nasegurando así que el modelo sea generalizable y eficaz en la toma de decisiones sobre \nnuevos datos. \nLa construcción de un árbol de decisión es un proceso meticuloso que involucra \nvarios criterios para asegurar que el modelo resultante sea tanto preciso como eficiente. \nA continuación, se explican los criterios: \nCriterio de Parada: Este criterio es fundamental para asegurar que el modelo sea \npreciso y generalizable, y evitar el sobreajuste. Se establecen criterios de parada, como la \nprofundidad máxima del árbol, un número mínimo de muestras por hoja, o un umbral de",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n174 \nganancia de información por debajo del cual no se realizarán más divisiones. \nCriterio de Selección: Se refiere a cómo se elige qué nodo (o característica) \ndividir en cada paso al construir el árbol, generalmente, se selecciona el nodo que ofrece \nla mayor ganancia de información o la mayor reducción en la impureza (como el índice \nde Gini o la entropía que cuantifican cuán mezcladas están las clases en un conjunto de \ndatos) para ser dividido a continuación. Este criterio asegura que las divisiones más \n\"informativas\" se realicen primero. \nCriterio de Clasificación: Una vez que se alcanza un nodo hoja, este criterio se \nutiliza para asignar una clase al nodo, y determinar la salida final. Esto se realiza \ngeneralmente en los árboles de clasificación, tomando la clase mayoritaria de las muestras \nque llegan a ese nodo; meintras que en los árboles de regresión se utiliza el promedio de \nlos valores. \nCriterio de Partición: Este criterio establece cómo se realizará la división del \nnodo seleccionado. En árboles binarios, cada nodo se divide generalmente en dos \nsubnodos basados en un valor umbral de un atributo específico. Sin embargo, también \nexisten árboles que permiten divisiones múltiples. \nEstos criterios trabajan en conjunto para construir un árbol de decisión que sea \ntanto preciso como generalizable. Es un equilibrio delicado que a menudo requiere ajustes \ny validación cruzada para optimizar el rendimiento del modelo. \nEn la construcción de los modelos de árboles de clasificación se debe considerar: \n✓ Preparar los Datos: Antes de entrenar cualquier modelo, es importante que los \ndatos estén en un formato adecuado. Esto puede implicar la eliminación de \nvalores nulos, vacíos, blancos. Se debe seleccionar las tablas, las columnas o \nvariables que se desean que entren al modelo. La calidad de los datos es \nfundamental para el rendimiento del modelo.   \n✓ Entrenar los Datos: Este es el núcleo del proceso de modelado. Se utiliza un \nconjunto de datos de entrenamiento para ajustar el modelo. Durante esta fase, el \nalgoritmo aprende a hacer predicciones o decisiones basadas en los datos. Los \nárboles de decisión, por ejemplo, aprenden a hacer divisiones basadas en los \nvalores de las características que resultan en la mayor ganancia de información o \nreducción de impureza. \n✓ Probar el Modelo: Una vez que el modelo ha sido entrenado, se debe probar con",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n175 \nun conjunto de datos que no haya visto antes. Esto se conoce como conjunto de \ndatos de prueba y sirve para evaluar cómo se desempeñará el modelo en \nescenarios no vistos previamente. \n✓ Evaluar el Modelo: La evaluación del rendimiento del modelo es crítica. Se \nutilizan métricas como la precisión, la sensibilidad, la especificidad y, a menudo, \nuna matriz de confusión para entender el rendimiento del modelo. Esto ofrece una \nvisión completa de cómo el modelo se desempeña en diferentes aspectos. \n✓ Aplicar el Modelo: Una vez que se está satisfecho con el rendimiento del \nmodelo, el último paso es desplegarlo en un entorno de producción donde pueda \nempezar a tomar decisiones o hacer predicciones en tiempo real. \nPara garantizar la eficacia y la robustez de los modelos generados a partir de los datos \nexistentes, es fundamental que estos modelos sean capaces de generalizarse bien a nuevos \nconjuntos de datos. En otras palabras, un modelo válido debe ser lo suficientemente \nflexible como para adaptarse a datos futuros y lo suficientemente preciso como para ser \nimplementado en un entorno de producción. \nDurante la fase de entrenamiento (figura 3.16), el modelo debe no solo ajustarse bien \na los datos de entrenamiento, sino también demostrar un rendimiento sólido en datos de \nprueba que no haya visto anteriormente. Este equilibrio es esencial para asegurar que el \nmodelo sea aplicable a situaciones del mundo real y no solo a las condiciones específicas \nde su conjunto de entrenamiento. \nEs vital prevenir el fenómeno de sobreentrenamiento, que ocurre cuando un modelo \nse ajusta demasiado a los datos de entrenamiento y pierde su capacidad para generalizar \na nuevos datos. Este problema se manifiesta cuando un modelo muestra un rendimiento \nexcepcional en el conjunto de datos de entrenamiento, pero falla al enfrentar datos nuevos \ne inéditos. \nAl abordar estos aspectos, se puede desarrollar un modelo de aprendizaje automático \nque sea tanto preciso como generalizable, lo que es fundamental para su éxito en \naplicaciones prácticas. \n \nFigura 3.16 Fases de entrenamiento y prueba",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n176 \nElaborado por los Autores \nPara los algoritmos supervisados es necesario contar con un conjunto de datos de \nentrenamiento y otro conjunto de datos de prueba, suponga que se tiene una tabla de datos \nde la cual el 70% se usa como datos de entrenamiento los cuales se introducen en el \nalgoritmo de aprendizaje (árbol de clasificación) y se genera el modelo, el 30% de datos \nrestantes son de prueba, se utiliza para aplicar el modelo y ver cuanta precisión existe con \nlos nuevos datos. \nEl modelo se forma mediante repetición iterativa de entrenamiento y verificación \nhasta conseguir unos niveles de precisión y de capacidad de predicción aceptables. \nLos conjuntos de datos de entrenamiento y de prueba se los escoge aleatoriamente \nde los datos iniciales. Pero existen técnicas que se utilizan para escoger la parte de datos \nque se quedan en el entrenamiento y en la prueba: \n• Una parte para el entrenamiento y la otra parte para la prueba (70% - 30%) \n• La tabla se divide en K conjuntos, se toman los K - 1 conjuntos para ir entrenado \ny se prueba el modelo con el último conjunto. \n• Todos los datos menos 1 se utiliza para el entrenamiento y la prueba se realiza con \nel único dato no usado.  \n3.4.2 Evaluación del modelo \nEn el campo del aprendizaje automático, el desarrollo y entrenamiento de modelos \nconstituyen solo una parte del proceso. Una vez que un modelo ha sido entrenado, surge \nuna pregunta importante: ¿Qué tan bien funciona? La evaluación de modelos es un paso \nesencial en el ciclo de vida del aprendizaje automático, porque proporciona perspectivas \ncríticas sobre la efectividad del modelo en la realización de predicciones o clasificaciones. \nEsta fase no solo es fundamental para validar la precisión del modelo, sino también para \ncomprender sus fortalezas y debilidades, asegurando que se tomen decisiones informadas \nantes de su implementación en aplicaciones prácticas. \nLa exactitud de un modelo de aprendizaje automático rara vez es perfecta, y es \naquí donde la evaluación se vuelve fundamental. Un modelo puede tener un alto grado de \nprecisión en el conjunto de entrenamiento, pero es su rendimiento en datos no vistos \nanteriormente —a menudo representados por el conjunto de prueba— lo que realmente \ndetermina su utilidad. Por ello, se utilizan diversas herramientas y métricas para evaluar \nla calidad de un modelo, no solo en términos de su precisión general, sino también en su",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n177 \ncapacidad para manejar diferentes tipos de instancias y su habilidad para evitar errores \ncríticos. \nLa evaluación del modelo va más allá de la mera medición de su precisión; implica \nuna comprensión profunda de cómo y por qué el modelo toma ciertas decisiones. Esto es \nespecialmente importante en aplicaciones donde las consecuencias de los errores pueden \nser significativas, como en el diagnóstico médico o en la toma de decisiones financieras. \nPor lo tanto, un modelo debe ser evaluado no solo por su capacidad para predecir \ncorrectamente, sino también por su habilidad para equilibrar diferentes tipos de errores y \nsu adaptabilidad a diversas condiciones de datos. \nLos modelos de aprendizaje automático raramente alcanzan una precisión del \n100%. Por lo general, se espera que un modelo tenga un cierto nivel de exactitud, y es \nprecisamente esta métrica la que se evalúa para determinar la eficacia del modelo. \nPara llevar a cabo esta evaluación, se emplean herramientas como la matriz de \nconfusión, también conocida como matriz de contingencia o matriz de errores. Esta matriz \nofrece una representación visual de cómo el modelo de clasificación se desempeña al \ndiferenciar entre las diversas clases en el conjunto de datos de prueba. No solo muestra \nlos aciertos del modelo, sino también los tipos de errores que comete, lo que facilita una \ncomprensión más profunda de su rendimiento. \nLa matriz de confusión es, en esencia, un instrumento gráfico que permite evaluar \nde manera cuantitativa y cualitativa el nivel de precisión de un modelo predictivo. A \ntravés de ella, se pueden calcular métricas adicionales como la sensibilidad, la \nespecificidad y la precisión, que proporcionan una visión más completa del rendimiento \ndel modelo (Géron, 2022). \nLa matriz de confusión (figura 3.17) tiene los siguientes componentes que son la \nclase verdadera y la clase predicha donde encontramos los verdaderos positivos que son \naquellos ítems de los datos de la tabla que realmente llevan un elemento de verdad por \nejemplo que son hombres y adultos, luego tenemos los falsos positivos que se predice que \nson hombres y adultos, pero no es verdad en realidad son hombres niños. Los falsos \nnegativos son aquellos casos en los que la predicción me dice que no son hombres adultos, \npero revisando la tabla si lo son, y por último los verdaderos negativos son aquellos casos \nen que se predijo que no son hombres adultos y es verdad.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n178 \n \nFigura 3.17 Matriz de Confusión \nElaborado por los Autores \nVerdadero Positivo (VP): Son los casos en los que el modelo predice \ncorrectamente la presencia de una característica o condición. Es el número de \nclasificaciones correctas en la Clase Positivos, son aquellos casos que en la clase \nverdadera son positivos y en la clase predicha también son positivos. Por ejemplo, si el \nmodelo predice que ciertos individuos son hombres adultos y, efectivamente, lo son según \nlos datos reales. \nVerdadero Negativo (VN): Son los casos en los que el modelo predice \ncorrectamente la ausencia de una característica. Es el número de clasificaciones correctas \nen la Clase Negativos, se predijo que eran No y realmente son No. En este caso, serían \nlos individuos que el modelo clasifica como no siendo hombres adultos, y que \nefectivamente no lo son según los datos reales. \nFalso Negativo (FN): Son los casos en los que el modelo predice incorrectamente \nla ausencia de una característica. Es el número de clasificaciones incorrectas de clase \npositiva clasificada como negativa, el modelo predijo que eran negativos, pero realmente \nson positivos. Siguiendo el ejemplo, serían los individuos que el modelo clasifica como \nno siendo hombres adultos, pero que en realidad sí lo son. \nFalso Positivo (FP): Son los casos en los que el modelo predice incorrectamente \nla presencia de una característica. Es el número de clasificaciones incorrectas de clase \nnegativa clasificada como positiva, se predijo que eran positivos, pero realmente son \nnegativos. En el ejemplo dado, serían los individuos que el modelo clasifica como \nhombres adultos, pero que en realidad son niños. \nEn el proceso de evaluación se usan las métricas las cuales proporcionan",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n179 \ninformación general.  \nError de clasificación es la frecuencia con la que el modelo de árbol de decisión \nhace una predicción incorrecta. Es decir, cuántas veces el modelo clasifica \nincorrectamente una instancia. Este error se puede medir de varias maneras, pero \ngeneralmente se calcula como la suma de las predicciones incorrectas sobre el número \ntotal de predicciones. \n 𝐸𝑟𝑟𝑜𝑟=\nFN +FP\nFN+FP+VP+VN \nExactitud (presición) es el número de predicciones correctas sobre el número \ntotal de predicciones. \n 𝐸𝑥𝑎𝑐𝑡𝑖𝑡𝑢𝑑=\nVP +VN\nFN+FP+VP+VN = 1 −𝐸𝑟𝑟𝑜𝑟 \nLa precisión es importante, especialmente en situaciones donde los costos de los \nfalsos positivos son altos. Se utiliza especialmente en tareas de clasificación y \nreconocimiento de patrones. Un ejemplo clásico de su uso es en los sistemas de filtrado \nde correos electrónicos para identificar y separar los correos no deseados o spam. \nRecall (o Sensibilidad): También conocida como tasa de verdaderos positivos, \nmide la capacidad del modelo para identificar correctamente los casos positivos. Se \ncalcula como: \n𝑅𝑒𝑐𝑎𝑙𝑙=\nVP\nVP+FN  \n \nEs importante en contextos donde no detectar los casos positivos (como \nenfermedades graves) es crítico. \nEspecificidad: Esta métrica mide la capacidad del modelo para identificar \ncorrectamente los casos negativos. Se calcula como: \n𝐸𝑠𝑝𝑒𝑐𝑖𝑓𝑖𝑐𝑖𝑑𝑎𝑑=\nVN\nVN+FP \nEs importante en escenarios donde es necesario no clasificar erróneamente los \nnegativos como positivos. Un ejemplo de uso de la métrica de especificidad es en el \ndiagnóstico médico, donde es importante no solo identificar correctamente las \ncondiciones presentes (sensibilidad) sino también confirmar con precisión la ausencia de \nuna condición (especificidad).  \nValor Predictivo Negativo: Mide la proporción de identificaciones negativas que \nfueron correctas. Se calcula como: \n𝑉𝑃𝑁=\nVN\nVN+FN",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n180 \nContinuando en elejemplo médico, esta métrica es importante en la determinación \nde la probabilidad de que una persona no tenga una enfermedad cuando la prueba indica \nun resultado negativo.  \nPuntuación F1: Esta es una métrica que combina la precisión y el recall en un \nsolo número, utilizando su media armónica. Es útil cuando se busca un balance entre \nprecisión y recall. Se calcula como: \nF1 = 2 x Presición  x  𝑅𝑒𝑐𝑎𝑙𝑙\nPrecisión + Recall  \nLa puntuación F1 se utiliza en aplicaciones de reconocimiento de voz, como \nasistentes virtuales o software de transcripción, puede ser utilizada para evaluar la \nprecisión en la identificación de palabras o frases específicas. Un alto valor de F1 indica \nque el sistema es eficaz tanto en reconocer correctamente las palabras (Precisión) como \nen capturar la totalidad de las palabras habladas (Sensibilidad). \nAdemás de estas métricas, la Curva ROC (Receiver Operating Characteristic) y \nel Área Bajo la Curva (AUC) son herramientas fundamentales para evaluar la capacidad \ndel modelo para discriminar entre clases.  \nLa curva ROC traza la tasa de verdaderos positivos (sensibilidad) en el eje de las \nY contra la tasa de falsos positivos (1 - especificidad) en el eje de las X, para diferentes \numbrales de decisión, que es el punto en el que decide clasificar un resultado como \npositivo o negativo. Mientras que el AUC proporciona una medida agregada de \nrendimiento en todos los umbrales posibles. Por ejemplo, un AUC de 1 indica un modelo \nperfecto que clasifica todos los positivos y negativos correctamente. Un AUC de 0.5 \nsugiere un rendimiento no mejor que el azar. Un AUC menor a 0.5 indica un rendimiento \npeor que el azar, lo que podría sugerir que las etiquetas están invertidas. \nROC y AUC son herramientas fundamentales para entender qué tan bien un \nmodelo puede diferenciar entre las clases, por ejemplo, en un modelo médico, debe \ndistinguir correctamente entre pacientes enfermos y sanos. Estas herramientas permiten \ntambién evaluar el modelo de forma integral en un espectro de situaciones, no solo en un \npunto de corte fijo. Esto es útil en aplicaciones donde el equilibrio entre sensibilidad y \nespecificidad es determinante y puede variar según el contexto. \nCada una de estas métricas aporta una dimensión diferente a la comprensión del \nrendimiento del modelo. Dependiendo del contexto y de los objetivos específicos del \nmodelo, algunas métricas pueden ser más relevantes que otras. Por ejemplo, en un modelo",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n181 \nde diagnóstico médico, la sensibilidad puede ser más crítica que la precisión, mientras \nque, en un sistema de recomendación de productos, la precisión puede tener mayor \nimportancia.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n182 \nBIBLIOGRAFÍA \nArtasanchez, A., & Joshi, P. (2020). Artificial Intelligence with Python: Your complete \nguide to building intelligent apps using Python 3. x. Packt Publishing Ltd. \nBaader, F. (2003). The description logic handbook: Theory, implementation and \napplications. Cambridge university press. \nBaral, C. (2003). Knowledge representation, reasoning and declarative problem solving. \nCambridge university press. \nBarski, C. (2010). Land of Lisp: learn to program in Lisp, one game at a time! No starch \npress. \nBenítez, R., Escudero, G., & Kanaan, S. (2014). Inteligencia artificial avanzada. Editorial \nUOC. \nBishop, C. M., & Nasrabadi, N. M. (2006). Pattern recognition and machine learning \n(Vol. 4, Número 4). Springer. \nBrachman, R., & Levesque, H. (2004a). Knowledge representation and reasoning. \nMorgan Kaufmann. \nBrachman, R., & Levesque, H. (2004b). Knowledge representation and reasoning. \nMorgan Kaufmann. \nBrookshear, J. G., & Brylow, D. (2020). Computer science: an overview. Pearson. \nChomsky, N. (2004). Estructuras sintácticas. Siglo xxi. \nChopra, R. (2012). Artificial Intelligence. S. Chand Publishing. \nColmerauer, A., & Roussel, P. (1996). History of Programming languages—II (T. J. \nBergin Jr. & R. G. Gibson Jr., Eds.; pp. 331–367). ACM. \nCroitoru, M., Marquis, P., Rudolph, S., & Stapleton, G. (2018). Graph Structures for \nKnowledge Representation and Reasoning: 5th International Workshop, GKR 2017, \nMelbourne, VIC, Australia, August 21, 2017, Revised Selected Papers (Vol. 10775). \nSpringer. \nDas, S. K. (2008). Foundations of decision-making agents: Logic, Probability and \nModality. World Scientific. \nDomkin, V. (2021). Programming Algorithms in Lisp. Springer. \nEdelkamp, S., & Schrödl, S. (2011). Heuristic search: theory and applications. Elsevier. \nEze, T. (2022). Trustworthy Autonomic Computing (Vol. 30). IET. \nFeigenbaum, E. A., & others. (1977). The art of artificial intelligence: Themes and case",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n183 \nstudies of knowledge engineering. \nFloridi, L. (2023). The ethics of artificial intelligence: Principles, challenges, and \nopportunities. \nFranceschetti, D. R. (2018). Principles of robotics & artificial intelligence. Salem Press, \na division of EBSCO Information Services, Incorporated. \nFraser, N. M. (1990). Natural Language Processing in PROLOG: An Introduction to \nComputational Linguistics. JSTOR. \nGarcía Serrano, A. (2012). Inteligencia Artificial. Fundamentos, práctica y aplicaciones. \nRc Libros. \nGelfond, M., & Kahl, Y. (2014). Knowledge representation, reasoning, and the design of \nintelligent agents: The answer-set programming approach. Cambridge University \nPress. \nGéron, A. (2022). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow. \n“ O’Reilly Media, Inc.” \nHaykin, S. (2009). Neural networks and learning machines, 3/E. Pearson Education \nIndia. \nKnott, G. D. (2017). Interpreting LISP: Programming and Data Structures. Apress. \nKörner, P., Leuschel, M., Barbosa, J., Costa, V. S., Dahl, V., Hermenegildo, M. V, \nMorales, J. F., Wielemaker, J., Diaz, D., Abreu, S., & others. (2022). Fifty years of \nProlog and beyond. Theory and Practice of Logic Programming, 22(6), 776–858. \nKowaliw, T., Bredeche, N., & Doursat, R. (2014). Growing Adaptive Machines. Springer. \nKowalski, R. A. (2011). Artificial intelligence and human thinking. Twenty-Second \nInternational Joint Conference on Artificial Intelligence. \nKumar, E. (2013). Artificial intelligence. IK International Pvt Ltd. \nLalanda, P., McCann, J. A., & Diaconescu, A. (2013). Autonomic computing. En \nPrinciples, Design and Implementation. Springer. \nLee, K.-F., & Qiufan, C. (2021). AI 2041: Ten visions for our future. Crown Currency. \nLeija, L. (2021). Métodos de procesamiento avanzado e inteligencia artificial en sistemas \nsensores y biosensores. Reverté. \nLindley, D. V. (2013). Understanding uncertainty. John Wiley & Sons. \nMacKay, D. J. C. (2003). Information theory, inference and learning algorithms. \nCambridge university press.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n184 \nMarkman, A. B. (2013). Knowledge representation. Psychology Press. \nMartinsanz, G. P., & Peñas, M. S. (2005). Inteligencia artificial e ingeniería del \nconocimiento. Ra-Ma. \nMcCarthy, J. (1956). The inversion of functions defined by Turing machines. Automata \nstudies, 34, 177–181. \nMcCarthy, J. (1960). Recursive functions of symbolic expressions and their computation \nby machine, part I. Communications of the ACM, 3(4), 184–195. \nMcCarthy, J. (1981). Epistemological problems of artificial intelligence. En Readings in \nartificial intelligence (pp. 459–465). Elsevier. \nMcCarthy, J. (1990). Artificial intelligence, logic, and formalising common sense. \nMachine Learning and the City: Applications in Architecture and Urban Design, \n69–90. \nMcDermott, D. (2007). Artificial intelligence and consciousness. The Cambridge \nhandbook of consciousness, 117–150. \nMichiels, W., Aarts, E., & Korst, J. (2007). Theoretical aspects of local search (Vol. 25). \nSpringer. \nMinsky, M. (1961). Steps toward artificial intelligence. Proceedings of the IRE, 49(1), 8–\n30. \nMinsky, M., & others. (1974). A framework for representing knowledge. Massachusetts \nInstitute of Technology AI Laboratory Cambridge. \nPham, D., & Karaboga, D. (2012). Intelligent optimisation techniques: genetic \nalgorithms, tabu search, simulated annealing and neural networks. Springer Science \n& Business Media. \nPoole, D. L., & Mackworth, A. K. (2010). Artificial Intelligence: foundations of \ncomputational agents. Cambridge University Press. \nRamirez, C. (2012). Advances in knowledge representation. BoD–Books on Demand. \nRussell, S., & Norvig, P. (2012). Artificial intelligence—a modern approach 3rd Edition. \nThe Knowledge Engineering Review. https://doi.org/10.1017/S0269888900007724 \nRussell, S., & Norvig, P. (2021). Artificial intelligence: a modern approach, 4th US ed. \nPearson Education. \nSamuel, A. L. (1959). Some studies in machine learning using the game of checkers. IBM \nJournal of research and development, 3(3), 210–229.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n185 \nShi, Z. (2019). Advanced artificial intelligence (Vol. 4). World Scientific. \nShortliffe, E. H. (1977). Mycin: A knowledge-based computer program applied to \ninfectious diseases. Proceedings of the Annual Symposium on Computer Application \nin Medical Care, 66. \nSipser, M. (1996). Introduction to the Theory of Computation. ACM Sigact News, 27(1), \n27–29. \nTuring, A. M. (2009). Computing machinery and intelligence. Springer. \nVan Harmelen, F., Lifschitz, V., & Porter, B. (2008). Handbook of knowledge \nrepresentation. Elsevier. \nWeller, K. (2010). Knowledge representation in the social semantic web. De Gruyter \nSaur. \nWhitby, B. (2009). Artificial intelligence. The Rosen Publishing Group, Inc. \nXiao, P. (2022). Artificial intelligence programming with Python: from zero to hero. John \nWiley & Sons.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n186 \nDE LOS AUTORES \nPATRICIO XAVIER MORENO VALLEJO \n \nIng. Patricio Xavier Moreno Vallejo M.S. \n \nESTUDIOS \n• Master of Science Major – Computer Science and Applications, Virginia \nPolytechnic Institute and State University, Estados Unidos de América \n• Ingeniero en Sistemas Informáticos, Escuela \nSuperior \nPolitécnica \nde \nChimborazo, Ecuador \n \nEXPERIENCIA \n• Docente en la Escuela Superior Politécnica de Chimborazo desde Octubre del \n2018 hasta la actualidad. \n• Senior Developer en Top-Tech Advisors desde Agosto – 2018 hasta Septiembre \n– 2018. \n• Teaching Assistant – Docente en Virginia Polytechnic Institute and State \nUniversity (Virginia Tech) desde Agosto – 2016 hasta Mayo – 2017. \n• Web Developer en Organization of American States (OEA) - Department of \nInformation and Technology Services desde Enero – 2016 hasta Mayo – 2016. \n• Program Developer en EasySoft S.A. desde Septiembre – 2014 hasta Septiembre \n– 2015. \n• Desarrollador de Sistemas en Clínica Riobamba desde Mayo – 2013 hasta Mayo \n– 2014. \n• Desarrollador Web en la Escuela Superior Politécnica de Chimborazo desde \nFebrero – 2013 hasta Julio – 2013.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n187 \nGISEL KATERINE BASTIDAS GUACHO \n \nIng. Gisel Katerine Bastidas Guacho M.S. \n \nESTUDIOS \n• Master of Science in Computer Science, University of California, Riverside, \nEstados Unidos. \n• Ingeniera en Sistemas Informáticos, Escuela Superior Politécnica de Chimborazo, \nEcuador \n \nEXPERIENCIA \n• Docente en la Escuela Superior Politécnica de Chimborazo desde Octubre del \n2019 hasta la actualidad. \n• Ingeniero Senior de Business Intelligence en TopTech Advisors - Produbanco \ndesde agosto-2018 hasta septiembre-2019. \n• Analista de Tecnologías de la Información y Comunicaciones en Ministerio del \nInterior desde marzo-2015 hasta octubre-2015. \n• Analista de TICs en CNT EP - Corporación Nacional de Telecomunicaciones \ndesde junio-2014 hasta marzo-2015. \n• Desarrolladora de Software en Clínica Riobamba desde julio-2013 hasta junio-\n2014. \n• Desarrolladora de Software – Prácticas pre-profesionales en Escuela Superior \nPolitécnica de Chimborazo desde febrero-2013 hasta julio-2013. \n• Soporte Técnico en Scytel - CNE desde enero-2013 hasta febrero-2013.",
  "FUNDAMENTOS DE LA INTELIGENCIA ARTIFICIAL: UNA VISION INTRODUCTORIA \nISBN General: 978-631-6557-23-0  \nISBN Tomo 1: 978-631-6557-25-4 \n \n \n \n188 \nPATRICIO RENE MORENO COSTALES  \n \nIng. Patricio René Moreno Costales M.S. \n \nESTUDIOS \n• Magister en Gerencia Educativa – Universidad Estatal de Bolívar – Ecuador \n• Magister en Informática Mención Redes – Universidad Andina Simón Bolívar – \nEscuela Politécnica Nacional - Ecuador \n• Ingeniero Mecánico – Escuela Superior Politécnica de Chimborazo – Ecuador \n \nEXPERIENCIA \n• Docente Escuela Superior Politécnica de Chimborazo desde 1990 \n• Director Carrera de Ingeniería en Sistemas Escuela Superior Politécnica de \nChimborazo 2000 a 2004 \n• Coordinador Carrera de Software Escuela Superior Politécnica de Chimborazo \n2016 - 2023"
]